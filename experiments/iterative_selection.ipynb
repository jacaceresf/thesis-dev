{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f330d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "#Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ea5eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import ModelDesc, dmatrices, dmatrix, demo_data\n",
    "import re\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "# TODO: add more complex operations from numpy\n",
    "COMPLEX_OPERATIONS = {\n",
    "    'cos': 'np.cos',\n",
    "    'tan': 'np.tan',\n",
    "    'log': 'np.log',\n",
    "    'log10': 'np.log10',\n",
    "    'log2': 'np.log2',\n",
    "    'min': 'np.min',\n",
    "    'max': 'np.max',\n",
    "    'pi': 'np.pi'\n",
    "}\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "def clean_column_symbols(column_, df, result):\n",
    "    df[column_.replace('np.cos', '_COZ_')\n",
    "       .replace(')', 'PAR_C')\n",
    "       .replace('(', 'PAR_O')\n",
    "       .replace('np.min', '_MINIM_')\n",
    "       .replace('np.max', '_MAXIM_')\n",
    "       .replace('np.pi', '_PII_')\n",
    "       .replace('**', '_POW_')\n",
    "       .replace('+', '_PLUS_')\n",
    "       .replace('*', '_TIMES_')\n",
    "       .replace('-', '_MINUS_')\n",
    "      .replace('/', '_DIV_')] = result\n",
    "    \n",
    "def add_blank_spaces_to_formula(formula: str) -> str:\n",
    "    new = ''\n",
    "    for index, element in enumerate(formula):\n",
    "        next_idx = index + 1\n",
    "        if next_idx < len(formula):\n",
    "            if not re.match('\\w', formula[index+1]):\n",
    "                new += element + ' '\n",
    "            else:\n",
    "                new += element\n",
    "        else:\n",
    "            new += element + ' '\n",
    "    return new\n",
    "\n",
    "def matched_words(s, pat):\n",
    "    pat = r'(\\w*%s\\w*)' % pat       # Not thrilled about this line\n",
    "    return re.findall(pat, s)\n",
    "\n",
    "def clean_formula(formula: str) -> str:\n",
    "    result = formula\n",
    "    for operation in COMPLEX_OPERATIONS:\n",
    "        if(operation in formula):\n",
    "            result = result.replace(operation, \"\")\n",
    "    return result\n",
    "\n",
    "def get_formula_variables(formula: str):\n",
    "  '''\n",
    "  Returns a list of every variable (non repeated) from the formula\n",
    "  '''\n",
    "  cleaned_formula = clean_formula(formula)\n",
    "  return sorted(list(set(\"\".join(re.findall(\"[a-zA-Z]+\", cleaned_formula)))))\n",
    "\n",
    "def group_columns(formula: str, data: pd.DataFrame):\n",
    "  # get number of variables inside formula\n",
    "  # convert string to set that only holds unique elements\n",
    "  characters = get_formula_variables(formula=formula)\n",
    "\n",
    "  # get dataset number of columns\n",
    "  columns = len(data.columns)\n",
    "  columns_lst = list(data.columns)\n",
    "  characters_len = len(characters)\n",
    "\n",
    "  result = []\n",
    "  \n",
    "  # column by column\n",
    "  for i in range(0, columns):  \n",
    "    # current column + 1 and substract 1 from characters so we don't count current character\n",
    "    for j in range(i+1, columns, characters_len-1):\n",
    "      column_variables = [columns_lst[i]]\n",
    "      column_variables.extend(columns_lst[j:j+(characters_len-1)])\n",
    "      # compare numbers and group columns by number of variables inside the formula\n",
    "      if(len(column_variables) == characters_len):\n",
    "        result.append(column_variables)\n",
    "  return result # grouped columns\n",
    "\n",
    "def get_formula_by_columns(formula: str, columns: list) -> dict:\n",
    "  '''\n",
    "  Mapping every single formula's variable to a column.\n",
    "  '''\n",
    "  to_replace = {}\n",
    "\n",
    "  # formula variables\n",
    "  variables = get_formula_variables(formula=formula)\n",
    "  # iterate over grouped columns\n",
    "  for cidx, column_group in enumerate(columns):\n",
    "    formula_grouped = {}\n",
    "    # iterate over variables\n",
    "    for idx, variable in enumerate(variables):\n",
    "      # variable paired to column name\n",
    "      formula_grouped[variable] = column_group[idx]\n",
    "    # every column group represents a key\n",
    "    to_replace[cidx] = formula_grouped\n",
    "  return to_replace\n",
    "\n",
    "def parse_formula(formula: str, formula_columns: dict) -> list:\n",
    "  '''\n",
    "  Parses, effectively, every grouped column to a real formula. \n",
    "  In simple words, replaces every formula variable for its paired column.\n",
    "  '''\n",
    "  result = []\n",
    "  formula_variables = re.findall(r'\\w+', formula)\n",
    "\n",
    "  for variables_paired in formula_columns.values():\n",
    "        new_formula = formula\n",
    "        for variable in formula_variables:\n",
    "            if variable in variables_paired:\n",
    "                # we need to put a blank space after a single character, \n",
    "                # so we can identify it then with the regex\n",
    "                replace_regex = f'{variable}(?:[^\\w\\*\\\\\\+\\(\\)\\-])'\n",
    "                new_formula = re.sub(replace_regex, variables_paired[variable], new_formula)\n",
    "#             elif variable in COMPLEX_OPERATIONS:\n",
    "#                 print(f'Going to replace [{variable} for [{COMPLEX_OPERATIONS[variable]}]')\n",
    "#                 new_formula = new_formula.replace(variable, COMPLEX_OPERATIONS[variable])\n",
    "#                 print(f'GOING TO APPEND => [{new_formula}]')\n",
    "        new_formula = new_formula.replace(\" \", \"\")\n",
    "        for key, value in COMPLEX_OPERATIONS.items():\n",
    "            if key in new_formula:\n",
    "                new_formula = new_formula.replace(key, value)\n",
    "        \n",
    "        result.append(new_formula)\n",
    "  \n",
    "  return result\n",
    "\n",
    "def execute_formula(formula_by_columns: list, data: pd.DataFrame) -> pd.DataFrame:\n",
    "  '''\n",
    "  Take every real formula and executes it via patsy dmatrix.\n",
    "  Saves every formula result inside a new dataframe's column.\n",
    "  '''\n",
    "  new_df = data.copy()\n",
    "     \n",
    "  for formula_columns in formula_by_columns:\n",
    "    result_items = []\n",
    "    add_data = True\n",
    "#     try:\n",
    "    formula = \"I(\"+formula_columns+\")-1\"\n",
    "    result = dmatrix(formula, data, NA_action='raise')\n",
    "    for item in result:\n",
    "        result_items.append(item.item())\n",
    "#     except:\n",
    "#         # Ignore Patsy error.\n",
    "#         add_data = False\n",
    "        \n",
    "    if add_data:\n",
    "        clean_column_symbols(formula_columns, new_df, result_items)\n",
    "    else:\n",
    "        print_error(\"Your data has some invalid values. Script will ignore them and their possible result\")\n",
    "        \n",
    "  return new_df\n",
    "\n",
    "def execute(formula_input: str, data: pd.DataFrame, class_column: str = None):\n",
    "\n",
    "    class_column_values = None\n",
    "    if class_column is not None:\n",
    "        class_column_values = data[class_column]\n",
    "        data=data.drop(class_column, axis=1)\n",
    "    \n",
    "    data.columns = data.columns.str.replace(' ','_')\n",
    "    \n",
    "    formula = add_blank_spaces_to_formula(formula_input.lower())\n",
    "    grouped_columns = group_columns(formula, data)\n",
    "    replaceable_result = get_formula_by_columns(formula, grouped_columns)\n",
    "    \n",
    "#     print(f'Got formula => {formula}')\n",
    "    executable_formulas = parse_formula(formula, replaceable_result)\n",
    "    new_data = execute_formula(executable_formulas, data)\n",
    "\n",
    "    if class_column_values is None:\n",
    "        return new_data\n",
    "    else:\n",
    "        return new_data, class_column_values\n",
    "def print_error(error_message: str):\n",
    "    print(f\"{bcolors.WARNING}{error_message}{bcolors.ENDC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bbdebd",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "317ae3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_for_selection(model: str):\n",
    "    models = {\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'LR': LogisticRegression(),\n",
    "        'NB': GaussianNB(),\n",
    "        'SVM': svm.SVC(max_iter=500000),\n",
    "        'RF': RandomForestClassifier(random_state=0),\n",
    "        'MLP': MLPClassifier(random_state=1)\n",
    "    }\n",
    "    model_ = models.get(model.upper())\n",
    "#     print(f'Going to return model: [{type(model_)}]')\n",
    "    return model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fc842414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_data(data: pd.DataFrame, \n",
    "                 class_name: str,\n",
    "                 formula_array: list,\n",
    "                 model: str, \n",
    "                 validation_data_size: float, \n",
    "                 test_data_size: float,\n",
    "                 dataset_name: str,\n",
    "                 forward_selection = True,\n",
    "                 use_cross_val = False,\n",
    "                 verbose_mode = False):\n",
    "    \n",
    "    if len(formula_array) == 0:\n",
    "       print_error(\"Formula array can't be empty.\")\n",
    "       return\n",
    "    \n",
    "    # variable definitions\n",
    "    continue_iter = True\n",
    "    idx_iter = 0\n",
    "    formula_len = len(formula_array)\n",
    "    last_formula_idx = 0\n",
    "    class_df = {}\n",
    "\n",
    "    iterations_result = []\n",
    "    iterations_df = []\n",
    "    \n",
    "    # this variables will handle the dataframe and classes\n",
    "    X = {}\n",
    "    y = {}\n",
    "\n",
    "    # the dataframe with its column filtered just for those that has been selected in the iteration n-1\n",
    "    last_selected_X = {}\n",
    "    \n",
    "    while continue_iter:\n",
    "        \n",
    "        formula = \"\"\n",
    "        \n",
    "        if idx_iter < formula_len:\n",
    "            formula = formula_array[idx_iter]\n",
    "            last_formula_idx += 1\n",
    "        elif (last_formula_idx+1) < formula_len:\n",
    "            formula = formula_array[last_formula_idx + 1]\n",
    "            last_formula_idx += 1\n",
    "        else:\n",
    "            last_formula_idx = 0\n",
    "            formula = formula_array[last_formula_idx]\n",
    "        \n",
    "        if verbose_mode:\n",
    "            print(f'ITERATION {idx_iter} with formula [{formula}]')\n",
    "        # for the first iteration, we need to create data from the original dataset\n",
    "        if idx_iter == 0:\n",
    "            new_df = df.sample(frac=1)\n",
    "            X, y = execute(formula_input=formula, data=new_df, class_column=class_name)\n",
    "        else:\n",
    "            X = execute(formula_input=formula, data=last_selected_X)\n",
    "\n",
    "        if verbose_mode:\n",
    "            print(f'Feature Generation - Columns => {list(X.columns)}')\n",
    "\n",
    "        number_of_columns = len(X.columns)\n",
    "\n",
    "        #split the dataset in 3 parts: train, evaluation and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_data_size, \n",
    "                                                            random_state=1)\n",
    "\n",
    "        # split the dataset in train and validation\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=validation_data_size,\n",
    "                                                          random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "        random_n = random.randint(2, number_of_columns)\n",
    "        if random_n > 10:\n",
    "            random_n = 10\n",
    "        model_selected = get_model_for_selection(model)\n",
    "        ## FEATURE SELECTION SECTION\n",
    "        plain_sfs = SFS(model_selected,\n",
    "                        scoring='accuracy',\n",
    "                        cv=0,\n",
    "                        k_features=random_n, \n",
    "                        forward=forward_selection, \n",
    "                        floating=(not forward_selection), n_jobs=-1)\n",
    "\n",
    "        # train\n",
    "        plain_sfs.fit(X_train, y_train)\n",
    "        selected_features = X.columns[list(plain_sfs.k_feature_idx_)]\n",
    "        if verbose_mode:\n",
    "            print(f'Selected Features => {list(selected_features)}')\n",
    "\n",
    "        clf = get_model_for_selection(model)\n",
    "        # validation\n",
    "        clf.fit(X_val[selected_features], y_val)\n",
    "\n",
    "        current_score = 0\n",
    "        # we get score using the test.\n",
    "        if use_cross_val:\n",
    "            current_score = cross_val_score(clf, X_test, y_test, cv=5).mean()\n",
    "        else:\n",
    "            current_score = accuracy_score(y_test, clf.predict(X_test[selected_features]))\n",
    "        if verbose_mode:\n",
    "            print(f'Got score = {current_score}')\n",
    "            \n",
    "        last_selected_X = X[selected_features]\n",
    "\n",
    "        # save both score and df with selected features to a list\n",
    "        iterations_result.append(current_score)\n",
    "        iterations_df.append(last_selected_X)\n",
    "\n",
    "        if idx_iter > 0 and current_score <= iterations_result[idx_iter-1]:\n",
    "            continue_iter = False\n",
    "        else:\n",
    "            continue_iter = True\n",
    "        idx_iter += 1\n",
    "#         print(\"\")\n",
    "        \n",
    "        max_index = iterations_result.index(max(iterations_result))\n",
    "\n",
    "    selection_type = \"Backward\"\n",
    "    if forward_selection:\n",
    "        selection_type = \"Forward\"\n",
    "        \n",
    "    print(f\"{dataset_name} - {selection_type} Selection - {model.upper()} - Formula {formula_array}\")\n",
    "    \n",
    "    if verbose_mode:\n",
    "        print('**** RESULTS ****')\n",
    "        print(f'Iteration with the best result: {max_index}')\n",
    "        print(f'Features for the best result: {clean_column_names(list(iterations_df[max_index].columns))}')\n",
    "    print(f'Score for the best result: {round(iterations_result[max_index], 2)}')\n",
    "    print(\"\")\n",
    "    \n",
    "def clean_column_names(names: list):\n",
    "    result = []\n",
    "    for column in names:\n",
    "        result.append(column.replace(\"_POW_\", \" ^ \")\n",
    "                      .replace(\"_TIMES_\", \"x\")\n",
    "                      .replace(\"_PLUS_\", \"+\")\n",
    "                      .replace(\"_MINUS_\", \"-\")\n",
    "                      .replace(\"_COZ_\", \"cos\")\n",
    "                      .replace(\"PAR_C\", \")\")\n",
    "                      .replace(\"PAR_O\", \"(\")\n",
    "                      .replace('_MINIM_', 'min')\n",
    "                      .replace('_MAXIM_', 'max')\n",
    "                      .replace('_PII_', 'pi')\n",
    "                     .replace('_DIV_', '/'))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e2bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algerian Forest - Forward Selection - SVM - Formula ['a * b']\n",
      "Score for the best result: 0.88\n",
      "\n",
      "Algerian Forest - Forward Selection - SVM - Formula ['cos(a+b)']\n",
      "Score for the best result: 0.56\n",
      "\n",
      "Algerian Forest - Forward Selection - SVM - Formula ['cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "Score for the best result: 0.64\n",
      "\n",
      "Algerian Forest - Forward Selection - SVM - Formula ['a * b', 'cos(a+b)']\n",
      "Score for the best result: 0.8\n",
      "\n",
      "Algerian Forest - Forward Selection - SVM - Formula ['a * b', 'cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "Score for the best result: 0.64\n",
      "\n",
      "Algerian Forest - Forward Selection - SVM - Formula ['a * b', 'cos(a+b)', 'cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "Score for the best result: 0.92\n",
      "\n",
      "Algerian Forest - Backward Selection - SVM - Formula ['a * b']\n",
      "Score for the best result: 0.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./datasets/Algerian_forest_fires.csv')\n",
    "\n",
    "# banknote => Class\n",
    "# speaker => language\n",
    "# algerian => Classes\n",
    "class_name = 'Classes'\n",
    "\n",
    "ds_name = 'Algerian Forest'\n",
    "# ds_name = 'Banknote Authentication'\n",
    "# ds_name = 'Speaker Accent Recognition'\n",
    "# ds_name = 'Pima Indian Diabetes'\n",
    "\n",
    "## F1\n",
    "# formulas = [\"a * b\"]\n",
    "##F2\n",
    "# formulas = [\"cos(a+b)\"]\n",
    "##F3\n",
    "# formulas = [\"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"]\n",
    "## F12\n",
    "# formulas = [\"a * b\", \"cos(a+b)\"]\n",
    "## F13\n",
    "# formulas = [\"a * b\", \"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"]\n",
    "## F123\n",
    "# formulas = [\"a * b\", \"cos(a+b)\", \"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"]\n",
    "\n",
    "selection_model = 'SVM'\n",
    "forward = True\n",
    "\n",
    "use_cross_validation = True\n",
    "\n",
    "formulas_list = [[\"a * b\"], [\"cos(a+b)\"], [\"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"],\n",
    "                 [\"a * b\", \"cos(a+b)\"], [\"a * b\", \"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"],\n",
    "                 [\"a * b\", \"cos(a+b)\", \"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"]]\n",
    "\n",
    "for form in formulas_list:\n",
    "    iterate_data(data=df, class_name=class_name, formula_array=form,\n",
    "             model=selection_model, validation_data_size=0.10, test_data_size=0.10, \n",
    "             forward_selection=forward, dataset_name=ds_name, use_cross_val=use_cross_validation,\n",
    "             verbose_mode = False)\n",
    "\n",
    "forward = False\n",
    "for form_ in formulas_list:\n",
    "    iterate_data(data=df, class_name=class_name, formula_array=form_,\n",
    "             model=selection_model, validation_data_size=0.10, test_data_size=0.10, \n",
    "             forward_selection=forward, dataset_name=ds_name, use_cross_val=use_cross_validation,\n",
    "             verbose_mode = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628869b1",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- When we use a formula with one character like (a*a) we have problem building the formula\n",
    "- We need to take care about the naming for the features that are generated by our method because if we use a math notation, we have problems at the next iteration. For instance: we can't create a feature called A1*A2 because in the next iteration, patsy will separate that into two columns and not just one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
