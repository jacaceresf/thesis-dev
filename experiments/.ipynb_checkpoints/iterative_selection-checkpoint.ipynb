{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f330d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5ea5eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import ModelDesc, dmatrices, dmatrix, demo_data\n",
    "import re\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "# TODO: add more complex operations from numpy\n",
    "COMPLEX_OPERATIONS = {\n",
    "    'cos': 'np.cos',\n",
    "    'tan': 'np.tan',\n",
    "    'log': 'np.log',\n",
    "    'log10': 'np.log10',\n",
    "    'log2': 'np.log2',\n",
    "    'min': 'np.min',\n",
    "    'max': 'np.max',\n",
    "    'pi': 'np.pi'\n",
    "}\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "def add_blank_spaces_to_formula(formula: str) -> str:\n",
    "    new = ''\n",
    "    for index, element in enumerate(formula):\n",
    "        next_idx = index + 1\n",
    "        if next_idx < len(formula):\n",
    "            if not re.match('\\w', formula[index+1]):\n",
    "                new += element + ' '\n",
    "            else:\n",
    "                new += element\n",
    "        else:\n",
    "            new += element + ' '\n",
    "    return new\n",
    "\n",
    "def matched_words(s, pat):\n",
    "    pat = r'(\\w*%s\\w*)' % pat       # Not thrilled about this line\n",
    "    return re.findall(pat, s)\n",
    "\n",
    "def clean_formula(formula: str) -> str:\n",
    "    result = formula\n",
    "    for operation in COMPLEX_OPERATIONS:\n",
    "        if(operation in formula):\n",
    "            result = result.replace(operation, \"\")\n",
    "    return result\n",
    "\n",
    "def get_formula_variables(formula: str):\n",
    "  '''\n",
    "  Returns a list of every variable (non repeated) from the formula\n",
    "  '''\n",
    "  cleaned_formula = clean_formula(formula)\n",
    "  return sorted(list(set(\"\".join(re.findall(\"[a-zA-Z]+\", cleaned_formula)))))\n",
    "\n",
    "def group_columns(formula: str, data: pd.DataFrame):\n",
    "  # get number of variables inside formula\n",
    "  # convert string to set that only holds unique elements\n",
    "  characters = get_formula_variables(formula=formula)\n",
    "\n",
    "  # get dataset number of columns\n",
    "  columns = len(data.columns)\n",
    "  columns_lst = list(data.columns)\n",
    "  characters_len = len(characters)\n",
    "\n",
    "  result = []\n",
    "  \n",
    "  # column by column\n",
    "  for i in range(0, columns):  \n",
    "    # current column + 1 and substract 1 from characters so we don't count current character\n",
    "    for j in range(i+1, columns, characters_len-1):\n",
    "      column_variables = [columns_lst[i]]\n",
    "      column_variables.extend(columns_lst[j:j+(characters_len-1)])\n",
    "      # compare numbers and group columns by number of variables inside the formula\n",
    "      if(len(column_variables) == characters_len):\n",
    "        result.append(column_variables)\n",
    "  return result # grouped columns\n",
    "\n",
    "def get_formula_by_columns(formula: str, columns: list) -> dict:\n",
    "  '''\n",
    "  Mapping every single formula's variable to a column.\n",
    "  '''\n",
    "  to_replace = {}\n",
    "\n",
    "  # formula variables\n",
    "  variables = get_formula_variables(formula=formula)\n",
    "  # iterate over grouped columns\n",
    "  for cidx, column_group in enumerate(columns):\n",
    "    formula_grouped = {}\n",
    "    # iterate over variables\n",
    "    for idx, variable in enumerate(variables):\n",
    "      # variable paired to column name\n",
    "      formula_grouped[variable] = column_group[idx]\n",
    "    # every column group represents a key\n",
    "    to_replace[cidx] = formula_grouped\n",
    "  return to_replace\n",
    "\n",
    "def parse_formula(formula: str, formula_columns: dict) -> list:\n",
    "  '''\n",
    "  Parses, effectively, every grouped column to a real formula. \n",
    "  In simple words, replaces every formula variable for its paired column.\n",
    "  '''\n",
    "  result = []\n",
    "  formula_variables = re.findall(r'\\w+', formula)\n",
    "\n",
    "  for variables_paired in formula_columns.values():\n",
    "        new_formula = formula\n",
    "        for variable in formula_variables:\n",
    "            if variable in variables_paired:\n",
    "                # we need to put a blank space after a single character, \n",
    "                # so we can identify it then with the regex\n",
    "                replace_regex = f'{variable}(?:[^\\w\\*\\\\\\+\\(\\)\\-])'\n",
    "                new_formula = re.sub(replace_regex, variables_paired[variable], new_formula)\n",
    "#             elif variable in COMPLEX_OPERATIONS:\n",
    "#                 print(f'Going to replace [{variable} for [{COMPLEX_OPERATIONS[variable]}]')\n",
    "#                 new_formula = new_formula.replace(variable, COMPLEX_OPERATIONS[variable])\n",
    "#                 print(f'GOING TO APPEND => [{new_formula}]')\n",
    "        new_formula = new_formula.replace(\" \", \"\")\n",
    "        for key, value in COMPLEX_OPERATIONS.items():\n",
    "            if key in new_formula:\n",
    "                new_formula = new_formula.replace(key, value)\n",
    "        \n",
    "        result.append(new_formula)\n",
    "  \n",
    "  return result\n",
    "\n",
    "def execute_formula(formula_by_columns: list, data: pd.DataFrame) -> pd.DataFrame:\n",
    "  '''\n",
    "  Take every real formula and executes it via patsy dmatrix.\n",
    "  Saves every formula result inside a new dataframe's column.\n",
    "  '''\n",
    "  new_df = data.copy()\n",
    "     \n",
    "  for formula_columns in formula_by_columns:\n",
    "    result_items = []\n",
    "    add_data = True\n",
    "#     try:\n",
    "    formula = \"I(\"+formula_columns+\")-1\"\n",
    "    result = dmatrix(formula, data, NA_action='raise')\n",
    "    for item in result:\n",
    "        result_items.append(item.item())\n",
    "#     except:\n",
    "#         # Ignore Patsy error.\n",
    "#         add_data = False\n",
    "        \n",
    "    if add_data:\n",
    "        if \"np.\" in formula_columns:\n",
    "            new_df[formula_columns.replace('np.', '')] = result_items\n",
    "        else:\n",
    "            new_df[formula_columns.replace('*', 'x')] = result_items\n",
    "    else:\n",
    "        print(f\"{bcolors.WARNING}Your data has some invalid values. Script will ignore them and their possible result.{bcolors.ENDC}\")\n",
    "        \n",
    "  return new_df\n",
    "\n",
    "def execute(formula_input: str, data: pd.DataFrame, class_column: str = None):\n",
    "\n",
    "    class_column_values = None\n",
    "    if class_column is not None:\n",
    "        class_column_values = data[class_column]\n",
    "        data=data.drop(class_column, axis=1)\n",
    "    \n",
    "    data.columns = data.columns.str.replace(' ','_')\n",
    "    \n",
    "    formula = add_blank_spaces_to_formula(formula_input.lower())\n",
    "    grouped_columns = group_columns(formula, data)\n",
    "    replaceable_result = get_formula_by_columns(formula, grouped_columns)\n",
    "    \n",
    "#     print(f'Got formula => {formula}')\n",
    "    executable_formulas = parse_formula(formula, replaceable_result)\n",
    "    new_data = execute_formula(executable_formulas, data)\n",
    "\n",
    "    if class_column_values is None:\n",
    "        return new_data\n",
    "    else:\n",
    "        return new_data, class_column_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ef43c0",
   "metadata": {},
   "source": [
    "## Variables definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bf7ee635",
   "metadata": {},
   "outputs": [],
   "source": [
    "continue_iter = True\n",
    "idx_iter = 0\n",
    "df = pd.read_csv('./datasets/user_knowledge.csv')\n",
    "formula = 'a* b'\n",
    "class_name = 'UNS'\n",
    "class_df = {}\n",
    "\n",
    "iterations_result = []\n",
    "iterations_df = []\n",
    "\n",
    "X = df\n",
    "# we're going to save here our dataframe class.\n",
    "y = {}\n",
    "\n",
    "# the dataframe with its column filtered just for those that has been selected in the iteration n-1\n",
    "last_selected_X = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bbdebd",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "317ae3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION 0\n",
      "Feature Generation - Columns => ['STG', 'SCG', 'STR', 'LPR', 'PEG', 'STGxSCG', 'STGxSTR', 'STGxLPR', 'STGxPEG', 'SCGxSTR', 'SCGxLPR', 'SCGxPEG', 'STRxLPR', 'STRxPEG', 'LPRxPEG']\n",
      "Selected Features => ['STR', 'LPR', 'PEG', 'STGxSCG', 'STGxSTR', 'STGxLPR', 'STGxPEG', 'SCGxPEG', 'STRxPEG', 'LPRxPEG']\n",
      "Got score = 0.8024691358024691\n",
      "\n",
      "ITERATION 1\n",
      "Feature Generation - Columns => ['STR', 'LPR', 'PEG', 'STGxSCG', 'STGxSTR', 'STGxLPR', 'STGxPEG', 'SCGxPEG', 'STRxPEG', 'LPRxPEG', 'STRxLPR', 'STRxSTGxSCG', 'STRxSTGxSTR', 'STRxSTGxLPR', 'STRxSTGxPEG', 'STRxSCGxPEG', 'STRxSTRxPEG', 'STRxLPRxPEG', 'LPRxSTGxSCG', 'LPRxSTGxSTR', 'LPRxSTGxLPR', 'LPRxSTGxPEG', 'LPRxSCGxPEG', 'LPRxSTRxPEG', 'LPRxLPRxPEG', 'PEGxSTGxSCG', 'PEGxSTGxSTR', 'PEGxSTGxLPR', 'PEGxSTGxPEG', 'PEGxSCGxPEG', 'PEGxSTRxPEG', 'PEGxLPRxPEG', 'STGxSCGxSTGxSTR', 'STGxSCGxSTGxLPR', 'STGxSCGxSTGxPEG', 'STGxSCGxSCGxPEG', 'STGxSCGxSTRxPEG', 'STGxSCGxLPRxPEG', 'STGxSTRxSTGxLPR', 'STGxSTRxSTGxPEG', 'STGxSTRxSCGxPEG', 'STGxSTRxSTRxPEG', 'STGxSTRxLPRxPEG', 'STGxLPRxSTGxPEG', 'STGxLPRxSCGxPEG', 'STGxLPRxSTRxPEG', 'STGxLPRxLPRxPEG', 'STGxPEGxSCGxPEG', 'STGxPEGxSTRxPEG', 'STGxPEGxLPRxPEG', 'SCGxPEGxSTRxPEG', 'SCGxPEGxLPRxPEG', 'STRxPEGxLPRxPEG']\n",
      "Selected Features => ['PEG', 'STGxPEG', 'LPRxPEG', 'STRxSTGxPEG', 'STRxSCGxPEG', 'STRxLPRxPEG', 'LPRxLPRxPEG', 'PEGxSCGxPEG', 'PEGxLPRxPEG', 'STGxSCGxSTGxSTR']\n",
      "Got score = 0.9135802469135802\n",
      "\n",
      "ITERATION 2\n",
      "Feature Generation - Columns => ['PEG', 'STGxPEG', 'LPRxPEG', 'STRxSTGxPEG', 'STRxSCGxPEG', 'STRxLPRxPEG', 'LPRxLPRxPEG', 'PEGxSCGxPEG', 'PEGxLPRxPEG', 'STGxSCGxSTGxSTR', 'PEGxSTGxPEG', 'PEGxSTRxSTGxPEG', 'PEGxSTRxSCGxPEG', 'PEGxSTRxLPRxPEG', 'PEGxLPRxLPRxPEG', 'PEGxPEGxSCGxPEG', 'PEGxPEGxLPRxPEG', 'PEGxSTGxSCGxSTGxSTR', 'STGxPEGxLPRxPEG', 'STGxPEGxSTRxSTGxPEG', 'STGxPEGxSTRxSCGxPEG', 'STGxPEGxSTRxLPRxPEG', 'STGxPEGxLPRxLPRxPEG', 'STGxPEGxPEGxSCGxPEG', 'STGxPEGxPEGxLPRxPEG', 'STGxPEGxSTGxSCGxSTGxSTR', 'LPRxPEGxSTRxSTGxPEG', 'LPRxPEGxSTRxSCGxPEG', 'LPRxPEGxSTRxLPRxPEG', 'LPRxPEGxLPRxLPRxPEG', 'LPRxPEGxPEGxSCGxPEG', 'LPRxPEGxPEGxLPRxPEG', 'LPRxPEGxSTGxSCGxSTGxSTR', 'STRxSTGxPEGxSTRxSCGxPEG', 'STRxSTGxPEGxSTRxLPRxPEG', 'STRxSTGxPEGxLPRxLPRxPEG', 'STRxSTGxPEGxPEGxSCGxPEG', 'STRxSTGxPEGxPEGxLPRxPEG', 'STRxSTGxPEGxSTGxSCGxSTGxSTR', 'STRxSCGxPEGxSTRxLPRxPEG', 'STRxSCGxPEGxLPRxLPRxPEG', 'STRxSCGxPEGxPEGxSCGxPEG', 'STRxSCGxPEGxPEGxLPRxPEG', 'STRxSCGxPEGxSTGxSCGxSTGxSTR', 'STRxLPRxPEGxLPRxLPRxPEG', 'STRxLPRxPEGxPEGxSCGxPEG', 'STRxLPRxPEGxPEGxLPRxPEG', 'STRxLPRxPEGxSTGxSCGxSTGxSTR', 'LPRxLPRxPEGxPEGxSCGxPEG', 'LPRxLPRxPEGxPEGxLPRxPEG', 'LPRxLPRxPEGxSTGxSCGxSTGxSTR', 'PEGxSCGxPEGxPEGxLPRxPEG', 'PEGxSCGxPEGxSTGxSCGxSTGxSTR', 'PEGxLPRxPEGxSTGxSCGxSTGxSTR']\n",
      "Selected Features => ['PEG', 'STGxPEG', 'LPRxPEG', 'STRxSTGxPEG', 'STRxSCGxPEG', 'STRxLPRxPEG', 'LPRxLPRxPEG', 'STGxSCGxSTGxSTR', 'PEGxPEGxLPRxPEG', 'LPRxPEGxLPRxLPRxPEG']\n",
      "Got score = 0.9012345679012346\n",
      "\n",
      "\n",
      "**** RESULTS ****\n",
      "Iteration with the best result: 1\n",
      "Features for the best result: ['PEG', 'STGxPEG', 'LPRxPEG', 'STRxSTGxPEG', 'STRxSCGxPEG', 'STRxLPRxPEG', 'LPRxLPRxPEG', 'PEGxSCGxPEG', 'PEGxLPRxPEG', 'STGxSCGxSTGxSTR']\n",
      "Score for the best result: 0.9135802469135802\n"
     ]
    }
   ],
   "source": [
    "while continue_iter:\n",
    "    print(f'ITERATION {idx_iter}')\n",
    "    # for the first iteration, we need to create data from the original dataset\n",
    "    if idx_iter == 0:\n",
    "        X, y = execute(formula_input=formula, data=df, class_column=class_name)\n",
    "    else:\n",
    "        X = execute(formula_input=formula, data=last_selected_X)\n",
    "    \n",
    "    print(f'Feature Generation - Columns => {list(X.columns)}')\n",
    "        \n",
    "    number_of_columns = len(X.columns)\n",
    "    \n",
    "    #split the dataset in 3 parts: train, evaluation and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=1) # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    random_n = random.randint(2, number_of_columns)\n",
    "    if random_n > 10:\n",
    "        random_n = 10\n",
    "#     print(f'Got random_n => [{random_n}]')\n",
    "    plain_sfs = SFS(KNeighborsClassifier(), \n",
    "          k_features=random_n, \n",
    "          forward=True, \n",
    "          floating=False, n_jobs=-1)\n",
    "    # train\n",
    "    plain_sfs.fit(X_train, y_train)\n",
    "    selected_features = X.columns[list(plain_sfs.k_feature_idx_)]\n",
    "    print(f'Selected Features => {list(selected_features)}')\n",
    "    \n",
    "    clf = KNeighborsClassifier()\n",
    "    # validation\n",
    "    clf.fit(X_val[selected_features], y_val)\n",
    "    \n",
    "    # we get score using the test.\n",
    "    current_score = accuracy_score(y_test, clf.predict(X_test[selected_features]))\n",
    "    print(f'Got score = {current_score}')\n",
    "    last_selected_X = X[selected_features]\n",
    "    \n",
    "    # save both score and df with selected features to a list\n",
    "    iterations_result.append(current_score)\n",
    "    iterations_df.append(last_selected_X)\n",
    "    \n",
    "    if idx_iter > 0 and current_score <= iterations_result[idx_iter-1]:\n",
    "        continue_iter = False\n",
    "    else:\n",
    "        continue_iter = True\n",
    "    idx_iter += 1\n",
    "    print(\"\")\n",
    "        \n",
    "\n",
    "max_index = iterations_result.index(max(iterations_result))\n",
    "print(\"\")\n",
    "print('**** RESULTS ****')\n",
    "print(f'Iteration with the best result: {max_index}')\n",
    "print(f'Features for the best result: {list(iterations_df[max_index].columns)}')\n",
    "print(f'Score for the best result: {iterations_result[max_index]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc842414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
