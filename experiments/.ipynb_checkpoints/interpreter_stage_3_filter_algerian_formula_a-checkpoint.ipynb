{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Execute imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>Ws</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>...</th>\n",
       "      <th>cos(DMC+DC)</th>\n",
       "      <th>cos(DMC+ISI)</th>\n",
       "      <th>cos(DMC+BUI)</th>\n",
       "      <th>cos(DMC+FWI)</th>\n",
       "      <th>cos(DC+ISI)</th>\n",
       "      <th>cos(DC+BUI)</th>\n",
       "      <th>cos(DC+FWI)</th>\n",
       "      <th>cos(ISI+BUI)</th>\n",
       "      <th>cos(ISI+FWI)</th>\n",
       "      <th>cos(BUI+FWI)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>-0.012389</td>\n",
       "      <td>0.869397</td>\n",
       "      <td>-0.725932</td>\n",
       "      <td>-0.865435</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>-0.243544</td>\n",
       "      <td>-0.012389</td>\n",
       "      <td>-0.227202</td>\n",
       "      <td>-0.725932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647596</td>\n",
       "      <td>0.377978</td>\n",
       "      <td>-0.145500</td>\n",
       "      <td>-0.210796</td>\n",
       "      <td>-0.678720</td>\n",
       "      <td>0.483305</td>\n",
       "      <td>-0.145500</td>\n",
       "      <td>0.186512</td>\n",
       "      <td>0.169967</td>\n",
       "      <td>-0.400799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.984688</td>\n",
       "      <td>-0.942222</td>\n",
       "      <td>0.468517</td>\n",
       "      <td>-0.856889</td>\n",
       "      <td>0.438547</td>\n",
       "      <td>-0.930426</td>\n",
       "      <td>0.608351</td>\n",
       "      <td>-0.989992</td>\n",
       "      <td>0.921061</td>\n",
       "      <td>-0.942222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339155</td>\n",
       "      <td>0.267499</td>\n",
       "      <td>-0.989992</td>\n",
       "      <td>0.267499</td>\n",
       "      <td>0.815725</td>\n",
       "      <td>-0.678720</td>\n",
       "      <td>0.815725</td>\n",
       "      <td>-0.128844</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.128844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078678</td>\n",
       "      <td>-0.490261</td>\n",
       "      <td>0.815725</td>\n",
       "      <td>-0.936457</td>\n",
       "      <td>-0.952953</td>\n",
       "      <td>0.731991</td>\n",
       "      <td>-0.533584</td>\n",
       "      <td>0.377978</td>\n",
       "      <td>-0.128844</td>\n",
       "      <td>-0.307333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>30</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>44.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.689687</td>\n",
       "      <td>-0.079564</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>-0.873305</td>\n",
       "      <td>0.300593</td>\n",
       "      <td>0.138497</td>\n",
       "      <td>0.742154</td>\n",
       "      <td>-0.830301</td>\n",
       "      <td>0.004426</td>\n",
       "      <td>-0.161238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "      <td>15</td>\n",
       "      <td>4.4</td>\n",
       "      <td>41.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.354924</td>\n",
       "      <td>0.950233</td>\n",
       "      <td>0.991085</td>\n",
       "      <td>0.976588</td>\n",
       "      <td>-0.243544</td>\n",
       "      <td>-0.062792</td>\n",
       "      <td>-0.145500</td>\n",
       "      <td>0.999859</td>\n",
       "      <td>0.995004</td>\n",
       "      <td>0.996542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>27</td>\n",
       "      <td>87</td>\n",
       "      <td>29</td>\n",
       "      <td>0.5</td>\n",
       "      <td>45.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.393491</td>\n",
       "      <td>-0.725932</td>\n",
       "      <td>0.815725</td>\n",
       "      <td>-0.848100</td>\n",
       "      <td>-0.431377</td>\n",
       "      <td>0.299745</td>\n",
       "      <td>-0.243544</td>\n",
       "      <td>-0.790968</td>\n",
       "      <td>0.825336</td>\n",
       "      <td>-0.896758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>54</td>\n",
       "      <td>18</td>\n",
       "      <td>0.1</td>\n",
       "      <td>79.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>15.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795815</td>\n",
       "      <td>0.960170</td>\n",
       "      <td>-0.999693</td>\n",
       "      <td>0.283662</td>\n",
       "      <td>-0.369768</td>\n",
       "      <td>0.120062</td>\n",
       "      <td>-0.981618</td>\n",
       "      <td>0.869397</td>\n",
       "      <td>-0.737394</td>\n",
       "      <td>0.885520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>15</td>\n",
       "      <td>0.2</td>\n",
       "      <td>67.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>16.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120062</td>\n",
       "      <td>0.283662</td>\n",
       "      <td>-0.678720</td>\n",
       "      <td>-0.400799</td>\n",
       "      <td>0.408893</td>\n",
       "      <td>-0.770514</td>\n",
       "      <td>-0.275163</td>\n",
       "      <td>0.960170</td>\n",
       "      <td>-0.128844</td>\n",
       "      <td>0.554374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows × 91 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     day  month  year  Temperature  RH  Ws  Rain  FFMC   DMC    DC  ...  \\\n",
       "0      1      6  2012           29  57  18   0.0  65.7   3.4   7.6  ...   \n",
       "1      2      6  2012           29  61  13   1.3  64.4   4.1   7.6  ...   \n",
       "2      3      6  2012           26  82  22  13.1  47.1   2.5   7.1  ...   \n",
       "3      4      6  2012           25  89  13   2.5  28.6   1.3   6.9  ...   \n",
       "4      5      6  2012           27  77  16   0.0  64.8   3.0  14.2  ...   \n",
       "..   ...    ...   ...          ...  ..  ..   ...   ...   ...   ...  ...   \n",
       "239   26      9  2012           30  65  14   0.0  85.4  16.0  44.5  ...   \n",
       "240   27      9  2012           28  87  15   4.4  41.1   6.5   8.0  ...   \n",
       "241   28      9  2012           27  87  29   0.5  45.9   3.5   7.9  ...   \n",
       "242   29      9  2012           24  54  18   0.1  79.7   4.3  15.2  ...   \n",
       "243   30      9  2012           24  64  15   0.2  67.3   3.8  16.5  ...   \n",
       "\n",
       "     cos(DMC+DC)  cos(DMC+ISI)  cos(DMC+BUI)  cos(DMC+FWI)  cos(DC+ISI)  \\\n",
       "0       0.004426     -0.012389      0.869397     -0.725932    -0.865435   \n",
       "1       0.647596      0.377978     -0.145500     -0.210796    -0.678720   \n",
       "2      -0.984688     -0.942222      0.468517     -0.856889     0.438547   \n",
       "3      -0.339155      0.267499     -0.989992      0.267499     0.815725   \n",
       "4      -0.078678     -0.490261      0.815725     -0.936457    -0.952953   \n",
       "..           ...           ...           ...           ...          ...   \n",
       "239    -0.689687     -0.079564      0.086614     -0.873305     0.300593   \n",
       "240    -0.354924      0.950233      0.991085      0.976588    -0.243544   \n",
       "241     0.393491     -0.725932      0.815725     -0.848100    -0.431377   \n",
       "242     0.795815      0.960170     -0.999693      0.283662    -0.369768   \n",
       "243     0.120062      0.283662     -0.678720     -0.400799     0.408893   \n",
       "\n",
       "     cos(DC+BUI)  cos(DC+FWI)  cos(ISI+BUI)  cos(ISI+FWI)  cos(BUI+FWI)  \n",
       "0       0.004426    -0.243544     -0.012389     -0.227202     -0.725932  \n",
       "1       0.483305    -0.145500      0.186512      0.169967     -0.400799  \n",
       "2      -0.930426     0.608351     -0.989992      0.921061     -0.942222  \n",
       "3      -0.678720     0.815725     -0.128844      1.000000     -0.128844  \n",
       "4       0.731991    -0.533584      0.377978     -0.128844     -0.307333  \n",
       "..           ...          ...           ...           ...           ...  \n",
       "239     0.138497     0.742154     -0.830301      0.004426     -0.161238  \n",
       "240    -0.062792    -0.145500      0.999859      0.995004      0.996542  \n",
       "241     0.299745    -0.243544     -0.790968      0.825336     -0.896758  \n",
       "242     0.120062    -0.981618      0.869397     -0.737394      0.885520  \n",
       "243    -0.770514    -0.275163      0.960170     -0.128844      0.554374  \n",
       "\n",
       "[244 rows x 91 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_glass = pd.read_csv('datasets/Algerian_forest_fires.csv', delimiter=',')\n",
    "X = pd.read_csv('datasets/algerian_formula_a.csv', delimiter=',')\n",
    "y = LabelEncoder().fit_transform(data_glass['Classes'])\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separamos los datos en dos entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "#agregamos el metodo de seleccion \n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=10)),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selector = SelectKBest(mutual_info_classif, k=10)\n",
    "#selector.fit(X_train, y_train)\n",
    "#cols = selector.get_support(indices=True)\n",
    "#features_df = X.iloc[:,cols]\n",
    "#features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "knn_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best_model = knn_info.best_estimator_\n",
    "#yhat = best_model.predict(X_test)\n",
    "#acc = accuracy_score(y_test, yhat)\n",
    "#acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_indexes = knn_info.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "features_df_train = X.iloc[:,select_indexes]\n",
    "features_df_train\n",
    "\n",
    "x_t = X_test[features_df_train.columns.values]\n",
    "features_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cross_val_score(knn_info, X_test, y_test, cv=5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(X.columns.values)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.878, est=0.887, cfg={'selector__k': 10}\n",
      ">acc=0.918, est=0.882, cfg={'selector__k': 10}\n",
      ">acc=0.939, est=0.831, cfg={'selector__k': 10}\n",
      ">acc=0.878, est=0.897, cfg={'classifier': KNeighborsClassifier()}\n",
      ">acc=0.896, est=0.842, cfg={'classifier': KNeighborsClassifier()}\n",
      "Accuracy: 0.902 (0.024)\n",
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=10)),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "    # define search space\n",
    "    search_space = [{'selector__k': [10]}, {'classifier': [KNeighborsClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "knn_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(knn_variance, X_test, y_test, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "#select_indexes = knn_variance.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "#selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "#x_t = X_test[selected_features.columns.values]\n",
    "#x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.755, est=0.826, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.857, est=0.805, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.898, est=0.785, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.857, est=0.831, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.812, est=0.801, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      "Accuracy: 0.836 (0.049)\n",
      "Wall time: 552 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "    search_space = [{'classifier': [KNeighborsClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "knn_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "knn_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_chi.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(knn_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.878, est=0.892, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.918, est=0.892, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.939, est=0.872, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.878, est=0.903, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.896, est=0.888, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      "Accuracy: 0.902 (0.024)\n",
      "Wall time: 803 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k=10)),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [KNeighborsClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logistic_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "logistic_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cross_val_score(logistic_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.878, est=0.892, cfg={'selector__k': 10}\n",
      ">acc=0.939, est=0.903, cfg={'selector__k': 10}\n",
      ">acc=0.878, est=0.877, cfg={'classifier': LogisticRegression()}\n",
      ">acc=0.898, est=0.918, cfg={'classifier': LogisticRegression()}\n",
      ">acc=0.875, est=0.903, cfg={'selector__k': 10}\n",
      "Accuracy: 0.893 (0.024)\n",
      "Wall time: 28.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=10)),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "    # define search space\n",
    "    search_space = [{'selector__k': [10]}, {'classifier': [LogisticRegression()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logistic_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "logistic_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(logistic_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.857, est=0.867, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.959, est=0.851, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.959, est=0.846, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.816, est=0.913, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.896, est=0.883, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', LogisticRegression())])\n",
      "Accuracy: 0.898 (0.056)\n",
      "Wall time: 2.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "    search_space = [{'classifier': [LogisticRegression()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logistic_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "logistic_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(logistic_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.898, est=0.928, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.939, est=0.923, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.857, est=0.887, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.898, est=0.933, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.896, est=0.924, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', LogisticRegression())])\n",
      "Accuracy: 0.898 (0.026)\n",
      "Wall time: 1.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k=10)),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [LogisticRegression()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [SVC(kernel='linear')]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "svm_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(svm_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.837, est=0.877, cfg={'classifier': SVC(kernel='linear')}\n",
      ">acc=0.939, est=0.862, cfg={'classifier': SVC(kernel='linear')}\n",
      ">acc=0.918, est=0.846, cfg={'classifier': SVC(kernel='linear')}\n",
      ">acc=0.816, est=0.903, cfg={'selector__k': 15}\n",
      ">acc=0.875, est=0.888, cfg={'classifier': SVC(kernel='linear')}\n",
      "Accuracy: 0.877 (0.047)\n",
      "Wall time: 27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=15)),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "    # define search space\n",
    "    search_space = [{'selector__k': [15]}, {'classifier': [SVC(kernel='linear')]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "search_space = [{'classifier': [SVC(kernel='linear')]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "svm_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(svm_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.816, est=0.810, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=3)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.918, est=0.826, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=3)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.918, est=0.846, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=3)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.857, est=0.897, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=3)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.917, est=0.821, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=3)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      "Accuracy: 0.885 (0.042)\n",
      "Wall time: 2.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold(3)),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "    search_space = [{'classifier': [SVC(kernel='linear')]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', SVC(kernel='linear'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [SVC(kernel='linear')]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "svm_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "svm_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(svm_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.796, est=0.923, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(k=15,\n",
      "                             score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.939, est=0.897, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(k=15,\n",
      "                             score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.939, est=0.882, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(k=15,\n",
      "                             score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.857, est=0.913, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(k=15,\n",
      "                             score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.896, est=0.908, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(k=15,\n",
      "                             score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      "Accuracy: 0.885 (0.054)\n",
      "Wall time: 623 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k=15)),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [SVC(kernel='linear')]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', GaussianNB())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nb_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(nb_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.857, est=0.795, cfg={'classifier': GaussianNB()}\n",
      ">acc=0.816, est=0.697, cfg={'selector__k': 15}\n",
      ">acc=0.816, est=0.785, cfg={'selector__k': 15}\n",
      ">acc=0.816, est=0.841, cfg={'selector__k': 15}\n",
      ">acc=0.896, est=0.766, cfg={'selector__k': 15}\n",
      "Accuracy: 0.840 (0.032)\n",
      "Wall time: 25.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=15)),\n",
    "                 ('classifier', GaussianNB())])\n",
    "    # define search space\n",
    "    search_space = [{'selector__k': [15]}, {'classifier': [GaussianNB()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', GaussianNB())])\n",
    "\n",
    "search_space = [{'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "nb_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cross_val_score(nb_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.796, est=0.769, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=1)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.735, est=0.785, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=1)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.796, est=0.779, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=1)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.857, est=0.851, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=1)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.729, est=0.781, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=1)),\n",
      "                ('classifier', GaussianNB())])\n",
      "Accuracy: 0.783 (0.047)\n",
      "Wall time: 375 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', GaussianNB())])\n",
    "\n",
    "    search_space = [{'classifier': [GaussianNB()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nb_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(nb_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.816, est=0.841, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.816, est=0.841, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.837, est=0.805, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.857, est=0.851, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.917, est=0.802, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', GaussianNB())])\n",
      "Accuracy: 0.849 (0.037)\n",
      "Wall time: 513 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k=10)),\n",
    "                 ('classifier', GaussianNB())])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [GaussianNB()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', RandomForestRegressor())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [RandomForestRegressor()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nb_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cross_val_score(nb_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', RandomForestRegressor())])\n",
    "\n",
    "    search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [RandomForestRegressor()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = RandomForestRegressor()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', VarianceThreshold(0.1)),\n",
    "                 ('classifier', RandomForestRegressor())])\n",
    "\n",
    "search_space = [{'classifier': [RandomForestRegressor()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "nb_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cross_val_score(nb_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1046\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1048\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1049\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    864\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 866\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    867\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    782\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mfit_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0mtest_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[0mscore_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mfit_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[0;32m    605\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     error_msg = (\"scoring must return a number, got %s (%s) \"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scorers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_BaseScorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m                 score = scorer._score(cached_call, estimator,\n\u001b[0m\u001b[0;32m     88\u001b[0m                                       *args, **kwargs)\n\u001b[0;32m     89\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001b[0m\n\u001b[0;32m    210\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    211\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m             return self._sign * self._score_func(y_true, y_pred,\n\u001b[0m\u001b[0;32m    213\u001b[0m                                                  **self._kwargs)\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', RandomForestRegressor())])\n",
    "\n",
    "    search_space = [{'classifier': [RandomForestRegressor()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = RandomForestRegressor()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', RandomForestRegressor())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [RandomForestRegressor()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.23 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
       "                                       ('classifier',\n",
       "                                        RandomForestRegressor())]),\n",
       "             param_grid=[{'classifier': [RandomForestRegressor()]}])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nb_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8381326475228967\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(nb_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[0;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and continuous targets"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', RandomForestRegressor())])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [RandomForestRegressor()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = RandomForestRegressor()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7916666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [MLPClassifier()]}]\n",
    "\n",
    "nb_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_info.fit(X_train, y_train)\n",
    "\n",
    "print(cross_val_score(nb_info, X, y, cv=10).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.857, est=0.908, cfg={'classifier': MLPClassifier()}\n",
      ">acc=0.918, est=0.887, cfg={'selector__k': 10}\n",
      ">acc=0.898, est=0.882, cfg={'selector__k': 10}\n",
      ">acc=0.878, est=0.908, cfg={'classifier': MLPClassifier()}\n",
      ">acc=0.854, est=0.893, cfg={'selector__k': 10}\n",
      "Accuracy: 0.881 (0.024)\n",
      "Wall time: 52.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=10)),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "    # define search space\n",
    "    search_space = [{'selector__k': [10]}, {'classifier': [MLPClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = MLPClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Variance threshold\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', VarianceThreshold()),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "\n",
    "search_space = [{'classifier': [MLPClassifier()]}]\n",
    "\n",
    "nb_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "nb_variance.fit(X_train, y_train)\n",
    "\n",
    "print(cross_val_score(nb_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.857, est=0.836, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.878, est=0.815, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.837, est=0.821, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.776, est=0.846, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.792, est=0.811, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', MLPClassifier())])\n",
      "Accuracy: 0.828 (0.039)\n",
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "\n",
    "    search_space = [{'classifier': [MLPClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = MLPClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Chi-Square\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "\n",
    "search_space = [{'classifier': [MLPClassifier()]}]\n",
    "\n",
    "nb_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_chi.fit(X_train, y_train)\n",
    "\n",
    "print(cross_val_score(nb_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.857, est=0.897, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.959, est=0.908, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.898, est=0.877, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.857, est=0.913, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.917, est=0.908, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000001EEBC8F0F70>)),\n",
      "                ('classifier', MLPClassifier())])\n",
      "Accuracy: 0.898 (0.039)\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k=10)),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [MLPClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = MLPClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
