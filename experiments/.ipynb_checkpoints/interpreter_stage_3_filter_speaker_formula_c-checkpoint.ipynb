{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Execute imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "data_glass = pd.read_csv('datasets/accent-mfcc-data-1.csv', delimiter=',')\n",
    "X = pd.read_csv('datasets/speaker_formula_c.csv', delimiter=',')\n",
    "y = LabelEncoder().fit_transform(data_glass['language'])\n",
    "features = list(X.columns.values)\n",
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000002C1061A8AF0>)),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [KNeighborsClassifier()]}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "knn_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "knn_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7297348484848485\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(knn_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.803, est=0.640\n",
      ">acc=0.742, est=0.673\n",
      ">acc=0.697, est=0.612\n",
      ">acc=0.803, est=0.597\n",
      ">acc=0.769, est=0.644\n",
      "Accuracy: 0.763 (0.040)\n",
      "Wall time: 44.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "    # define search space\n",
    "    search_space = [{'selector__k': ['all']}, {'classifier': [KNeighborsClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    # get the best performing model fit on the whole training set\n",
    "    best_model = result.best_estimator_\n",
    "    # evaluate model on the hold out dataset\n",
    "    yhat = best_model.predict(X_test)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, yhat)\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f' % (acc, result.best_score_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(outer_results), std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 127 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             param_grid=[{'classifier': [KNeighborsClassifier()]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "knn_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "knn_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7418560606060607\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(knn_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.773, est=0.658, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.758, est=0.662, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.727, est=0.639, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.833, est=0.612, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.785, est=0.640, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      "Accuracy: 0.775 (0.035)\n",
      "Wall time: 586 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "    search_space = [{'classifier': [KNeighborsClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 140 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000002C105F70F70>)),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             param_grid=[{'classifier': [KNeighborsClassifier()]}])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "knn_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "knn_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7206439393939394\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(knn_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.682, est=0.582, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.636, est=0.551, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.682, est=0.517, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.606, est=0.566, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      ">acc=0.692, est=0.553, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', KNeighborsClassifier())])\n",
      "Accuracy: 0.660 (0.033)\n",
      "Wall time: 755 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k=10)),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [KNeighborsClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = KNeighborsClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.96 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000002C1061A8AF0>)),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [LogisticRegression()]}])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "logistic_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7203598484848486\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(logistic_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.652, est=0.579, cfg={'selector__k': 10}\n",
      ">acc=0.667, est=0.547, cfg={'selector__k': 10}\n",
      ">acc=0.515, est=0.564, cfg={'selector__k': 10}\n",
      ">acc=0.682, est=0.582, cfg={'selector__k': 10}\n",
      ">acc=0.615, est=0.542, cfg={'selector__k': 10}\n",
      "Accuracy: 0.626 (0.060)\n",
      "Wall time: 48.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=10)),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "    # define search space\n",
    "    search_space = [{'selector__k': [10]}, {'classifier': [LogisticRegression()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 390 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'classifier': [LogisticRegression()]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "logistic_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6442234848484849\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(logistic_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.788, est=0.631, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.788, est=0.615, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.682, est=0.658, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.833, est=0.669, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.769, est=0.614, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', LogisticRegression())])\n",
      "Accuracy: 0.772 (0.050)\n",
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "    search_space = [{'classifier': [LogisticRegression()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 368 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000002C105F70F70>)),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'classifier': [LogisticRegression()]}])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "logistic_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.669034090909091\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(logistic_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.682, est=0.559, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.636, est=0.563, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.545, est=0.586, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.621, est=0.567, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', LogisticRegression())])\n",
      ">acc=0.677, est=0.565, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', LogisticRegression())])\n",
      "Accuracy: 0.632 (0.049)\n",
      "Wall time: 1.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k=10)),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [LogisticRegression()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [SVC(kernel='linear')]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000002C1061A8AF0>)),\n",
       "                                       ('classifier', SVC(kernel='linear'))]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [SVC(kernel='linear')]}])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "svm_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65625\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(svm_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.712, est=0.575, cfg={'selector__k': 9}\n",
      ">acc=0.652, est=0.574, cfg={'selector__k': 9}\n",
      ">acc=0.515, est=0.571, cfg={'selector__k': 9}\n",
      ">acc=0.667, est=0.560, cfg={'selector__k': 9}\n",
      ">acc=0.600, est=0.538, cfg={'selector__k': 9}\n",
      "Accuracy: 0.629 (0.067)\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=9)),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "    # define search space\n",
    "    search_space = [{'selector__k': [9]}, {'classifier': [SVC(kernel='linear')]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "search_space = [{'classifier': [SVC(kernel='linear')]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 234 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', SVC(kernel='linear'))]),\n",
       "             param_grid=[{'classifier': [SVC(kernel='linear')]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "svm_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6170454545454546\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(svm_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.697, est=0.597, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=3)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.803, est=0.600, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=3)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.742, est=0.597, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=3)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.758, est=0.566, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=3)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.769, est=0.512, cfg=Pipeline(steps=[('selector', VarianceThreshold(threshold=3)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      "Accuracy: 0.754 (0.035)\n",
      "Wall time: 742 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold(3)),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "    search_space = [{'classifier': [SVC(kernel='linear')]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [SVC()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 124 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000002C105F70F70>)),\n",
       "                                       ('classifier', SVC())]),\n",
       "             param_grid=[{'classifier': [SVC()]}])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "svm_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7205492424242423\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(svm_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.667, est=0.559, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.682, est=0.555, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.682, est=0.559, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.652, est=0.552, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      ">acc=0.708, est=0.557, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', SVC(kernel='linear'))])\n",
      "Accuracy: 0.678 (0.019)\n",
      "Wall time: 6.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k=10)),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [SVC(kernel='linear')]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = SVC(kernel='linear')\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', GaussianNB())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000002C1061A8AF0>)),\n",
       "                                       ('classifier', GaussianNB())]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [GaussianNB()]}])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nb_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5295454545454545\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(nb_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.470, est=0.426, cfg={'selector__k': 10}\n",
      ">acc=0.530, est=0.445, cfg={'selector__k': 10}\n",
      ">acc=0.409, est=0.460, cfg={'selector__k': 10}\n",
      ">acc=0.439, est=0.411, cfg={'selector__k': 10}\n",
      ">acc=0.446, est=0.390, cfg={'selector__k': 10}\n",
      "Accuracy: 0.459 (0.041)\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=10)),\n",
    "                 ('classifier', GaussianNB())])\n",
    "    # define search space\n",
    "    search_space = [{'selector__k': [10]}, {'classifier': [GaussianNB()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', GaussianNB())])\n",
    "\n",
    "search_space = [{'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', GaussianNB())]),\n",
       "             param_grid=[{'classifier': [GaussianNB()]}], scoring='accuracy')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "nb_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5295454545454545\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(nb_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.606, est=0.510, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.545, est=0.525, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.470, est=0.536, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.636, est=0.456, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.569, est=0.485, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', GaussianNB())])\n",
      "Accuracy: 0.565 (0.057)\n",
      "Wall time: 370 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', GaussianNB())])\n",
    "\n",
    "    search_space = [{'classifier': [GaussianNB()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 111 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000002C105F70F70>)),\n",
       "                                       ('classifier', GaussianNB())]),\n",
       "             param_grid=[{'classifier': [GaussianNB()]}])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nb_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5295454545454545\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(nb_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.439, est=0.430, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.591, est=0.460, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.409, est=0.449, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.439, est=0.468, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', GaussianNB())])\n",
      ">acc=0.492, est=0.470, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', GaussianNB())])\n",
      "Accuracy: 0.474 (0.064)\n",
      "Wall time: 636 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k=10)),\n",
    "                 ('classifier', GaussianNB())])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [GaussianNB()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = GaussianNB()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest -> Information gain\n",
      "-24.27688190655531\n",
      "Random Forest -> Chi-Square\n",
      "-22.824261936290092\n",
      "MLPClassifier -> Info\n",
      "0.7298295454545455\n",
      "MLPClassifier -> Variance\n",
      "0.6569128787878789\n",
      "MLPClassifier -> Chi\n",
      "0.6660984848484849\n"
     ]
    }
   ],
   "source": [
    "## Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "### Information gain\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', RandomForestRegressor())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [RandomForestRegressor()]}]\n",
    "\n",
    "nb_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_info.fit(X_train, y_train)\n",
    "print('Random Forest -> Information gain')\n",
    "print(cross_val_score(nb_info, X, y, cv=10).mean())\n",
    "\n",
    "### Chi-Square\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', RandomForestRegressor())])\n",
    "\n",
    "search_space = [{'classifier': [RandomForestRegressor()]}]\n",
    "\n",
    "nb_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_chi.fit(X_train, y_train)\n",
    "\n",
    "print('Random Forest -> Chi-Square')\n",
    "print(cross_val_score(nb_chi, X, y, cv=10).mean())\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [MLPClassifier()]}]\n",
    "\n",
    "nb_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_info.fit(X_train, y_train)\n",
    "\n",
    "print('MLPClassifier -> Info')\n",
    "print(cross_val_score(nb_info, X, y, cv=10).mean())\n",
    "\n",
    "### Variance threshold\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', VarianceThreshold()),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "\n",
    "search_space = [{'classifier': [MLPClassifier()]}]\n",
    "\n",
    "nb_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "nb_variance.fit(X_train, y_train)\n",
    "\n",
    "print('MLPClassifier -> Variance')\n",
    "print(cross_val_score(nb_variance, X, y, cv=10).mean())\n",
    "\n",
    "\n",
    "### Chi-Square\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "\n",
    "search_space = [{'classifier': [MLPClassifier()]}]\n",
    "\n",
    "nb_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_chi.fit(X_train, y_train)\n",
    "\n",
    "print('MLPClassifier -> Chi')\n",
    "print(cross_val_score(nb_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.636, est=0.586, cfg={'classifier': MLPClassifier()}\n",
      ">acc=0.727, est=0.585, cfg={'classifier': MLPClassifier()}\n",
      ">acc=0.530, est=0.613, cfg={'classifier': MLPClassifier()}\n",
      ">acc=0.697, est=0.605, cfg={'classifier': MLPClassifier()}\n",
      ">acc=0.585, est=0.576, cfg={'classifier': MLPClassifier()}\n",
      "Accuracy: 0.635 (0.072)\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k=10)),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "    # define search space\n",
    "    search_space = [{'selector__k': [10]}, {'classifier': [MLPClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = MLPClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_params_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.667, est=0.563, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.788, est=0.555, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.788, est=0.673, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.773, est=0.608, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.785, est=0.569, cfg=Pipeline(steps=[('selector', VarianceThreshold()),\n",
      "                ('classifier', MLPClassifier())])\n",
      "Accuracy: 0.760 (0.047)\n",
      "Wall time: 14.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix].loc[:, features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "\n",
    "    search_space = [{'classifier': [MLPClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    select_indexes = np.arange(len(X_train.columns)).reshape(1, -1)\n",
    "    select_indexes = result.best_estimator_.named_steps['selector'].transform(select_indexes)\n",
    "    selected_features = X.iloc[:,select_indexes.reshape(-1)]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = MLPClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">acc=0.636, est=0.567, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.682, est=0.567, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.591, est=0.570, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.621, est=0.548, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', MLPClassifier())])\n",
      ">acc=0.723, est=0.561, cfg=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
      "                ('selector',\n",
      "                 SelectKBest(score_func=<function chi2 at 0x000002C105F70F70>)),\n",
      "                ('classifier', MLPClassifier())])\n",
      "Accuracy: 0.651 (0.047)\n",
      "Wall time: 16.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = list(X.columns.values)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# enumerate splits\n",
    "outer_results = list()\n",
    "for train_ix, test_ix in kf.split(X):\n",
    "    # split data\n",
    "    X_train, X_test = X.iloc[train_ix][features], X.iloc[test_ix][features]\n",
    "    y_train, y_test = y.iloc[train_ix], y.iloc[test_ix]\n",
    "    # define the model\n",
    "    pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k=10)),\n",
    "                 ('classifier', MLPClassifier())])\n",
    "    # define search space\n",
    "    search_space = [{'classifier': [MLPClassifier()]}]\n",
    "    # define search\n",
    "    _info = GridSearchCV(pipe, search_space, scoring='accuracy', cv=None, refit=True)\n",
    "    # execute search\n",
    "    result = _info.fit(X_train, y_train)\n",
    "    \n",
    "    selected = result.best_estimator_.named_steps['selector'].get_support(indices=True)\n",
    "    selected_features = X.iloc[:,selected]\n",
    "    x_t = X_test[selected_features.columns.values]\n",
    "    \n",
    "    clf = MLPClassifier()\n",
    "    clf.fit(X_train[selected_features.columns.values], y_train)\n",
    "    # evaluate the model\n",
    "    acc = accuracy_score(y_test, clf.predict(x_t))\n",
    "    # store the result\n",
    "    outer_results.append(acc)\n",
    "    # report progress\n",
    "    print('>acc=%.3f, est=%.3f, cfg=%s' % (acc, result.best_score_, result.best_estimator_))\n",
    "# summarize the estimated performance of the model\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(outer_results), np.std(outer_results)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
