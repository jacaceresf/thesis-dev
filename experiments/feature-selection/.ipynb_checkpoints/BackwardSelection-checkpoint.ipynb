{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "021956aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def8b9eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>cos(X8+X9)</th>\n",
       "      <th>cos(X8+X10)</th>\n",
       "      <th>cos(X8+X11)</th>\n",
       "      <th>cos(X8+X12)</th>\n",
       "      <th>cos(X9+X10)</th>\n",
       "      <th>cos(X9+X11)</th>\n",
       "      <th>cos(X9+X12)</th>\n",
       "      <th>cos(X10+X11)</th>\n",
       "      <th>cos(X10+X12)</th>\n",
       "      <th>cos(X11+X12)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.071476</td>\n",
       "      <td>-6.512900</td>\n",
       "      <td>7.650800</td>\n",
       "      <td>11.150783</td>\n",
       "      <td>-7.657312</td>\n",
       "      <td>12.484021</td>\n",
       "      <td>-11.709772</td>\n",
       "      <td>3.426596</td>\n",
       "      <td>1.462715</td>\n",
       "      <td>-2.812753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176001</td>\n",
       "      <td>0.817440</td>\n",
       "      <td>-0.407080</td>\n",
       "      <td>-0.244381</td>\n",
       "      <td>0.218970</td>\n",
       "      <td>-0.687802</td>\n",
       "      <td>-0.802116</td>\n",
       "      <td>-0.366662</td>\n",
       "      <td>-0.201653</td>\n",
       "      <td>-0.328441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.982967</td>\n",
       "      <td>-5.157445</td>\n",
       "      <td>3.952060</td>\n",
       "      <td>11.529381</td>\n",
       "      <td>-7.638047</td>\n",
       "      <td>12.136098</td>\n",
       "      <td>-12.036247</td>\n",
       "      <td>3.491943</td>\n",
       "      <td>0.595441</td>\n",
       "      <td>-4.508811</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.585102</td>\n",
       "      <td>0.526032</td>\n",
       "      <td>0.896454</td>\n",
       "      <td>-0.916451</td>\n",
       "      <td>-0.716672</td>\n",
       "      <td>-0.977188</td>\n",
       "      <td>0.791969</td>\n",
       "      <td>-0.569476</td>\n",
       "      <td>-0.261818</td>\n",
       "      <td>-0.732971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.827108</td>\n",
       "      <td>-5.477472</td>\n",
       "      <td>7.816257</td>\n",
       "      <td>9.187592</td>\n",
       "      <td>-7.172511</td>\n",
       "      <td>11.715299</td>\n",
       "      <td>-13.847214</td>\n",
       "      <td>4.574075</td>\n",
       "      <td>-1.687559</td>\n",
       "      <td>-7.204041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.967644</td>\n",
       "      <td>-0.871949</td>\n",
       "      <td>-0.149597</td>\n",
       "      <td>-0.312927</td>\n",
       "      <td>-0.861196</td>\n",
       "      <td>-0.128256</td>\n",
       "      <td>-0.292387</td>\n",
       "      <td>0.595666</td>\n",
       "      <td>0.452871</td>\n",
       "      <td>0.981662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.744083</td>\n",
       "      <td>-5.688920</td>\n",
       "      <td>6.546789</td>\n",
       "      <td>9.000183</td>\n",
       "      <td>-6.924963</td>\n",
       "      <td>11.710766</td>\n",
       "      <td>-12.374388</td>\n",
       "      <td>6.169879</td>\n",
       "      <td>-0.544747</td>\n",
       "      <td>-6.019237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791184</td>\n",
       "      <td>0.988675</td>\n",
       "      <td>0.319824</td>\n",
       "      <td>0.982648</td>\n",
       "      <td>0.960835</td>\n",
       "      <td>0.686732</td>\n",
       "      <td>0.815037</td>\n",
       "      <td>-0.051688</td>\n",
       "      <td>0.981873</td>\n",
       "      <td>0.281630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.836843</td>\n",
       "      <td>-5.326557</td>\n",
       "      <td>7.472265</td>\n",
       "      <td>8.847440</td>\n",
       "      <td>-6.773244</td>\n",
       "      <td>12.677218</td>\n",
       "      <td>-12.315061</td>\n",
       "      <td>4.416344</td>\n",
       "      <td>0.193500</td>\n",
       "      <td>-3.644812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.102365</td>\n",
       "      <td>0.716843</td>\n",
       "      <td>0.959831</td>\n",
       "      <td>-0.737371</td>\n",
       "      <td>-0.952419</td>\n",
       "      <td>-0.698960</td>\n",
       "      <td>0.942880</td>\n",
       "      <td>0.077146</td>\n",
       "      <td>-0.509370</td>\n",
       "      <td>-0.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>-0.525273</td>\n",
       "      <td>-3.868338</td>\n",
       "      <td>3.548304</td>\n",
       "      <td>1.496249</td>\n",
       "      <td>3.490753</td>\n",
       "      <td>5.849887</td>\n",
       "      <td>-7.747027</td>\n",
       "      <td>9.738836</td>\n",
       "      <td>-11.754543</td>\n",
       "      <td>7.129909</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.430378</td>\n",
       "      <td>-0.398622</td>\n",
       "      <td>-0.865822</td>\n",
       "      <td>0.062020</td>\n",
       "      <td>-0.087642</td>\n",
       "      <td>0.521853</td>\n",
       "      <td>0.422054</td>\n",
       "      <td>0.491774</td>\n",
       "      <td>0.453427</td>\n",
       "      <td>-0.165407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>-2.094001</td>\n",
       "      <td>-1.073113</td>\n",
       "      <td>1.217397</td>\n",
       "      <td>-0.550790</td>\n",
       "      <td>2.666547</td>\n",
       "      <td>7.449942</td>\n",
       "      <td>-6.418064</td>\n",
       "      <td>10.907098</td>\n",
       "      <td>-11.134323</td>\n",
       "      <td>6.728373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974295</td>\n",
       "      <td>0.349195</td>\n",
       "      <td>0.695146</td>\n",
       "      <td>-0.114339</td>\n",
       "      <td>-0.301666</td>\n",
       "      <td>-0.730392</td>\n",
       "      <td>0.164116</td>\n",
       "      <td>-0.972524</td>\n",
       "      <td>0.913466</td>\n",
       "      <td>-0.760794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>2.116909</td>\n",
       "      <td>-4.441482</td>\n",
       "      <td>5.350392</td>\n",
       "      <td>3.675396</td>\n",
       "      <td>2.715876</td>\n",
       "      <td>3.682670</td>\n",
       "      <td>-4.500850</td>\n",
       "      <td>11.798565</td>\n",
       "      <td>-12.031005</td>\n",
       "      <td>7.566142</td>\n",
       "      <td>...</td>\n",
       "      <td>0.973107</td>\n",
       "      <td>0.870218</td>\n",
       "      <td>0.195709</td>\n",
       "      <td>-0.991735</td>\n",
       "      <td>-0.245006</td>\n",
       "      <td>0.997506</td>\n",
       "      <td>-0.138520</td>\n",
       "      <td>0.779489</td>\n",
       "      <td>0.571739</td>\n",
       "      <td>-0.958114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.299616</td>\n",
       "      <td>0.324844</td>\n",
       "      <td>3.299919</td>\n",
       "      <td>2.044040</td>\n",
       "      <td>3.634828</td>\n",
       "      <td>6.693840</td>\n",
       "      <td>-5.676224</td>\n",
       "      <td>12.000518</td>\n",
       "      <td>-11.912901</td>\n",
       "      <td>4.664406</td>\n",
       "      <td>...</td>\n",
       "      <td>0.996164</td>\n",
       "      <td>-0.576007</td>\n",
       "      <td>0.806885</td>\n",
       "      <td>-0.940918</td>\n",
       "      <td>0.569162</td>\n",
       "      <td>-0.276800</td>\n",
       "      <td>-0.006010</td>\n",
       "      <td>0.912685</td>\n",
       "      <td>-0.760014</td>\n",
       "      <td>0.512686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>3.214254</td>\n",
       "      <td>-3.135152</td>\n",
       "      <td>1.122691</td>\n",
       "      <td>4.712444</td>\n",
       "      <td>5.926518</td>\n",
       "      <td>6.915566</td>\n",
       "      <td>-5.799727</td>\n",
       "      <td>10.858532</td>\n",
       "      <td>-11.659845</td>\n",
       "      <td>10.605734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695764</td>\n",
       "      <td>-0.864379</td>\n",
       "      <td>0.210846</td>\n",
       "      <td>0.162143</td>\n",
       "      <td>0.494001</td>\n",
       "      <td>0.309615</td>\n",
       "      <td>0.356357</td>\n",
       "      <td>-0.040347</td>\n",
       "      <td>-0.089815</td>\n",
       "      <td>0.796455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            X1        X2        X3         X4        X5         X6         X7  \\\n",
       "0     7.071476 -6.512900  7.650800  11.150783 -7.657312  12.484021 -11.709772   \n",
       "1    10.982967 -5.157445  3.952060  11.529381 -7.638047  12.136098 -12.036247   \n",
       "2     7.827108 -5.477472  7.816257   9.187592 -7.172511  11.715299 -13.847214   \n",
       "3     6.744083 -5.688920  6.546789   9.000183 -6.924963  11.710766 -12.374388   \n",
       "4     5.836843 -5.326557  7.472265   8.847440 -6.773244  12.677218 -12.315061   \n",
       "..         ...       ...       ...        ...       ...        ...        ...   \n",
       "324  -0.525273 -3.868338  3.548304   1.496249  3.490753   5.849887  -7.747027   \n",
       "325  -2.094001 -1.073113  1.217397  -0.550790  2.666547   7.449942  -6.418064   \n",
       "326   2.116909 -4.441482  5.350392   3.675396  2.715876   3.682670  -4.500850   \n",
       "327   0.299616  0.324844  3.299919   2.044040  3.634828   6.693840  -5.676224   \n",
       "328   3.214254 -3.135152  1.122691   4.712444  5.926518   6.915566  -5.799727   \n",
       "\n",
       "            X8         X9        X10  ...  cos(X8+X9)  cos(X8+X10)  \\\n",
       "0     3.426596   1.462715  -2.812753  ...    0.176001     0.817440   \n",
       "1     3.491943   0.595441  -4.508811  ...   -0.585102     0.526032   \n",
       "2     4.574075  -1.687559  -7.204041  ...   -0.967644    -0.871949   \n",
       "3     6.169879  -0.544747  -6.019237  ...    0.791184     0.988675   \n",
       "4     4.416344   0.193500  -3.644812  ...   -0.102365     0.716843   \n",
       "..         ...        ...        ...  ...         ...          ...   \n",
       "324   9.738836 -11.754543   7.129909  ...   -0.430378    -0.398622   \n",
       "325  10.907098 -11.134323   6.728373  ...    0.974295     0.349195   \n",
       "326  11.798565 -12.031005   7.566142  ...    0.973107     0.870218   \n",
       "327  12.000518 -11.912901   4.664406  ...    0.996164    -0.576007   \n",
       "328  10.858532 -11.659845  10.605734  ...    0.695764    -0.864379   \n",
       "\n",
       "     cos(X8+X11)  cos(X8+X12)  cos(X9+X10)  cos(X9+X11)  cos(X9+X12)  \\\n",
       "0      -0.407080    -0.244381     0.218970    -0.687802    -0.802116   \n",
       "1       0.896454    -0.916451    -0.716672    -0.977188     0.791969   \n",
       "2      -0.149597    -0.312927    -0.861196    -0.128256    -0.292387   \n",
       "3       0.319824     0.982648     0.960835     0.686732     0.815037   \n",
       "4       0.959831    -0.737371    -0.952419    -0.698960     0.942880   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "324    -0.865822     0.062020    -0.087642     0.521853     0.422054   \n",
       "325     0.695146    -0.114339    -0.301666    -0.730392     0.164116   \n",
       "326     0.195709    -0.991735    -0.245006     0.997506    -0.138520   \n",
       "327     0.806885    -0.940918     0.569162    -0.276800    -0.006010   \n",
       "328     0.210846     0.162143     0.494001     0.309615     0.356357   \n",
       "\n",
       "     cos(X10+X11)  cos(X10+X12)  cos(X11+X12)  \n",
       "0       -0.366662     -0.201653     -0.328441  \n",
       "1       -0.569476     -0.261818     -0.732971  \n",
       "2        0.595666      0.452871      0.981662  \n",
       "3       -0.051688      0.981873      0.281630  \n",
       "4        0.077146     -0.509370     -0.047300  \n",
       "..            ...           ...           ...  \n",
       "324      0.491774      0.453427     -0.165407  \n",
       "325     -0.972524      0.913466     -0.760794  \n",
       "326      0.779489      0.571739     -0.958114  \n",
       "327      0.912685     -0.760014      0.512686  \n",
       "328     -0.040347     -0.089815      0.796455  \n",
       "\n",
       "[329 rows x 78 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.read_csv('../datasets/speaker_formula_a.csv')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ab54292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../datasets/winequality-white.csv', sep=';')\n",
    "df = pd.read_csv('../datasets/accent-mfcc-data-1.csv')\n",
    "# df = pd.read_csv(\"https://raw.githubusercontent.com/SahilSinhaLpu/Machine-Learning/master/Datasets/SomvervilleHappines.csv\")\n",
    "df\n",
    "\n",
    "### Speaker DS\n",
    "Y = df['language']\n",
    "\n",
    "### Algerian DS\n",
    "# Y = df['Classes']\n",
    "\n",
    "### Banknote DS\n",
    "# Y = df['Class']\n",
    "\n",
    "### User knowledge DS\n",
    "# Y = df['UNS']\n",
    "\n",
    "## Wine quality DS\n",
    "# Y = df['quality']\n",
    "\n",
    "### Somerville DS\n",
    "# Y = df['D']\n",
    "\n",
    "## Pima Indians Diabetes DS\n",
    "# Y = df['Outcome']\n",
    "# Y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e28b176",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "bdde0163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5127577117803643\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "plain_sbs = SFS(knn, \n",
    "          k_features=(1, 10), \n",
    "          forward=False,\n",
    "          floating=False, \n",
    "          scoring='accuracy',\n",
    "          cv=10,\n",
    "          n_jobs=-1)\n",
    "\n",
    "plain_sbs.fit(X_train, y_train, custom_feature_names=X.columns)\n",
    "\n",
    "selected_features = X.columns[list(plain_sbs.k_feature_idx_)]\n",
    "\n",
    "x_t = X_train[selected_features]\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(x_t, y_train)\n",
    "print(cross_val_score(clf, x_t, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3beba8d",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "616bb95b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialFeatureSelector(cv=10, estimator=GaussianNB(), forward=False,\n",
       "                          k_features=(1, 10), scoring='accuracy')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sequential Backward Selection\n",
    "gnb = GaussianNB()\n",
    "\n",
    "nb_sbs = SFS(gnb, \n",
    "          k_features=(1, 10), \n",
    "          forward=False, \n",
    "          floating=False, \n",
    "          scoring='accuracy',\n",
    "          cv=10)\n",
    "\n",
    "nb_sbs.fit(X_train, y_train, custom_feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "bc0c5cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5216875880787099\n"
     ]
    }
   ],
   "source": [
    "selected_features = X.columns[list(nb_sbs.k_feature_idx_)]\n",
    "x_nb = X_train[selected_features]\n",
    "\n",
    "gnb_ = GaussianNB()\n",
    "gnb_.fit(x_nb, y_train)\n",
    "print(cross_val_score(gnb_, x_nb, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f39f134",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "680f17eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "STOPPING EARLY DUE TO KEYBOARD INTERRUPT..."
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-302bc50a7a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m           cv=10) # -1 means ALL CPU\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0msvm_sbs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_feature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/mlxtend/feature_selection/sequential_feature_selector.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, custom_feature_names, groups, **fit_params)\u001b[0m\n\u001b[1;32m    566\u001b[0m                     \u001b[0mbest_subset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0mk_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m             \u001b[0mk_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubsets_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'feature_idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_features\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'parsimonious'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "# Sequential Backward Selection\n",
    "svm_sbs = SFS(svm.SVC(), \n",
    "          k_features=(1, 10), \n",
    "          forward=False, \n",
    "          floating=False, \n",
    "          scoring='accuracy',\n",
    "          cv=10) # -1 means ALL CPU\n",
    "\n",
    "svm_sbs.fit(X, Y, custom_feature_names=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83843ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = X.columns[list(svm_sbs.k_feature_idx_)]\n",
    "x_lr = X_train[selected_features]\n",
    "svm_clf = svm.SVC()\n",
    "svm_clf.fit(x_lr, y_train)\n",
    "print(cross_val_score(svm_clf, x_lr, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd881e70",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Sequential Backward Selection\n",
    "lr_sbs = SFS(LogisticRegression(), \n",
    "          k_features=(1, 10), \n",
    "          forward=False, \n",
    "          floating=False, \n",
    "          scoring='accuracy',\n",
    "          cv=10) # -1 means ALL CPU\n",
    "\n",
    "lr_sbs.fit(X, Y, custom_feature_names=X.columns)\n",
    "\n",
    "selected_features = X.columns[list(lr_sbs.k_feature_idx_)]\n",
    "x_lr = X_train[selected_features]\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_lr, y_train)\n",
    "print(cross_val_score(lr, x_lr, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65014740",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91aa5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Backward Selection\n",
    "rfc_sbs = SFS(RandomForestClassifier(random_state=0), \n",
    "          k_features=(1, 10), \n",
    "          forward=False, \n",
    "          floating=False, \n",
    "          scoring='accuracy',\n",
    "          cv=10) # -1 means ALL CPU\n",
    "\n",
    "rfc_sbs.fit(X, Y, custom_feature_names=X.columns)\n",
    "\n",
    "selected_features = X.columns[list(rfc_sbs.k_feature_idx_)]\n",
    "x_lr = X_train[selected_features]\n",
    "rfc_ = RandomForestClassifier(random_state=0)\n",
    "rfc_.fit(x_lr, y_train)\n",
    "print(cross_val_score(rfc_, x_lr, y_train, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172c5e72",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3de3aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Backward Selection\n",
    "mlp_sbs = SFS(MLPClassifier(random_state=1), \n",
    "          k_features=(1, 10), \n",
    "          forward=False, \n",
    "          floating=False, \n",
    "          scoring='accuracy',\n",
    "          cv=10) # -1 means ALL CPU\n",
    "\n",
    "mlp_sbs.fit(X, Y, custom_feature_names=X.columns)\n",
    "\n",
    "selected_features = X.columns[list(mlp_sbs.k_feature_idx_)]\n",
    "x_lr = X_train[selected_features]\n",
    "mlp_ = MLPClassifier(random_state=1)\n",
    "mlp_.fit(x_lr, y_train)\n",
    "print(cross_val_score(mlp_, x_lr, y_train, cv=10).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
