{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f330d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "#Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ea5eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import ModelDesc, dmatrices, dmatrix, demo_data\n",
    "import re\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "# TODO: add more complex operations from numpy\n",
    "COMPLEX_OPERATIONS = {\n",
    "    'cos': 'np.cos',\n",
    "    'tan': 'np.tan',\n",
    "    'log': 'np.log',\n",
    "    'log10': 'np.log10',\n",
    "    'log2': 'np.log2',\n",
    "    'min': 'np.min',\n",
    "    'max': 'np.max',\n",
    "    'pi': 'np.pi'\n",
    "}\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "def clean_column_symbols(column_, df, result):\n",
    "    df[column_.replace('np.cos', '_COZ_')\n",
    "       .replace(')', 'PAR_C')\n",
    "       .replace('(', 'PAR_O')\n",
    "       .replace('np.min', '_MINIM_')\n",
    "       .replace('np.max', '_MAXIM_')\n",
    "       .replace('np.pi', '_PII_')\n",
    "       .replace('**', '_POW_')\n",
    "       .replace('+', '_PLUS_')\n",
    "       .replace('*', '_TIMES_')\n",
    "       .replace('-', '_MINUS_')\n",
    "      .replace('/', '_DIV_')] = result\n",
    "    \n",
    "def add_blank_spaces_to_formula(formula: str) -> str:\n",
    "    new = ''\n",
    "    for index, element in enumerate(formula):\n",
    "        next_idx = index + 1\n",
    "        if next_idx < len(formula):\n",
    "            if not re.match('\\w', formula[index+1]):\n",
    "                new += element + ' '\n",
    "            else:\n",
    "                new += element\n",
    "        else:\n",
    "            new += element + ' '\n",
    "    return new\n",
    "\n",
    "def matched_words(s, pat):\n",
    "    pat = r'(\\w*%s\\w*)' % pat       # Not thrilled about this line\n",
    "    return re.findall(pat, s)\n",
    "\n",
    "def clean_formula(formula: str) -> str:\n",
    "    result = formula\n",
    "    for operation in COMPLEX_OPERATIONS:\n",
    "        if(operation in formula):\n",
    "            result = result.replace(operation, \"\")\n",
    "    return result\n",
    "\n",
    "def get_formula_variables(formula: str):\n",
    "  '''\n",
    "  Returns a list of every variable (non repeated) from the formula\n",
    "  '''\n",
    "  cleaned_formula = clean_formula(formula)\n",
    "  return sorted(list(set(\"\".join(re.findall(\"[a-zA-Z]+\", cleaned_formula)))))\n",
    "\n",
    "def group_columns(formula: str, data: pd.DataFrame):\n",
    "  # get number of variables inside formula\n",
    "  # convert string to set that only holds unique elements\n",
    "  characters = get_formula_variables(formula=formula)\n",
    "\n",
    "  # get dataset number of columns\n",
    "  columns = len(data.columns)\n",
    "  columns_lst = list(data.columns)\n",
    "  characters_len = len(characters)\n",
    "\n",
    "  result = []\n",
    "  \n",
    "  # column by column\n",
    "  for i in range(0, columns):  \n",
    "    # current column + 1 and substract 1 from characters so we don't count current character\n",
    "    for j in range(i+1, columns, characters_len-1):\n",
    "      column_variables = [columns_lst[i]]\n",
    "      column_variables.extend(columns_lst[j:j+(characters_len-1)])\n",
    "      # compare numbers and group columns by number of variables inside the formula\n",
    "      if(len(column_variables) == characters_len):\n",
    "        result.append(column_variables)\n",
    "  return result # grouped columns\n",
    "\n",
    "def get_formula_by_columns(formula: str, columns: list) -> dict:\n",
    "  '''\n",
    "  Mapping every single formula's variable to a column.\n",
    "  '''\n",
    "  to_replace = {}\n",
    "\n",
    "  # formula variables\n",
    "  variables = get_formula_variables(formula=formula)\n",
    "  # iterate over grouped columns\n",
    "  for cidx, column_group in enumerate(columns):\n",
    "    formula_grouped = {}\n",
    "    # iterate over variables\n",
    "    for idx, variable in enumerate(variables):\n",
    "      # variable paired to column name\n",
    "      formula_grouped[variable] = column_group[idx]\n",
    "    # every column group represents a key\n",
    "    to_replace[cidx] = formula_grouped\n",
    "  return to_replace\n",
    "\n",
    "def parse_formula(formula: str, formula_columns: dict) -> list:\n",
    "  '''\n",
    "  Parses, effectively, every grouped column to a real formula. \n",
    "  In simple words, replaces every formula variable for its paired column.\n",
    "  '''\n",
    "  result = []\n",
    "  formula_variables = re.findall(r'\\w+', formula)\n",
    "\n",
    "  for variables_paired in formula_columns.values():\n",
    "        new_formula = formula\n",
    "        for variable in formula_variables:\n",
    "            if variable in variables_paired:\n",
    "                # we need to put a blank space after a single character, \n",
    "                # so we can identify it then with the regex\n",
    "                replace_regex = f'{variable}(?:[^\\w\\*\\\\\\+\\(\\)\\-])'\n",
    "                new_formula = re.sub(replace_regex, variables_paired[variable], new_formula)\n",
    "#             elif variable in COMPLEX_OPERATIONS:\n",
    "#                 print(f'Going to replace [{variable} for [{COMPLEX_OPERATIONS[variable]}]')\n",
    "#                 new_formula = new_formula.replace(variable, COMPLEX_OPERATIONS[variable])\n",
    "#                 print(f'GOING TO APPEND => [{new_formula}]')\n",
    "        new_formula = new_formula.replace(\" \", \"\")\n",
    "        for key, value in COMPLEX_OPERATIONS.items():\n",
    "            if key in new_formula:\n",
    "                new_formula = new_formula.replace(key, value)\n",
    "        \n",
    "        result.append(new_formula)\n",
    "  \n",
    "  return result\n",
    "\n",
    "def execute_formula(formula_by_columns: list, data: pd.DataFrame) -> pd.DataFrame:\n",
    "  '''\n",
    "  Take every real formula and executes it via patsy dmatrix.\n",
    "  Saves every formula result inside a new dataframe's column.\n",
    "  '''\n",
    "  new_df = data.copy()\n",
    "     \n",
    "  for formula_columns in formula_by_columns:\n",
    "    result_items = []\n",
    "    add_data = True\n",
    "#     try:\n",
    "    formula = \"I(\"+formula_columns+\")-1\"\n",
    "    result = dmatrix(formula, data, NA_action='raise')\n",
    "    for item in result:\n",
    "        result_items.append(item.item())\n",
    "#     except:\n",
    "#         # Ignore Patsy error.\n",
    "#         add_data = False\n",
    "        \n",
    "    if add_data:\n",
    "        clean_column_symbols(formula_columns, new_df, result_items)\n",
    "    else:\n",
    "        print_error(\"Your data has some invalid values. Script will ignore them and their possible result\")\n",
    "        \n",
    "  return new_df\n",
    "\n",
    "def execute(formula_input: str, data: pd.DataFrame, class_column: str = None):\n",
    "\n",
    "    class_column_values = None\n",
    "    if class_column is not None:\n",
    "        class_column_values = data[class_column]\n",
    "        data=data.drop(class_column, axis=1)\n",
    "    \n",
    "    data.columns = data.columns.str.replace(' ','_')\n",
    "    \n",
    "    formula = add_blank_spaces_to_formula(formula_input.lower())\n",
    "    grouped_columns = group_columns(formula, data)\n",
    "    replaceable_result = get_formula_by_columns(formula, grouped_columns)\n",
    "    \n",
    "#     print(f'Got formula => {formula}')\n",
    "    executable_formulas = parse_formula(formula, replaceable_result)\n",
    "    new_data = execute_formula(executable_formulas, data)\n",
    "\n",
    "    if class_column_values is None:\n",
    "        return new_data\n",
    "    else:\n",
    "        return new_data, class_column_values\n",
    "def print_error(error_message: str):\n",
    "    print(f\"{bcolors.WARNING}{error_message}{bcolors.ENDC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bbdebd",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "317ae3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_for_selection(model: str):\n",
    "    models = {\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'LR': LogisticRegression(),\n",
    "        'NB': GaussianNB(),\n",
    "        'SVM': svm.SVC(max_iter=500000),\n",
    "        'RF': RandomForestClassifier(random_state=0),\n",
    "        'MLP': MLPClassifier(random_state=1)\n",
    "    }\n",
    "    model_ = models.get(model.upper())\n",
    "#     print(f'Going to return model: [{type(model_)}]')\n",
    "    return model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8d8dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X_source: pd.DataFrame,\n",
    "                    X_training: pd.DataFrame,\n",
    "                    Y_training: pd.Series,\n",
    "                    model: str,\n",
    "                    forward_selection: True, \n",
    "                    verbose_mode: True):\n",
    "    \n",
    "    # Get the model from the parameter\n",
    "    model_selected = get_model_for_selection(model)\n",
    "    \n",
    "    # Build the feature selector object\n",
    "    plain_sfs = SFS(model_selected,\n",
    "                    scoring='accuracy',\n",
    "                    cv=0,\n",
    "                    k_features=(5, 10), \n",
    "                    forward=forward_selection, \n",
    "                    floating=(not forward_selection), n_jobs=-1)\n",
    "    # train\n",
    "    plain_sfs.fit(X_training, Y_training)\n",
    "    sub_selected_features = X_source.columns[list(plain_sfs.k_feature_idx_)]\n",
    "    \n",
    "    if verbose_mode:\n",
    "        print(f'Selected Features => {list(sub_selected_features)}')\n",
    "        \n",
    "    return list(sub_selected_features)\n",
    "\n",
    "def compute_score_for_features(X_validation: pd.DataFrame,\n",
    "                               Y_validation: pd.Series,\n",
    "                               model: str,\n",
    "                               selected_features: list,\n",
    "                               use_cross_val: True):\n",
    "    clf = get_model_for_selection(model)\n",
    "    label = np.unique(Y_validation)\n",
    "    # validation\n",
    "    clf.fit(X_validation[selected_features], Y_validation)\n",
    "\n",
    "    selected_features_score = 0\n",
    "    \n",
    "    # we get score using the pre-validation ds.\n",
    "    try:\n",
    "        if use_cross_val:\n",
    "            cv_value = 5\n",
    "            selected_features_score = cross_val_score(clf, X_validation[selected_features], Y_validation, cv=3).mean()\n",
    "    except:\n",
    "        selected_features_score = accuracy_score(Y_validation, clf.predict(X_validation[selected_features]))\n",
    "        \n",
    "    return selected_features_score\n",
    "\n",
    "def clean_column_names(names: list):\n",
    "    result = []\n",
    "    for column in names:\n",
    "        result.append(column.replace(\"_POW_\", \" ^ \")\n",
    "                      .replace(\"_TIMES_\", \"x\")\n",
    "                      .replace(\"_PLUS_\", \"+\")\n",
    "                      .replace(\"_MINUS_\", \"-\")\n",
    "                      .replace(\"_COZ_\", \"cos\")\n",
    "                      .replace(\"PAR_C\", \")\")\n",
    "                      .replace(\"PAR_O\", \"(\")\n",
    "                      .replace('_MINIM_', 'min')\n",
    "                      .replace('_MAXIM_', 'max')\n",
    "                      .replace('_PII_', 'pi')\n",
    "                      .replace('_DIV_', '/'))\n",
    "    return result\n",
    "\n",
    "def compute_final_score(X_test_df: pd.DataFrame, \n",
    "                        Y_test_class: pd.Series,\n",
    "                        model: str,\n",
    "                        use_cross_val: bool):\n",
    "    \n",
    "    #Get the best result using the TEST ds\n",
    "    final_clf = get_model_for_selection(model)\n",
    "\n",
    "    # validation\n",
    "    final_clf.fit(X_test_df, Y_test_class)\n",
    "    \n",
    "    final_score = 0\n",
    "    if use_cross_val:\n",
    "        final_score = cross_val_score(final_clf, X_test_df, Y_test_class, cv=5).mean()\n",
    "    else:\n",
    "        final_score = accuracy_score(Y_test_class, final_clf.predict(X_test_df))\n",
    "    \n",
    "    return final_score\n",
    "\n",
    "def print_iteration_result(selected_index: int,\n",
    "                           final_selected_features: list,\n",
    "                           final_score: float,\n",
    "                           iteration_numbers: int,\n",
    "                           forward_selection: bool,\n",
    "                           verbose_mode: bool,\n",
    "                           dataset_name: str,\n",
    "                           model: str,\n",
    "                           formula_array: list):\n",
    "    selection_type = \"Backward\"\n",
    "    if forward_selection:\n",
    "        selection_type = \"Forward\"\n",
    "        \n",
    "    print(f\"{dataset_name.upper()} - {selection_type.upper()} Select - {model.upper()} - Form {formula_array}\")\n",
    "    \n",
    "    if verbose_mode:\n",
    "        print('**** RESULTS ****')\n",
    "        print(f'Iteration with the best result: {selected_index}')\n",
    "        print(f'Features for the best result: {clean_column_names(final_selected_features)}')\n",
    "    print(f'BEST RESULT SCORE: {round(final_score, 2)} IN [{iteration_numbers}] ITERARIONS')\n",
    "    print(\"\")\n",
    "    \n",
    "def get_final_list_of_features(sub_iterations_features: list):\n",
    "    result = []\n",
    "    for features in sub_iterations_features:\n",
    "        result.extend(features)\n",
    "    \n",
    "    return list(dict.fromkeys(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fc842414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_data(data: pd.DataFrame, \n",
    "                 class_name: str,\n",
    "                 formula_array: list,\n",
    "                 model: str, \n",
    "                 validation_data_size: float, \n",
    "                 test_data_size: float,\n",
    "                 dataset_name: str,\n",
    "                 forward_selection = True,\n",
    "                 use_cross_val = False,\n",
    "                 verbose_mode = False,\n",
    "                 sub_iterations = 3):\n",
    "    \n",
    "    if len(formula_array) == 0:\n",
    "       print_error(\"Formula array can't be empty.\")\n",
    "       return\n",
    "    \n",
    "    # variable definitions\n",
    "    continue_iter = True\n",
    "    idx_iter = 0\n",
    "    formula_len = len(formula_array)\n",
    "    last_formula_idx = 0\n",
    "    class_df = {}\n",
    "\n",
    "    iterations_result = []\n",
    "    iterations_df     = []\n",
    "    iterations_x      = []\n",
    "    iterations_y      = []\n",
    "    \n",
    "    # this variables will handle the dataframe and classes\n",
    "    X = {}\n",
    "    y = {}\n",
    "\n",
    "    # the dataframe with its column filtered just for those that has been selected in the iteration n-1\n",
    "    last_selected_X = {}\n",
    "    \n",
    "    while continue_iter:\n",
    "        \n",
    "        formula = \"\"\n",
    "        selected_features = []\n",
    "        if idx_iter < formula_len:\n",
    "            formula = formula_array[idx_iter]\n",
    "            last_formula_idx += 1\n",
    "        elif (last_formula_idx+1) < formula_len:\n",
    "            formula = formula_array[last_formula_idx + 1]\n",
    "            last_formula_idx += 1\n",
    "        else:\n",
    "            last_formula_idx = 0\n",
    "            formula = formula_array[last_formula_idx]\n",
    "        \n",
    "        if verbose_mode:\n",
    "            print(f'ITERATION {idx_iter} with formula [{formula}]')\n",
    "        # for the first iteration, we need to create data from the original dataset\n",
    "        if idx_iter == 0:\n",
    "            new_df = df.sample(frac=1)\n",
    "            X, y = execute(formula_input=formula, data=new_df, class_column=class_name)\n",
    "        else:\n",
    "            X = execute(formula_input=formula, data=last_selected_X)\n",
    "            \n",
    "        # Replace infinite values to avoid errors\n",
    "        X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        # Drop columns with at least one NaN value\n",
    "        X.dropna(axis='columns', inplace=True)\n",
    "\n",
    "        if verbose_mode:\n",
    "            print(f'Feature Generation - Columns => {list(X.columns)}')\n",
    "\n",
    "        number_of_columns = len(X.columns)\n",
    "\n",
    "        #split the dataset in 3 parts: train, evaluation and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_data_size, \n",
    "                                                            random_state=1)\n",
    " \n",
    "        sub_iter_idx = 0\n",
    "        sub_iterations_result = []\n",
    "        sub_iterations_df = []\n",
    "        sub_iterations_features = []\n",
    "        \n",
    "        # sub iteration to get the best result from the pre-validation set.\n",
    "        for sub_iter_idx in range(sub_iterations):\n",
    "            \n",
    "            # split the dataset in train and validation\n",
    "            # the random_state = None will shuffle the ds in every single call\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                              y_train, \n",
    "                                                              test_size=validation_data_size,\n",
    "                                                              random_state=None)\n",
    "            \n",
    "            if (len(np.unique(y_val)) == 1) or (len(np.unique(y_train)) == 1):\n",
    "                print('UNIQUE!')\n",
    "                current_score = sum(sub_iterations_result) / len(sub_iterations_result)\n",
    "                selected_features = get_final_list_of_features(sub_iterations_features)\n",
    "                break\n",
    "            \n",
    "            \n",
    "            sub_selected_features = select_features(X_source=X, X_training=X_train,\n",
    "                                                    Y_training=y_train, model=model,\n",
    "                                                    forward_selection=forward_selection,\n",
    "                                                    verbose_mode=verbose_mode)\n",
    "            \n",
    "            current_iter_score = compute_score_for_features(X_validation=X_val, Y_validation=y_val,\n",
    "                                                            use_cross_val=use_cross_val, \n",
    "                                                            model=model, \n",
    "                                                            selected_features=sub_selected_features)\n",
    "            # number_of_columns = len(sub_selected_features)              \n",
    "            # save the current sub iteration result\n",
    "            sub_iterations_result.append(current_iter_score)\n",
    "            sub_iterations_features.append(sub_selected_features)\n",
    "        #### END OF SUBITERATIONS ####\n",
    "\n",
    "        # if we reach the max iterations, return the average result\n",
    "        current_score = sum(sub_iterations_result) / len(sub_iterations_result)\n",
    "        selected_features = get_final_list_of_features(sub_iterations_features)\n",
    "            \n",
    "        if verbose_mode:\n",
    "            print(f'Got score = {current_score}')\n",
    "        \n",
    "        last_selected_X = X[selected_features]\n",
    "\n",
    "        # save both score and df with selected features to a list\n",
    "        iterations_result.append(current_score)\n",
    "        iterations_df.append(last_selected_X)\n",
    "        iterations_x.append(X_test[selected_features])\n",
    "        iterations_y.append(y_test)\n",
    "\n",
    "        if idx_iter > 0 and current_score <= iterations_result[idx_iter-1]:\n",
    "            continue_iter = False\n",
    "        else:\n",
    "            continue_iter = True\n",
    "        idx_iter += 1\n",
    "    ###### END OF WHILE ITERATION ####\n",
    "    \n",
    "    max_index = iterations_result.index(max(iterations_result))\n",
    "    x_test_final = iterations_x[max_index]\n",
    "    y_test_final = iterations_y[max_index]\n",
    "\n",
    "    # list of selected features for the best result\n",
    "    final_selected_features = list(iterations_df[max_index].columns)\n",
    "    \n",
    "    # compute best score based on the selected features and using the test df\n",
    "    final_score = compute_final_score(X_test_df=x_test_final, \n",
    "                                      Y_test_class=y_test_final,\n",
    "                                      model=model, \n",
    "                                      use_cross_val=use_cross_val)\n",
    "    \n",
    "    print_iteration_result(selected_index=max_index, \n",
    "                           final_selected_features=final_selected_features,\n",
    "                           final_score=final_score,\n",
    "                           iteration_numbers=len(iterations_result),\n",
    "                           forward_selection=forward_selection,\n",
    "                           formula_array=formula_array,\n",
    "                           verbose_mode=verbose_mode,\n",
    "                           dataset_name=dataset_name,\n",
    "                           model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba8e2bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIMA INDIAN DIABETES - FORWARD Select - SVM - Form ['a * b']\n",
      "BEST RESULT SCORE: 0.74 IN [2] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - FORWARD Select - SVM - Form ['cos(a+b)']\n",
      "BEST RESULT SCORE: 0.71 IN [4] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - FORWARD Select - SVM - Form ['cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.74 IN [3] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - FORWARD Select - SVM - Form ['a * b', 'cos(a+b)']\n",
      "BEST RESULT SCORE: 0.74 IN [5] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - FORWARD Select - SVM - Form ['a * b', 'cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.78 IN [3] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - FORWARD Select - SVM - Form ['a * b', 'cos(a+b)', 'cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.75 IN [2] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - BACKWARD Select - SVM - Form ['a * b']\n",
      "BEST RESULT SCORE: 0.7 IN [2] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - BACKWARD Select - SVM - Form ['cos(a+b)']\n",
      "BEST RESULT SCORE: 0.76 IN [2] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - BACKWARD Select - SVM - Form ['cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.74 IN [3] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - BACKWARD Select - SVM - Form ['a * b', 'cos(a+b)']\n",
      "BEST RESULT SCORE: 0.75 IN [4] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - BACKWARD Select - SVM - Form ['a * b', 'cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.72 IN [2] ITERARIONS\n",
      "\n",
      "PIMA INDIAN DIABETES - BACKWARD Select - SVM - Form ['a * b', 'cos(a+b)', 'cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.78 IN [2] ITERARIONS\n",
      "\n",
      "CPU times: user 18min 40s, sys: 1min 34s, total: 20min 15s\n",
      "Wall time: 34min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./datasets/diabetes.csv')\n",
    "\n",
    "# banknote => Class\n",
    "# speaker => language\n",
    "# algerian => Classes\n",
    "class_name = 'Outcome'\n",
    "\n",
    "# ds_name = 'Algerian Forest'\n",
    "# ds_name = 'Banknote Authentication'\n",
    "# ds_name = 'Speaker Accent Recognition'\n",
    "ds_name = 'Pima Indian Diabetes'\n",
    "\n",
    "selection_model = 'SVM'\n",
    "forward = True\n",
    "\n",
    "use_cross_validation = True\n",
    "\n",
    "formulas_list = [[\"a * b\"], \n",
    "                 [\"cos(a+b)\"],\n",
    "                 [\"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"],\n",
    "                 [\"a * b\", \"cos(a+b)\"],\n",
    "                 [\"a * b\", \"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"],\n",
    "                 [\"a * b\", \"cos(a+b)\", \"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"]]\n",
    "\n",
    "data_size = 0.30\n",
    "for form in formulas_list:\n",
    "    iterate_data(data=df, class_name=class_name, \n",
    "                 formula_array=form,\n",
    "                 model=selection_model, \n",
    "                 validation_data_size=data_size, \n",
    "                 test_data_size=data_size, \n",
    "                 forward_selection=forward, \n",
    "                 dataset_name=ds_name, \n",
    "                 use_cross_val=use_cross_validation,\n",
    "                 verbose_mode = False)\n",
    "\n",
    "forward = False\n",
    "for form_ in formulas_list:\n",
    "    iterate_data(data=df, \n",
    "                 class_name=class_name,\n",
    "                 formula_array=form_,\n",
    "                 model=selection_model,\n",
    "                 validation_data_size=data_size,\n",
    "                 test_data_size=data_size, \n",
    "                 forward_selection=forward,\n",
    "                 dataset_name=ds_name,\n",
    "                 use_cross_val=use_cross_validation,\n",
    "                 verbose_mode = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6694c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "628869b1",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- When we use a formula with one character like (a*a) we have problem building the formula\n",
    "- We need to take care about the naming for the features that are generated by our method because if we use a math notation, we have problems at the next iteration. For instance: we can't create a feature called A1*A2 because in the next iteration, patsy will separate that into two columns and not just one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
