{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f330d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import sys\n",
    "\n",
    "\n",
    "#Models\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from datetime import datetime\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from random import randrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5ea5eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import ModelDesc, dmatrices, dmatrix, demo_data\n",
    "import re\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "# TODO: add more complex operations from numpy\n",
    "COMPLEX_OPERATIONS = {\n",
    "    'cos': 'np.cos',\n",
    "    'tan': 'np.tan',\n",
    "    'log': 'np.log',\n",
    "    'log10': 'np.log10',\n",
    "    'log2': 'np.log2',\n",
    "    'min': 'np.min',\n",
    "    'max': 'np.max',\n",
    "    'pi': 'np.pi'\n",
    "}\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "def clean_column_symbols(column_, df, result):\n",
    "    df[column_.replace('np.cos', '_COZ_')\n",
    "       .replace(')', 'PAR_C')\n",
    "       .replace('(', 'PAR_O')\n",
    "       .replace('np.min', '_MINIM_')\n",
    "       .replace('np.max', '_MAXIM_')\n",
    "       .replace('np.pi', '_PII_')\n",
    "       .replace('**', '_POW_')\n",
    "       .replace('+', '_PLUS_')\n",
    "       .replace('*', '_TIMES_')\n",
    "       .replace('-', '_MINUS_')\n",
    "      .replace('/', '_DIV_')] = result\n",
    "    \n",
    "def add_blank_spaces_to_formula(formula: str) -> str:\n",
    "    new = ''\n",
    "    for index, element in enumerate(formula):\n",
    "        next_idx = index + 1\n",
    "        if next_idx < len(formula):\n",
    "            if not re.match('\\w', formula[index+1]):\n",
    "                new += element + ' '\n",
    "            else:\n",
    "                new += element\n",
    "        else:\n",
    "            new += element + ' '\n",
    "    return new\n",
    "\n",
    "def matched_words(s, pat):\n",
    "    pat = r'(\\w*%s\\w*)' % pat       # Not thrilled about this line\n",
    "    return re.findall(pat, s)\n",
    "\n",
    "def clean_formula(formula: str) -> str:\n",
    "    result = formula\n",
    "    for operation in COMPLEX_OPERATIONS:\n",
    "        if(operation in formula):\n",
    "            result = result.replace(operation, \"\")\n",
    "    return result\n",
    "\n",
    "def get_formula_variables(formula: str):\n",
    "  '''\n",
    "  Returns a list of every variable (non repeated) from the formula\n",
    "  '''\n",
    "  cleaned_formula = clean_formula(formula)\n",
    "  return sorted(list(set(\"\".join(re.findall(\"[a-zA-Z]+\", cleaned_formula)))))\n",
    "\n",
    "def group_columns(formula: str, data: pd.DataFrame):\n",
    "  # get number of variables inside formula\n",
    "  # convert string to set that only holds unique elements\n",
    "  characters = get_formula_variables(formula=formula)\n",
    "\n",
    "  # get dataset number of columns\n",
    "  columns = len(data.columns)\n",
    "  columns_lst = list(data.columns)\n",
    "  characters_len = len(characters)\n",
    "\n",
    "  result = []\n",
    "  \n",
    "  # column by column\n",
    "  for i in range(0, columns):  \n",
    "    # current column + 1 and substract 1 from characters so we don't count current character\n",
    "    for j in range(i+1, columns, characters_len-1):\n",
    "      column_variables = [columns_lst[i]]\n",
    "      column_variables.extend(columns_lst[j:j+(characters_len-1)])\n",
    "      # compare numbers and group columns by number of variables inside the formula\n",
    "      if(len(column_variables) == characters_len):\n",
    "        result.append(column_variables)\n",
    "  return result # grouped columns\n",
    "\n",
    "def get_formula_by_columns(formula: str, columns: list) -> dict:\n",
    "  '''\n",
    "  Mapping every single formula's variable to a column.\n",
    "  '''\n",
    "  to_replace = {}\n",
    "\n",
    "  # formula variables\n",
    "  variables = get_formula_variables(formula=formula)\n",
    "  # iterate over grouped columns\n",
    "  for cidx, column_group in enumerate(columns):\n",
    "    formula_grouped = {}\n",
    "    # iterate over variables\n",
    "    for idx, variable in enumerate(variables):\n",
    "      # variable paired to column name\n",
    "      formula_grouped[variable] = column_group[idx]\n",
    "    # every column group represents a key\n",
    "    to_replace[cidx] = formula_grouped\n",
    "  return to_replace\n",
    "\n",
    "def parse_formula(formula: str, formula_columns: dict) -> list:\n",
    "  '''\n",
    "  Parses, effectively, every grouped column to a real formula. \n",
    "  In simple words, replaces every formula variable for its paired column.\n",
    "  '''\n",
    "  result = []\n",
    "  formula_variables = re.findall(r'\\w+', formula)\n",
    "\n",
    "  for variables_paired in formula_columns.values():\n",
    "        new_formula = formula\n",
    "        for variable in formula_variables:\n",
    "            if variable in variables_paired:\n",
    "                # we need to put a blank space after a single character, \n",
    "                # so we can identify it then with the regex\n",
    "                replace_regex = f'{variable}(?:[^\\w\\*\\\\\\+\\(\\)\\-])'\n",
    "                new_formula = re.sub(replace_regex, variables_paired[variable], new_formula)\n",
    "#             elif variable in COMPLEX_OPERATIONS:\n",
    "#                 print(f'Going to replace [{variable} for [{COMPLEX_OPERATIONS[variable]}]')\n",
    "#                 new_formula = new_formula.replace(variable, COMPLEX_OPERATIONS[variable])\n",
    "#                 print(f'GOING TO APPEND => [{new_formula}]')\n",
    "        new_formula = new_formula.replace(\" \", \"\")\n",
    "        for key, value in COMPLEX_OPERATIONS.items():\n",
    "            if key in new_formula:\n",
    "                new_formula = new_formula.replace(key, value)\n",
    "        \n",
    "        result.append(new_formula)\n",
    "  \n",
    "  return result\n",
    "\n",
    "def execute_formula(formula_by_columns: list, data: pd.DataFrame) -> pd.DataFrame:\n",
    "  '''\n",
    "  Take every real formula and executes it via patsy dmatrix.\n",
    "  Saves every formula result inside a new dataframe's column.\n",
    "  '''\n",
    "  new_df = data.copy()\n",
    "     \n",
    "  for formula_columns in formula_by_columns:\n",
    "    result_items = []\n",
    "    add_data = True\n",
    "#     try:\n",
    "    formula = \"I(\"+formula_columns+\")-1\"\n",
    "    result = dmatrix(formula, data, NA_action='raise')\n",
    "    for item in result:\n",
    "        result_items.append(item.item())\n",
    "#     except:\n",
    "#         # Ignore Patsy error.\n",
    "#         add_data = False\n",
    "        \n",
    "    if add_data:\n",
    "        clean_column_symbols(formula_columns, new_df, result_items)\n",
    "    else:\n",
    "        print_error(\"Your data has some invalid values. Script will ignore them and their possible result\")\n",
    "        \n",
    "  return new_df\n",
    "\n",
    "def execute(formula_input: str, data: pd.DataFrame, class_column: str = None):\n",
    "\n",
    "    class_column_values = None\n",
    "    if class_column is not None:\n",
    "        class_column_values = data[class_column]\n",
    "        data=data.drop(class_column, axis=1)\n",
    "    \n",
    "    data.columns = data.columns.str.replace(' ','_')\n",
    "    \n",
    "    formula = add_blank_spaces_to_formula(formula_input.lower())\n",
    "    grouped_columns = group_columns(formula, data)\n",
    "    replaceable_result = get_formula_by_columns(formula, grouped_columns)\n",
    "    \n",
    "#     print(f'Got formula => {formula}')\n",
    "    executable_formulas = parse_formula(formula, replaceable_result)\n",
    "    new_data = execute_formula(executable_formulas, data)\n",
    "\n",
    "    if class_column_values is None:\n",
    "        return new_data\n",
    "    else:\n",
    "        return new_data, class_column_values\n",
    "def print_error(error_message: str):\n",
    "    print(f\"{bcolors.WARNING}{error_message}{bcolors.ENDC}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bbdebd",
   "metadata": {},
   "source": [
    "## Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "317ae3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_for_selection(model: str):\n",
    "    models = {\n",
    "        'KNN': KNeighborsClassifier(),\n",
    "        'LR': LogisticRegression(),\n",
    "        'NB': GaussianNB(),\n",
    "        'SVM': svm.SVC(max_iter=500000),\n",
    "        'RF': RandomForestClassifier(random_state=0),\n",
    "        'MLP': MLPClassifier(random_state=1)\n",
    "    }\n",
    "    model_ = models.get(model.upper())\n",
    "#     print(f'Going to return model: [{type(model_)}]')\n",
    "    return model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf602c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score_from_validations(X_val: pd.DataFrame,\n",
    "                               y_val: pd.Series,\n",
    "                               model: str,\n",
    "                               selected_features: list, \n",
    "                               use_cross_val: True):\n",
    "#     print(X_val.shape[0])\n",
    "    shape = int(X_val.shape[0]/3)\n",
    "#     print(f'shape => {shape}')\n",
    "    df_1 = X_val.iloc[0:shape,:]\n",
    "    df_2 = X_val.iloc[shape:shape*2,:]\n",
    "    df_3 = X_val.iloc[shape*2:,:]\n",
    "#     print(f'df_1 => {df_1.shape}')\n",
    "#     print(f'df_2 => {df_2.shape}')\n",
    "#     print(f'df_3 => {df_3.shape}')\n",
    "    \n",
    "    y_1 = y_val.iloc[0:shape]\n",
    "    y_2 = y_val.iloc[shape:shape*2]\n",
    "    y_3 = y_val.iloc[shape*2:shape*3]\n",
    "#     print(f'y_1 => {y_1.shape}')\n",
    "#     print(f'y_2 => {y_2.shape}')\n",
    "#     print(f'y_3 => {y_3.shape}')\n",
    "    \n",
    "    sub_scores = []\n",
    "    \n",
    "    X_sub = []\n",
    "    y_sub = []\n",
    "    for n in range(3):\n",
    "        if n == 0:\n",
    "            X_sub = df_1\n",
    "            y_sub = y_1\n",
    "        elif n == 1:\n",
    "            X_sub = df_2\n",
    "            y_sub = y_2\n",
    "        else:\n",
    "            X_sub = df_3\n",
    "            y_sub = y_3\n",
    "        \n",
    "        clf = get_model_for_selection(model)\n",
    "        # validation\n",
    "        clf.fit(X_sub[selected_features], y_sub)\n",
    "        current_score = 0\n",
    "        try:\n",
    "            # we get score using the test.\n",
    "            if use_cross_val:\n",
    "                current_score = cross_val_score(clf, X_sub, y_sub, cv=5).mean()\n",
    "            else:\n",
    "                current_score = accuracy_score(y_sub, clf.predict(X_sub[selected_features]))\n",
    "        except:\n",
    "            print(\"Oops!\", sys.exc_info()[0], \"occurred.\")\n",
    "        sub_scores.append(current_score)\n",
    "    \n",
    "#     print(f'Got subscores => {sub_scores}')\n",
    "    return min(sub_scores)\n",
    "\n",
    "def compute_score_for_features(X_validation: pd.DataFrame,\n",
    "                               Y_validation: pd.Series,\n",
    "                               model: str,\n",
    "                               use_cross_val: True):\n",
    "    clf = get_model_for_selection(model)\n",
    "#     label = np.unique(Y_validation)\n",
    "    \n",
    "    # validation\n",
    "    clf.fit(X_validation, Y_validation)\n",
    "\n",
    "    selected_features_score = 0\n",
    "    \n",
    "    # we get score using the pre-validation ds.\n",
    "    if use_cross_val:\n",
    "        selected_features_score = cross_val_score(clf, X_validation, Y_validation, cv=3).mean()\n",
    "    else:\n",
    "        selected_features_score = accuracy_score(Y_validation, clf.predict(X_validation))\n",
    "        \n",
    "    return selected_features_score\n",
    "\n",
    "def clean_column_names(names: list):\n",
    "    result = []\n",
    "    for column in names:\n",
    "        result.append(column.replace(\"_POW_\", \" ^ \")\n",
    "                      .replace(\"_TIMES_\", \"x\")\n",
    "                      .replace(\"_PLUS_\", \"+\")\n",
    "                      .replace(\"_MINUS_\", \"-\")\n",
    "                      .replace(\"_COZ_\", \"cos\")\n",
    "                      .replace(\"PAR_C\", \")\")\n",
    "                      .replace(\"PAR_O\", \"(\")\n",
    "                      .replace('_MINIM_', 'min')\n",
    "                      .replace('_MAXIM_', 'max')\n",
    "                      .replace('_PII_', 'pi')\n",
    "                     .replace('_DIV_', '/'))\n",
    "    return result\n",
    "\n",
    "def train_model(X_source: pd.DataFrame,\n",
    "                X_train_df: pd.DataFrame, \n",
    "                Y_train_class: pd.Series, \n",
    "                model: str, \n",
    "                number_of_columns: int, \n",
    "                forward_selection: bool,\n",
    "                verbose_mode: bool):\n",
    "\n",
    "    random_n = random.randint(2, number_of_columns)\n",
    "    if random_n > 10:\n",
    "        random_n = 10\n",
    "    \n",
    "    model_selected = get_model_for_selection(model)\n",
    "    \n",
    "    ## FEATURE SELECTION SECTION\n",
    "    plain_sfs = SFS(model_selected,\n",
    "                        scoring='accuracy',\n",
    "                        cv=0,\n",
    "                        k_features=random_n, \n",
    "                        forward=forward_selection, \n",
    "                        floating=(not forward_selection), n_jobs=-1)\n",
    "\n",
    "    # train\n",
    "    plain_sfs.fit(X_train_df, Y_train_class)\n",
    "    selected_features = X_source.columns[list(plain_sfs.k_feature_idx_)]\n",
    "    if verbose_mode:\n",
    "        print(f'Selected Features => {list(selected_features)}')\n",
    "    \n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc842414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_data(data: pd.DataFrame, \n",
    "                 class_name: str,\n",
    "                 formula_array: list,\n",
    "                 model: str, \n",
    "                 validation_data_size: float, \n",
    "                 test_data_size: float,\n",
    "                 dataset_name: str,\n",
    "                 forward_selection = True,\n",
    "                 use_cross_val = False,\n",
    "                 verbose_mode = False):\n",
    "    \n",
    "    if len(formula_array) == 0:\n",
    "       print_error(\"Formula array can't be empty.\")\n",
    "       return\n",
    "    \n",
    "    # variable definitions\n",
    "    continue_iter = True\n",
    "    idx_iter = 0\n",
    "    formula_len = len(formula_array)\n",
    "    last_formula_idx = 0\n",
    "    class_df = {}\n",
    "\n",
    "    iterations_result = []\n",
    "    iterations_df     = []\n",
    "    iterations_x      = []\n",
    "    iterations_y      = []\n",
    "    \n",
    "    # this variables will handle the dataframe and classes\n",
    "    X = {}\n",
    "    y = {}\n",
    "\n",
    "    # the dataframe with its column filtered just for those that has been selected in the iteration n-1\n",
    "    last_selected_X = {}\n",
    "    \n",
    "    while continue_iter:\n",
    "        \n",
    "        formula = \"\"\n",
    "        \n",
    "        if idx_iter < formula_len:\n",
    "            formula = formula_array[idx_iter]\n",
    "            last_formula_idx += 1\n",
    "        elif (last_formula_idx+1) < formula_len:\n",
    "            formula = formula_array[last_formula_idx + 1]\n",
    "            last_formula_idx += 1\n",
    "        else:\n",
    "            last_formula_idx = 0\n",
    "            formula = formula_array[last_formula_idx]\n",
    "        \n",
    "        if verbose_mode:\n",
    "            print(f'ITERATION {idx_iter} with formula [{formula}]')\n",
    "        # for the first iteration, we need to create data from the original dataset\n",
    "        if idx_iter == 0:\n",
    "            new_df = df.sample(frac=1)\n",
    "            X, y = execute(formula_input=formula, data=new_df, class_column=class_name)\n",
    "        else:\n",
    "            X = execute(formula_input=formula, data=last_selected_X)\n",
    "            \n",
    "        # Replace infinite values to avoid errors\n",
    "        X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        # Drop columns with at least one NaN value\n",
    "        X.dropna(axis='columns', inplace=True)\n",
    "\n",
    "        if verbose_mode:\n",
    "            print(f'Feature Generation - Columns => {list(X.columns)}')\n",
    "\n",
    "        number_of_columns = len(X.columns)\n",
    "        \n",
    "        #split the dataset in 3 parts: train, evaluation and test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                            test_size=test_data_size, \n",
    "                                                            random_state=1)\n",
    "\n",
    "        # split the dataset in train and validation\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "                                                          test_size=validation_data_size,\n",
    "                                                          random_state=None)\n",
    "        \n",
    "        # train model and get selected features\n",
    "        selected_features = train_model(X_source=X, X_train_df=X_train, \n",
    "                                        Y_train_class=y_train, model=model, \n",
    "                                        verbose_mode=verbose_mode, number_of_columns=number_of_columns,\n",
    "                                        forward_selection=forward_selection)\n",
    "        \n",
    "\n",
    "        # this method will compute the worst score from three validations using the validation dataset\n",
    "        current_score = get_score_from_validations(X_val=X_val, \n",
    "                                                   y_val=y_train, \n",
    "                                                   model=model, \n",
    "                                                   selected_features=selected_features,\n",
    "                                                   use_cross_val=use_cross_val)\n",
    "\n",
    "        # save both score and df with selected features to a list\n",
    "        iterations_result.append(current_score)\n",
    "        last_selected_X = X[selected_features]\n",
    "        iterations_df.append(last_selected_X)\n",
    "        \n",
    "        #save both data and class from the to get the final score later\n",
    "        iterations_y.append(y_test)\n",
    "        iterations_x.append(X_test[selected_features])\n",
    "        \n",
    "        if idx_iter > 0 and current_score <= iterations_result[idx_iter-1]:\n",
    "            continue_iter = False\n",
    "        else:\n",
    "            continue_iter = True\n",
    "        idx_iter += 1\n",
    "    ##### END OF WHILE #####    \n",
    "\n",
    "    min_index = iterations_result.index(min(iterations_result))\n",
    "        \n",
    "    X_test_final = iterations_x[min_index]\n",
    "    Y_test_final = iterations_y[min_index]\n",
    "        \n",
    "    # get score using test data\n",
    "    final_score = compute_score_for_features(X_validation=X_test_final,\n",
    "                                            Y_validation=Y_test_final,\n",
    "                                            model=model, \n",
    "                                            use_cross_val=use_cross_val)    \n",
    "\n",
    "    selection_type = \"Backward\"\n",
    "    if forward_selection:\n",
    "        selection_type = \"Forward\"\n",
    "        \n",
    "    print(f\"{dataset_name.upper()} - {selection_type.upper()} Selection - {model.upper()} - Formula {formula_array}\")\n",
    "    \n",
    "    if verbose_mode:\n",
    "        print('**** RESULTS ****')\n",
    "        print(f'Iteration with the best result: {min_index}')\n",
    "        print(f'Features for the best result: {clean_column_names(list(X_test_final.columns))}')\n",
    "    print(f'BEST RESULT SCORE: {round(final_score, 2)} IN [{len(iterations_result)}] ITERARIONS')\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ba8e2bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPEAKER ACCENT RECOGNITION - FORWARD Selection - SVM - Formula ['a * b']\n",
      "BEST RESULT SCORE: 0.51 IN [3] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - FORWARD Selection - SVM - Formula ['cos(a+b)']\n",
      "BEST RESULT SCORE: 0.57 IN [2] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - FORWARD Selection - SVM - Formula ['cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.67 IN [2] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - FORWARD Selection - SVM - Formula ['a * b', 'cos(a+b)']\n",
      "BEST RESULT SCORE: 0.62 IN [2] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - FORWARD Selection - SVM - Formula ['a * b', 'cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.54 IN [3] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - FORWARD Selection - SVM - Formula ['a * b', 'cos(a+b)', 'cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.46 IN [4] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - BACKWARD Selection - SVM - Formula ['a * b']\n",
      "BEST RESULT SCORE: 0.55 IN [2] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - BACKWARD Selection - SVM - Formula ['cos(a+b)']\n",
      "BEST RESULT SCORE: 0.6 IN [2] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - BACKWARD Selection - SVM - Formula ['cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.59 IN [2] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - BACKWARD Selection - SVM - Formula ['a * b', 'cos(a+b)']\n",
      "BEST RESULT SCORE: 0.59 IN [4] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - BACKWARD Selection - SVM - Formula ['a * b', 'cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.55 IN [2] ITERARIONS\n",
      "\n",
      "SPEAKER ACCENT RECOGNITION - BACKWARD Selection - SVM - Formula ['a * b', 'cos(a+b)', 'cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))']\n",
      "BEST RESULT SCORE: 0.47 IN [3] ITERARIONS\n",
      "\n",
      "CPU times: user 2min 23s, sys: 13 s, total: 2min 36s\n",
      "Wall time: 2min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_csv('./datasets/accent-mfcc-data-1.csv')\n",
    "# banknote => Class\n",
    "# speaker => language\n",
    "# algerian => Classes\n",
    "class_name = 'language'\n",
    "\n",
    "# ds_name = 'Algerian Forest'\n",
    "# ds_name = 'Banknote Authentication'\n",
    "ds_name = 'Speaker Accent Recognition'\n",
    "# ds_name = 'Pima Indian Diabetes'\n",
    "# ds_name = 'Glass'\n",
    "\n",
    "selection_model = 'SVM'\n",
    "forward = True\n",
    "\n",
    "use_cross_validation = True\n",
    "verbose_mode = False\n",
    "formulas_list = [[\"a * b\"], [\"cos(a+b)\"], [\"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"],\n",
    "                 [\"a * b\", \"cos(a+b)\"], [\"a * b\", \"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"],\n",
    "                 [\"a * b\", \"cos(a+b)\", \"cos(2*pi*(a-min(a)+b-min(b)))/(max(a)+max(b)-min(a)-min(b))\"]]\n",
    "data_size = 0.30\n",
    "for form in formulas_list:\n",
    "    iterate_data(data=df, class_name=class_name, \n",
    "                 formula_array=form,\n",
    "                 model=selection_model, \n",
    "                 validation_data_size=data_size, \n",
    "                 test_data_size=data_size, \n",
    "                 forward_selection=forward, dataset_name=ds_name, \n",
    "                 use_cross_val=use_cross_validation,\n",
    "                 verbose_mode = verbose_mode)\n",
    "\n",
    "forward = False\n",
    "for form_ in formulas_list:\n",
    "    iterate_data(data=df, class_name=class_name, \n",
    "                 formula_array=form_,\n",
    "                 model=selection_model, \n",
    "                 validation_data_size=data_size, \n",
    "                 test_data_size=data_size, \n",
    "                 forward_selection=forward, \n",
    "                 dataset_name=ds_name, \n",
    "                 use_cross_val=use_cross_validation,\n",
    "                 verbose_mode = verbose_mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628869b1",
   "metadata": {},
   "source": [
    "# TODO\n",
    "- When we use a formula with one character like (a*a) we have problem building the formula\n",
    "- We need to take care about the naming for the features that are generated by our method because if we use a math notation, we have problems at the next iteration. For instance: we can't create a feature called A1*A2 because in the next iteration, patsy will separate that into two columns and not just one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
