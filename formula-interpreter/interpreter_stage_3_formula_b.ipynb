{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Execute imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-genetic in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from sklearn-genetic) (0.23.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from sklearn-genetic) (1.19.2)\n",
      "Requirement already satisfied: deap>=1.0.2 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from sklearn-genetic) (1.3.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from sklearn-genetic) (0.70.12.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->sklearn-genetic) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->sklearn-genetic) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->sklearn-genetic) (1.5.2)\n",
      "Requirement already satisfied: dill>=0.3.4 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from multiprocess->sklearn-genetic) (0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\walter ortiz\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glass = pd.read_csv('glass.csv', delimiter=',')\n",
    "X = pd.read_csv('glass_formula_b.csv', delimiter=',')\n",
    "y = data_glass['Type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>cos(2*pi*(RI-min(RI)+Na-min(Na)))/(max(RI)+max(Na)-min(RI)-min(Na))</th>\n",
       "      <th>...</th>\n",
       "      <th>cos(2*pi*(Si-min(Si)+K-min(K)))/(max(Si)+max(K)-min(Si)-min(K))</th>\n",
       "      <th>cos(2*pi*(Si-min(Si)+Ca-min(Ca)))/(max(Si)+max(Ca)-min(Si)-min(Ca))</th>\n",
       "      <th>cos(2*pi*(Si-min(Si)+Ba-min(Ba)))/(max(Si)+max(Ba)-min(Si)-min(Ba))</th>\n",
       "      <th>cos(2*pi*(Si-min(Si)+Fe-min(Fe)))/(max(Si)+max(Fe)-min(Si)-min(Fe))</th>\n",
       "      <th>cos(2*pi*(K-min(K)+Ca-min(Ca)))/(max(K)+max(Ca)-min(K)-min(Ca))</th>\n",
       "      <th>cos(2*pi*(K-min(K)+Ba-min(Ba)))/(max(K)+max(Ba)-min(K)-min(Ba))</th>\n",
       "      <th>cos(2*pi*(K-min(K)+Fe-min(Fe)))/(max(K)+max(Fe)-min(K)-min(Fe))</th>\n",
       "      <th>cos(2*pi*(Ca-min(Ca)+Ba-min(Ba)))/(max(Ca)+max(Ba)-min(Ca)-min(Ba))</th>\n",
       "      <th>cos(2*pi*(Ca-min(Ca)+Fe-min(Fe)))/(max(Ca)+max(Fe)-min(Ca)-min(Fe))</th>\n",
       "      <th>cos(2*pi*(Ba-min(Ba)+Fe-min(Fe)))/(max(Ba)+max(Fe)-min(Ba)-min(Fe))</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131262</td>\n",
       "      <td>...</td>\n",
       "      <td>8.317420e-02</td>\n",
       "      <td>-0.015201</td>\n",
       "      <td>1.122614e-01</td>\n",
       "      <td>1.607671e-01</td>\n",
       "      <td>-0.042956</td>\n",
       "      <td>0.099335</td>\n",
       "      <td>0.138360</td>\n",
       "      <td>-0.030610</td>\n",
       "      <td>-3.777988e-02</td>\n",
       "      <td>0.273224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.850271e-02</td>\n",
       "      <td>-0.026026</td>\n",
       "      <td>1.001493e-01</td>\n",
       "      <td>1.434217e-01</td>\n",
       "      <td>0.042956</td>\n",
       "      <td>-0.105995</td>\n",
       "      <td>-0.147636</td>\n",
       "      <td>-0.058161</td>\n",
       "      <td>-7.178500e-02</td>\n",
       "      <td>0.273224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050791</td>\n",
       "      <td>...</td>\n",
       "      <td>-7.661533e-02</td>\n",
       "      <td>-0.060042</td>\n",
       "      <td>4.866049e-02</td>\n",
       "      <td>6.968565e-02</td>\n",
       "      <td>-0.003700</td>\n",
       "      <td>-0.082320</td>\n",
       "      <td>-0.114660</td>\n",
       "      <td>-0.042256</td>\n",
       "      <td>-5.215486e-02</td>\n",
       "      <td>0.273224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.149325</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.796335e-02</td>\n",
       "      <td>-0.051609</td>\n",
       "      <td>3.531623e-02</td>\n",
       "      <td>5.057561e-02</td>\n",
       "      <td>-0.037562</td>\n",
       "      <td>-0.096670</td>\n",
       "      <td>-0.134647</td>\n",
       "      <td>0.017878</td>\n",
       "      <td>2.206654e-02</td>\n",
       "      <td>0.273224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.143574</td>\n",
       "      <td>...</td>\n",
       "      <td>3.605244e-02</td>\n",
       "      <td>0.051609</td>\n",
       "      <td>-1.432380e-02</td>\n",
       "      <td>-2.051280e-02</td>\n",
       "      <td>0.021693</td>\n",
       "      <td>-0.101609</td>\n",
       "      <td>-0.141526</td>\n",
       "      <td>-0.045825</td>\n",
       "      <td>-5.655936e-02</td>\n",
       "      <td>0.273224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.129031</td>\n",
       "      <td>...</td>\n",
       "      <td>6.172469e-02</td>\n",
       "      <td>-0.058133</td>\n",
       "      <td>7.284846e-02</td>\n",
       "      <td>5.057561e-02</td>\n",
       "      <td>0.028389</td>\n",
       "      <td>0.068101</td>\n",
       "      <td>0.130403</td>\n",
       "      <td>0.026465</td>\n",
       "      <td>-2.391164e-16</td>\n",
       "      <td>0.254037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050143</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.300901e-17</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>6.123735e-02</td>\n",
       "      <td>-1.604479e-16</td>\n",
       "      <td>0.057884</td>\n",
       "      <td>-0.090206</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>-0.066842</td>\n",
       "      <td>8.715947e-02</td>\n",
       "      <td>-0.230691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.095888</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.524244e-02</td>\n",
       "      <td>-0.044558</td>\n",
       "      <td>7.559942e-16</td>\n",
       "      <td>-1.261069e-01</td>\n",
       "      <td>0.058811</td>\n",
       "      <td>-0.068101</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>-0.042256</td>\n",
       "      <td>8.855605e-02</td>\n",
       "      <td>-0.174160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.083955</td>\n",
       "      <td>...</td>\n",
       "      <td>2.616571e-02</td>\n",
       "      <td>0.035928</td>\n",
       "      <td>-7.823395e-02</td>\n",
       "      <td>5.057561e-02</td>\n",
       "      <td>0.056043</td>\n",
       "      <td>-0.096670</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>-0.052406</td>\n",
       "      <td>8.438833e-02</td>\n",
       "      <td>-0.247221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.149758</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.052976e-02</td>\n",
       "      <td>-0.003838</td>\n",
       "      <td>2.141501e-02</td>\n",
       "      <td>-1.556557e-01</td>\n",
       "      <td>0.021693</td>\n",
       "      <td>-0.051469</td>\n",
       "      <td>0.148810</td>\n",
       "      <td>0.045825</td>\n",
       "      <td>3.266411e-02</td>\n",
       "      <td>-0.131627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  \\\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0   \n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0   \n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0   \n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0   \n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0   \n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...  ...   \n",
       "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0   \n",
       "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0   \n",
       "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0   \n",
       "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0   \n",
       "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0   \n",
       "\n",
       "     cos(2*pi*(RI-min(RI)+Na-min(Na)))/(max(RI)+max(Na)-min(RI)-min(Na))  ...  \\\n",
       "0                                             0.131262                    ...   \n",
       "1                                             0.075100                    ...   \n",
       "2                                             0.050791                    ...   \n",
       "3                                            -0.149325                    ...   \n",
       "4                                            -0.143574                    ...   \n",
       "..                                                 ...                    ...   \n",
       "209                                          -0.129031                    ...   \n",
       "210                                           0.050143                    ...   \n",
       "211                                          -0.095888                    ...   \n",
       "212                                          -0.083955                    ...   \n",
       "213                                          -0.149758                    ...   \n",
       "\n",
       "     cos(2*pi*(Si-min(Si)+K-min(K)))/(max(Si)+max(K)-min(Si)-min(K))  \\\n",
       "0                                         8.317420e-02                 \n",
       "1                                        -6.850271e-02                 \n",
       "2                                        -7.661533e-02                 \n",
       "3                                        -5.796335e-02                 \n",
       "4                                         3.605244e-02                 \n",
       "..                                                 ...                 \n",
       "209                                       6.172469e-02                 \n",
       "210                                      -8.300901e-17                 \n",
       "211                                      -6.524244e-02                 \n",
       "212                                       2.616571e-02                 \n",
       "213                                      -8.052976e-02                 \n",
       "\n",
       "     cos(2*pi*(Si-min(Si)+Ca-min(Ca)))/(max(Si)+max(Ca)-min(Si)-min(Ca))  \\\n",
       "0                                            -0.015201                     \n",
       "1                                            -0.026026                     \n",
       "2                                            -0.060042                     \n",
       "3                                            -0.051609                     \n",
       "4                                             0.051609                     \n",
       "..                                                 ...                     \n",
       "209                                          -0.058133                     \n",
       "210                                           0.011454                     \n",
       "211                                          -0.044558                     \n",
       "212                                           0.035928                     \n",
       "213                                          -0.003838                     \n",
       "\n",
       "     cos(2*pi*(Si-min(Si)+Ba-min(Ba)))/(max(Si)+max(Ba)-min(Si)-min(Ba))  \\\n",
       "0                                         1.122614e-01                     \n",
       "1                                         1.001493e-01                     \n",
       "2                                         4.866049e-02                     \n",
       "3                                         3.531623e-02                     \n",
       "4                                        -1.432380e-02                     \n",
       "..                                                 ...                     \n",
       "209                                       7.284846e-02                     \n",
       "210                                       6.123735e-02                     \n",
       "211                                       7.559942e-16                     \n",
       "212                                      -7.823395e-02                     \n",
       "213                                       2.141501e-02                     \n",
       "\n",
       "     cos(2*pi*(Si-min(Si)+Fe-min(Fe)))/(max(Si)+max(Fe)-min(Si)-min(Fe))  \\\n",
       "0                                         1.607671e-01                     \n",
       "1                                         1.434217e-01                     \n",
       "2                                         6.968565e-02                     \n",
       "3                                         5.057561e-02                     \n",
       "4                                        -2.051280e-02                     \n",
       "..                                                 ...                     \n",
       "209                                       5.057561e-02                     \n",
       "210                                      -1.604479e-16                     \n",
       "211                                      -1.261069e-01                     \n",
       "212                                       5.057561e-02                     \n",
       "213                                      -1.556557e-01                     \n",
       "\n",
       "     cos(2*pi*(K-min(K)+Ca-min(Ca)))/(max(K)+max(Ca)-min(K)-min(Ca))  \\\n",
       "0                                            -0.042956                 \n",
       "1                                             0.042956                 \n",
       "2                                            -0.003700                 \n",
       "3                                            -0.037562                 \n",
       "4                                             0.021693                 \n",
       "..                                                 ...                 \n",
       "209                                           0.028389                 \n",
       "210                                           0.057884                 \n",
       "211                                           0.058811                 \n",
       "212                                           0.056043                 \n",
       "213                                           0.021693                 \n",
       "\n",
       "     cos(2*pi*(K-min(K)+Ba-min(Ba)))/(max(K)+max(Ba)-min(K)-min(Ba))  \\\n",
       "0                                             0.099335                 \n",
       "1                                            -0.105995                 \n",
       "2                                            -0.082320                 \n",
       "3                                            -0.096670                 \n",
       "4                                            -0.101609                 \n",
       "..                                                 ...                 \n",
       "209                                           0.068101                 \n",
       "210                                          -0.090206                 \n",
       "211                                          -0.068101                 \n",
       "212                                          -0.096670                 \n",
       "213                                          -0.051469                 \n",
       "\n",
       "     cos(2*pi*(K-min(K)+Fe-min(Fe)))/(max(K)+max(Fe)-min(K)-min(Fe))  \\\n",
       "0                                             0.138360                 \n",
       "1                                            -0.147636                 \n",
       "2                                            -0.114660                 \n",
       "3                                            -0.134647                 \n",
       "4                                            -0.141526                 \n",
       "..                                                 ...                 \n",
       "209                                           0.130403                 \n",
       "210                                           0.148810                 \n",
       "211                                           0.148810                 \n",
       "212                                           0.148810                 \n",
       "213                                           0.148810                 \n",
       "\n",
       "     cos(2*pi*(Ca-min(Ca)+Ba-min(Ba)))/(max(Ca)+max(Ba)-min(Ca)-min(Ba))  \\\n",
       "0                                            -0.030610                     \n",
       "1                                            -0.058161                     \n",
       "2                                            -0.042256                     \n",
       "3                                             0.017878                     \n",
       "4                                            -0.045825                     \n",
       "..                                                 ...                     \n",
       "209                                           0.026465                     \n",
       "210                                          -0.066842                     \n",
       "211                                          -0.042256                     \n",
       "212                                          -0.052406                     \n",
       "213                                           0.045825                     \n",
       "\n",
       "     cos(2*pi*(Ca-min(Ca)+Fe-min(Fe)))/(max(Ca)+max(Fe)-min(Ca)-min(Fe))  \\\n",
       "0                                        -3.777988e-02                     \n",
       "1                                        -7.178500e-02                     \n",
       "2                                        -5.215486e-02                     \n",
       "3                                         2.206654e-02                     \n",
       "4                                        -5.655936e-02                     \n",
       "..                                                 ...                     \n",
       "209                                      -2.391164e-16                     \n",
       "210                                       8.715947e-02                     \n",
       "211                                       8.855605e-02                     \n",
       "212                                       8.438833e-02                     \n",
       "213                                       3.266411e-02                     \n",
       "\n",
       "     cos(2*pi*(Ba-min(Ba)+Fe-min(Fe)))/(max(Ba)+max(Fe)-min(Ba)-min(Fe))  \n",
       "0                                             0.273224                    \n",
       "1                                             0.273224                    \n",
       "2                                             0.273224                    \n",
       "3                                             0.273224                    \n",
       "4                                             0.273224                    \n",
       "..                                                 ...                    \n",
       "209                                           0.254037                    \n",
       "210                                          -0.230691                    \n",
       "211                                          -0.174160                    \n",
       "212                                          -0.247221                    \n",
       "213                                          -0.131627                    \n",
       "\n",
       "[214 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.65 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000001F28005BD30>)),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [KNeighborsClassifier()]}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "knn_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "knn_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(knn_info,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.484765  4.94      0.093498]\t[ 0.082855  2.540945  0.023581]\t[ 0.345098  1.        0.050373]\t[ 0.666993  9.        0.159177]\n",
      "1  \t34    \t[-799.505294    6.76      800.085826]\t[ 2713.077875     2.241071  2712.906685]\t[-10000.            1.            0.063506]\t[     0.666993     12.        10000.      ]\n",
      "2  \t37    \t[-1599.515778     7.5       1600.078163]\t[ 3666.271888     1.835756  3666.026443]\t[-10000.            2.            0.048189]\t[     0.666993     11.        10000.      ]\n",
      "3  \t24    \t[-999.453908    7.46     1000.075478]   \t[ 3000.182031     1.802332  2999.974841]\t[-10000.            3.            0.048189]\t[     0.678758     12.        10000.      ]\n",
      "4  \t30    \t[-1399.453686     7.94      1400.071606]\t[ 3470.090738     1.302459  3469.841424]\t[-10000.            5.            0.035741]\t[     0.714052     11.        10000.      ]\n",
      "5  \t32    \t[-999.410621    7.82     1000.06876 ]   \t[ 3000.19646      1.409823  2999.97708 ]\t[-10000.            4.            0.035741]\t[     0.720261     12.        10000.      ]\n",
      "6  \t35    \t[-1799.451444     7.86      1800.062096]\t[ 3842.131552     1.549322  3841.845449]\t[-10000.            5.            0.040612]\t[     0.720261     11.        10000.      ]\n",
      "7  \t27    \t[-599.368418    7.42      600.074011]   \t[ 2375.027984     1.357792  2374.849719]\t[-10000.            5.            0.053483]\t[     0.726144     11.        10000.      ]\n",
      "8  \t25    \t[-399.344046    7.58      400.078425]   \t[ 1959.725691     1.357792  1959.575786]\t[-10000.            4.            0.056456]\t[     0.726144     10.        10000.      ]\n",
      "9  \t37    \t[-399.335078    7.24      400.073684]   \t[ 1959.727521     1.422111  1959.576754]\t[-10000.            4.            0.048517]\t[     0.726144     11.        10000.      ]\n",
      "10 \t28    \t[-199.311392    7.26      200.076413]   \t[ 1400.098373     1.467106  1399.989084]\t[-10000.            5.            0.043888]\t[     0.732026     10.        10000.      ]\n",
      "11 \t30    \t[-999.364418    8.1      1000.068789]   \t[ 3000.211861     1.603122  2999.97707 ]\t[-10000.            5.            0.043888]\t[     0.737908     12.        10000.      ]\n",
      "12 \t28    \t[-1199.370634     8.6       1200.067606]\t[ 3249.847771     1.32665   3249.590397]\t[-10000.            5.            0.043888]\t[     0.737908     13.        10000.      ]\n",
      "13 \t21    \t[-799.331144    8.5       800.072089]   \t[ 2713.129228     1.615549  2712.910735]\t[-10000.            5.            0.043888]\t[     0.737908     15.        10000.      ]\n",
      "14 \t29    \t[-799.331922    8.42      800.074924]   \t[ 2713.128999     1.021567  2712.909899]\t[-10000.            5.            0.065061]\t[     0.743464     11.        10000.      ]\n",
      "15 \t31    \t[-1799.404967     8.54      1800.066295]\t[ 3842.153328     1.22      3841.843482]\t[-10000.            7.            0.058832]\t[     0.743791     12.        10000.      ]\n",
      "16 \t25    \t[-799.325752    8.42      800.075729]   \t[ 2713.130818     0.981631  2712.909662]\t[-10000.            8.            0.057175]\t[     0.743791     12.        10000.      ]\n",
      "17 \t35    \t[-799.32481     8.28      800.073329]   \t[ 2713.131096     0.980612  2712.91037 ]\t[-10000.            7.            0.059603]\t[     0.749346     12.        10000.      ]\n",
      "18 \t26    \t[-1399.36885      8.36      1400.069723]\t[ 3470.124967     1.307823  3469.842183]\t[-10000.            6.            0.057535]\t[     0.755229     13.        10000.      ]\n",
      "19 \t28    \t[-599.303902    8.26      600.073623]   \t[ 2375.044284     0.91236   2374.849817]\t[-10000.            7.            0.057535]\t[     0.755229     11.        10000.      ]\n",
      "20 \t28    \t[-599.307876    8.22      600.074944]   \t[ 2375.04328      0.855336  2374.849483]\t[-10000.            7.            0.049798]\t[     0.755229     10.        10000.      ]\n",
      "21 \t28    \t[-599.306438    8.08      600.071327]   \t[ 2375.043643     1.128539  2374.850397]\t[-10000.            7.            0.050373]\t[     0.755229     12.        10000.      ]\n",
      "22 \t32    \t[-1599.374301     7.92      1600.063344]\t[ 3666.333634     1.635115  3666.03291 ]\t[-10000.            6.            0.057535]\t[     0.755229     14.        10000.      ]\n",
      "23 \t27    \t[-599.29681     7.36      600.069558]   \t[ 2375.046075     1.015086  2374.850844]\t[-10000.            6.            0.052613]\t[     0.755229     12.        10000.      ]\n",
      "24 \t34    \t[-199.264333    7.14      200.072393]   \t[ 1400.105095     0.566039  1399.989658]\t[-10000.            6.            0.066211]\t[     0.755229     10.        10000.      ]\n",
      "25 \t33    \t[-799.316712    7.44      800.067998]   \t[ 2713.133484     1.022937  2712.911942]\t[-10000.            6.            0.062322]\t[     0.755229     11.        10000.      ]\n",
      "26 \t34    \t[-399.283346    7.36      400.070336]   \t[ 1959.738081     1.109234  1959.577437]\t[-10000.            6.            0.043359]\t[     0.755229     13.        10000.      ]\n",
      "27 \t27    \t[-399.289085    7.34      400.072023]   \t[ 1959.73691      0.907965  1959.577093]\t[-10000.          7.          0.0625]      \t[     0.755229     11.        10000.      ]\n",
      "28 \t34    \t[-399.286359    7.3       400.070681]   \t[ 1959.737466     0.754983  1959.577367]\t[-10000.            7.            0.052025]\t[     0.755229     10.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI',\n",
       " 'Mg',\n",
       " 'Ba',\n",
       " 'cos(2*pi*(Mg-min(Mg)+K-min(K)))/(max(Mg)+max(K)-min(Mg)-min(K))',\n",
       " 'cos(2*pi*(Al-min(Al)+Ba-min(Ba)))/(max(Al)+max(Ba)-min(Al)-min(Ba))',\n",
       " 'cos(2*pi*(K-min(K)+Ba-min(Ba)))/(max(K)+max(Ba)-min(K)-min(Ba))',\n",
       " 'cos(2*pi*(K-min(K)+Fe-min(Fe)))/(max(K)+max(Fe)-min(K)-min(Fe))']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.52      0.79      0.63        14\n",
      "           2       0.50      0.33      0.40        15\n",
      "           3       0.00      0.00      0.00         3\n",
      "           5       0.40      0.67      0.50         3\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.56        43\n",
      "   macro avg       0.57      0.52      0.52        43\n",
      "weighted avg       0.56      0.56      0.54        43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5569264069264068\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(knn_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 98.2 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             param_grid=[{'classifier': [KNeighborsClassifier()]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "knn_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "knn_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(knn_variance,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.473514  5.48      0.115504]\t[ 0.08881   2.714701  0.02934 ]\t[ 0.285714  1.        0.042013]\t[ 0.651429  9.        0.193819]\n",
      "1  \t19    \t[-999.507924    7.26     1000.11014 ]\t[ 3000.164026     2.364826  2999.963287]\t[-10000.            2.            0.076214]\t[     0.664286     13.        10000.      ]\n",
      "2  \t26    \t[-999.468619    7.72     1000.114281]\t[ 3000.177128     2.172924  2999.961907]\t[-10000.            3.            0.052778]\t[     0.664762     13.        10000.      ]\n",
      "3  \t30    \t[-599.399352    7.98      600.118711]\t[ 2375.020169     1.516443  2374.838426]\t[-10000.            4.            0.089868]\t[     0.671905     11.        10000.      ]\n",
      "4  \t28    \t[-1399.433705     7.64      1400.100738]\t[ 3470.0988       1.797331  3469.829669]\t[-10000.            5.            0.078657]\t[     0.678571     11.        10000.      ]\n",
      "5  \t30    \t[-799.389029    7.42      800.103488]   \t[ 2713.112159     1.497865  2712.901476]\t[-10000.            5.            0.071506]\t[     0.678571     11.        10000.      ]\n",
      "6  \t23    \t[-199.347486    7.2       200.109837]   \t[ 1400.093216     1.183216  1399.984309]\t[-10000.            5.            0.071506]\t[     0.678571     10.        10000.      ]\n",
      "7  \t33    \t[-999.400971    7.6      1000.099922]   \t[ 3000.199676     1.356466  2999.966693]\t[-10000.            4.            0.071506]\t[     0.678571     11.        10000.      ]\n",
      "8  \t30    \t[-1199.414286     8.1       1200.09608 ]\t[ 3249.831651     1.374773  3249.579882]\t[-10000.            4.            0.092755]\t[     0.678571     12.        10000.      ]\n",
      "9  \t29    \t[-1599.43541      8.26      1600.091667]\t[ 3666.306963     1.45341   3666.020549]\t[-10000.            5.            0.099978]\t[     0.678571     13.        10000.      ]\n",
      "10 \t28    \t[-999.39321     8.34     1000.097408]   \t[ 3000.202264     0.815107  2999.967531]\t[-10000.            7.            0.103942]\t[     0.712857     12.        10000.      ]\n",
      "11 \t26    \t[-1199.401533     8.46      1200.094303]\t[ 3249.83636      1.043264  3249.580538]\t[-10000.            7.            0.099938]\t[     0.712857     13.        10000.      ]\n",
      "12 \t34    \t[-799.368581    8.42      800.101353]   \t[ 2713.118189     0.850647  2712.902106]\t[-10000.            7.            0.099938]\t[     0.712857     11.        10000.      ]\n",
      "13 \t32    \t[-799.3634      8.62      800.105404]   \t[ 2713.119716     0.891964  2712.900911]\t[-10000.            7.            0.099938]\t[     0.719524     12.        10000.      ]\n",
      "14 \t33    \t[-1199.379029     9.06      1200.103509]\t[ 3249.844671     1.138596  3249.577139]\t[-10000.            7.            0.099938]\t[     0.719524     14.        10000.      ]\n",
      "15 \t31    \t[-1799.416905     9.18      1800.097281]\t[ 3842.147735     0.993781  3841.828964]\t[-10000.            7.            0.099938]\t[     0.719524     12.        10000.      ]\n",
      "16 \t30    \t[-2799.486886     9.32      2800.084228]\t[ 4490.308847     1.489161  4489.936339]\t[-10000.            7.            0.110686]\t[     0.719524     15.        10000.      ]\n",
      "17 \t30    \t[-999.355324    8.66     1000.102462]   \t[ 3000.214892     0.764461  2999.965846]\t[-10000.            8.            0.110686]\t[     0.719524     11.        10000.      ]\n",
      "18 \t34    \t[-799.341362    8.38      800.103895]   \t[ 2713.126215     0.745386  2712.901356]\t[-10000.            8.            0.110686]\t[     0.719524     11.        10000.      ]\n",
      "19 \t35    \t[-799.340133    8.3       800.102862]   \t[ 2713.126577     1.024695  2712.901661]\t[-10000.            6.            0.110555]\t[     0.719524     13.        10000.      ]\n",
      "20 \t27    \t[-799.3386      8.26      800.102213]   \t[ 2713.127029     0.844038  2712.901852]\t[-10000.            8.            0.110555]\t[     0.719524     12.        10000.      ]\n",
      "21 \t32    \t[-999.35521     8.32     1000.100231]   \t[ 3000.21493      0.835225  2999.96659 ]\t[-10000.            8.            0.110686]\t[     0.719524     12.        10000.      ]\n",
      "22 \t27    \t[-1199.3696       8.44      1200.098711]\t[ 3249.848153     1.134196  3249.578911]\t[-10000.            8.            0.110686]\t[     0.719524     14.        10000.      ]\n",
      "23 \t35    \t[-999.355771    8.3      1000.101984]   \t[ 3000.214743     0.921954  2999.966005]\t[-10000.            7.            0.110686]\t[     0.719524     12.        10000.      ]\n",
      "24 \t29    \t[-799.343086    8.36      800.105184]   \t[ 2713.125707     1.053755  2712.900976]\t[-10000.            7.            0.109674]\t[     0.719524     13.        10000.      ]\n",
      "25 \t33    \t[-399.31039     8.14      400.106584]   \t[ 1959.73256      0.529528  1959.570038]\t[-10000.            8.            0.108777]\t[     0.719524     11.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Na',\n",
       " 'Mg',\n",
       " 'Al',\n",
       " 'Ca',\n",
       " 'cos(2*pi*(RI-min(RI)+Mg-min(Mg)))/(max(RI)+max(Mg)-min(RI)-min(Mg))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+Ca-min(Ca)))/(max(Mg)+max(Ca)-min(Mg)-min(Ca))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+Ba-min(Ba)))/(max(Mg)+max(Ba)-min(Mg)-min(Ba))',\n",
       " 'cos(2*pi*(Al-min(Al)+K-min(K)))/(max(Al)+max(K)-min(Al)-min(K))']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.93      0.77        27\n",
      "           2       0.84      0.73      0.78        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.67      0.67      0.67         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.80      0.80      0.80        10\n",
      "\n",
      "    accuracy                           0.72        71\n",
      "   macro avg       0.49      0.52      0.50        71\n",
      "weighted avg       0.65      0.72      0.68        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6502164502164501\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(knn_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 90.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000001F2FFE2F1F0>)),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             param_grid=[{'classifier': [KNeighborsClassifier()]}])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "knn_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "knn_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(knn_chi,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.448619  4.8       0.110153]\t[ 0.081484  2.529822  0.023383]\t[ 0.27381   1.        0.062713]\t[ 0.629048  9.        0.168709]\n",
      "1  \t35    \t[-1199.543581     6.04      1200.103777]\t[ 3249.783906     2.972945  3249.57704 ]\t[-10000.            0.            0.077759]\t[     0.629048     12.        10000.      ]\n",
      "2  \t29    \t[-1199.533467     6.62      1200.10828 ]\t[ 3249.787641     2.813468  3249.575377]\t[-10000.           1.           0.06708]   \t[     0.629048     13.        10000.      ]\n",
      "3  \t31    \t[-799.48879     5.74      800.111569]   \t[ 2713.082741     3.205059  2712.899093]\t[-10000.            1.            0.089842]\t[     0.629048     12.        10000.      ]\n",
      "4  \t24    \t[-199.438876    3.3       200.114342]   \t[ 1400.080162     2.837252  1399.983666]\t[-10000.            1.            0.086902]\t[     0.629048     11.        10000.      ]\n",
      "5  \t32    \t[ 0.588295  1.78      0.112527]         \t[ 0.068376  1.487145  0.016904]         \t[ 0.42      1.        0.061692]            \t[ 0.629048  8.        0.171904]            \n",
      "6  \t36    \t[ 0.607124  1.42      0.112974]         \t[ 0.055336  1.312859  0.013578]         \t[ 0.383333  1.        0.071506]            \t[ 0.629048  8.        0.165421]            \n",
      "7  \t32    \t[ 0.587143  1.64      0.116329]         \t[ 0.071591  1.162067  0.020097]         \t[ 0.427143  1.        0.072506]            \t[ 0.629048  5.        0.182169]            \n",
      "8  \t30    \t[ 0.58101   1.96      0.114396]         \t[ 0.079765  1.648757  0.015083]         \t[ 0.376667  1.        0.069393]            \t[ 0.629048  6.        0.182169]            \n",
      "9  \t27    \t[ 0.598629  1.46      0.1103  ]         \t[ 0.060253  1.023914  0.010999]         \t[ 0.419524  1.        0.074537]            \t[ 0.629048  5.        0.153553]            \n",
      "10 \t27    \t[ 0.608829  1.24      0.112231]         \t[ 0.062488  0.861626  0.007142]         \t[ 0.35      1.        0.093963]            \t[ 0.629048  5.        0.148855]            \n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cos(2*pi*(RI-min(RI)+Ba-min(Ba)))/(max(RI)+max(Ba)-min(RI)-min(Ba))']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.78      0.71        27\n",
      "           2       0.62      0.68      0.65        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.20      0.33      0.25         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.63        71\n",
      "   macro avg       0.40      0.43      0.41        71\n",
      "weighted avg       0.58      0.63      0.60        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5099567099567099\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(knn_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000001F28005BD30>)),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [LogisticRegression()]}])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "logistic_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(logistic_info,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.460505  5.24      0.115501]\t[ 0.061267  2.159259  0.028094]\t[ 0.351429  1.        0.050352]\t[ 0.60381   9.        0.172075]\n",
      "1  \t34    \t[-999.540981    6.56     1000.109387]\t[ 3000.153007     2.475157  2999.963538]\t[-10000.            1.            0.060091]\t[     0.638571     14.        10000.      ]\n",
      "2  \t28    \t[-399.468971    6.46      400.114988]\t[ 1959.700191     1.941237  1959.568323]\t[-10000.            1.            0.081217]\t[     0.651905     13.        10000.      ]\n",
      "3  \t24    \t[-799.461524    6.66      800.110246]\t[ 2713.090782     1.795661  2712.899484]\t[-10000.            4.            0.081217]\t[     0.667143     12.        10000.      ]\n",
      "4  \t30    \t[-799.438733    7.2       800.111864]\t[ 2713.097502     1.788854  2712.899006]\t[-10000.            3.            0.065493]\t[     0.679048     13.        10000.      ]\n",
      "5  \t26    \t[-599.409438    7.18      600.114191]\t[ 2375.01762      1.57086   2374.839568]\t[-10000.           4.           0.07554]   \t[     0.679524     11.        10000.      ]\n",
      "6  \t31    \t[-599.39839     7.42      600.116343]\t[ 2375.020412     1.575944  2374.839024]\t[-10000.            4.            0.069008]\t[     0.679524     12.        10000.      ]\n",
      "7  \t31    \t[-799.397867    7.74      800.115726]\t[ 2713.109553     1.439583  2712.897868]\t[-10000.            4.            0.084366]\t[     0.700476     11.        10000.      ]\n",
      "8  \t25    \t[-1399.427076     8.14      1400.110483]\t[ 3470.101474     1.442359  3469.825738]\t[-10000.            4.            0.084366]\t[     0.706667     12.        10000.      ]\n",
      "9  \t26    \t[-999.397276    8.3      1000.115761]   \t[ 3000.200908     1.044031  2999.961413]\t[-10000.            6.            0.081161]\t[     0.706667     11.        10000.      ]\n",
      "10 \t30    \t[-1399.416867     8.26      1400.113514]\t[ 3470.105593     1.128007  3469.824515]\t[-10000.            6.            0.089834]\t[     0.706667     11.        10000.      ]\n",
      "11 \t31    \t[-1199.396838     8.56      1200.11502 ]\t[ 3249.838094     1.134196  3249.572888]\t[-10000.            7.            0.089834]\t[     0.706667     12.        10000.      ]\n",
      "12 \t21    \t[-799.362467    8.82      800.117011]   \t[ 2713.119992     0.84119   2712.897489]\t[-10000.            7.            0.089834]\t[     0.708095     11.        10000.      ]\n",
      "13 \t19    \t[-799.351905    9.02      800.117488]   \t[ 2713.123106     0.761315  2712.897348]\t[-10000.            7.            0.115687]\t[     0.708095     11.        10000.      ]\n",
      "14 \t30    \t[-1399.396695     9.12      1400.108377]\t[ 3470.113732     0.738647  3469.826587]\t[-10000.           7.           0.11199]   \t[     0.708095     12.        10000.      ]\n",
      "15 \t27    \t[-799.354286    9.12      800.114857]   \t[ 2713.122404     0.765245  2712.898124]\t[-10000.           7.           0.10633]   \t[     0.708095     13.        10000.      ]\n",
      "16 \t20    \t[-1599.409229     9.2       1600.103454]\t[ 3666.31839      0.87178   3666.015405]\t[-10000.            7.            0.115687]\t[     0.708095     13.        10000.      ]\n",
      "17 \t30    \t[-1999.438219     9.34      2000.096296]\t[ 4000.28089      0.764461  3999.951852]\t[-10000.           9.           0.10633]   \t[     0.708095     12.        10000.      ]\n",
      "18 \t31    \t[-1199.382552     9.14      1200.103378]\t[ 3249.84337      0.80025   3249.577187]\t[-10000.            7.            0.099067]\t[     0.708095     13.        10000.      ]\n",
      "19 \t20    \t[-1599.405352     9.24      1600.097213]\t[ 3666.320081     0.618385  3666.018129]\t[-10000.            9.            0.115687]\t[     0.708095     12.        10000.      ]\n",
      "20 \t34    \t[-1399.391038     9.28      1400.099491]\t[ 3470.116014     0.800999  3469.830173]\t[-10000.            9.            0.115687]\t[     0.708095     13.        10000.      ]\n",
      "21 \t28    \t[-1799.419362     9.38      1800.094863]\t[ 3842.146584     0.997798  3841.830097]\t[-10000.            9.            0.115687]\t[     0.708095     14.        10000.      ]\n",
      "22 \t23    \t[-1599.405495     9.24      1600.09806 ]\t[ 3666.320019     0.68      3666.017759]\t[-10000.            8.            0.115687]\t[     0.708095     12.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Na',\n",
       " 'Mg',\n",
       " 'Al',\n",
       " 'K',\n",
       " 'Ba',\n",
       " 'cos(2*pi*(Mg-min(Mg)+K-min(K)))/(max(Mg)+max(K)-min(Mg)-min(K))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+Ba-min(Ba)))/(max(Mg)+max(Ba)-min(Mg)-min(Ba))',\n",
       " 'cos(2*pi*(K-min(K)+Ba-min(Ba)))/(max(K)+max(Ba)-min(K)-min(Ba))',\n",
       " 'cos(2*pi*(K-min(K)+Fe-min(Fe)))/(max(K)+max(Fe)-min(K)-min(Fe))']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.68      0.85      0.75        27\n",
      "           2       0.67      0.64      0.65        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.50      0.67      0.57         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.80      0.80      0.80        10\n",
      "\n",
      "    accuracy                           0.66        71\n",
      "   macro avg       0.44      0.49      0.46        71\n",
      "weighted avg       0.60      0.66      0.63        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5798701298701298\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(logistic_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 412 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'classifier': [LogisticRegression()]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "logistic_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(logistic_variance,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.433638  4.08      0.07372 ]\t[ 0.066789  2.591062  0.032858]\t[ 0.335714  1.        0.041239]\t[ 0.580952  9.        0.148632]\n",
      "1  \t28    \t[-799.534943    5.94      800.095251]\t[ 2713.069132     2.671404  2712.903905]\t[-10000.            1.            0.041853]\t[     0.636667     12.        10000.      ]\n",
      "2  \t31    \t[-799.495705    6.36      800.097158]\t[ 2713.080702     2.242855  2712.903343]\t[-10000.            3.            0.041853]\t[     0.645238     13.        10000.      ]\n",
      "3  \t32    \t[-199.423238    6.22      200.108844]\t[ 1400.082395     1.64061   1399.984451]\t[-10000.            4.            0.065921]\t[     0.645238     10.        10000.      ]\n",
      "4  \t36    \t[-399.412419    6.5       400.109728]\t[ 1959.711734     2.061553  1959.569396]\t[-10000.            2.            0.087532]\t[     0.651905     13.        10000.      ]\n",
      "5  \t26    \t[-199.387914    6.8       200.112848]\t[ 1400.087441     1.624808  1399.983879]\t[-10000.            3.            0.087532]\t[     0.666667     11.        10000.      ]\n",
      "6  \t33    \t[-999.427276    7.64     1000.109254]\t[ 3000.190908     1.466424  2999.963582]\t[-10000.            5.            0.087532]\t[     0.666667     11.        10000.      ]\n",
      "7  \t27    \t[-599.391629    7.44      600.116988]\t[ 2375.02212      1.358823  2374.838861]\t[-10000.           5.           0.09017]   \t[     0.666667     10.        10000.      ]\n",
      "8  \t32    \t[-199.358562    7.42      200.121167]\t[ 1400.091634     1.328006  1399.982691]\t[-10000.           5.           0.09017]   \t[     0.666667     13.        10000.      ]\n",
      "9  \t26    \t[-1599.446181     7.82      1600.110326]\t[ 3666.302262     1.57086   3666.012406]\t[-10000.           6.           0.11039]   \t[     0.666667     13.        10000.      ]\n",
      "10 \t31    \t[-399.364562    7.18      400.124005]   \t[ 1959.721503     0.909725  1959.566482]\t[-10000.           6.           0.09898]   \t[     0.666667     11.        10000.      ]\n",
      "11 \t29    \t[-199.348943    7.26      200.126073]   \t[ 1400.093008     0.687314  1399.98199 ]\t[-10000.           7.           0.11419]   \t[     0.666667     10.        10000.      ]\n",
      "12 \t26    \t[-599.376581    7.42      600.120882]   \t[ 2375.025921     0.896437  2374.837877]\t[-10000.            7.            0.109838]\t[     0.666667     10.        10000.      ]\n",
      "13 \t19    \t[-199.348105    7.12      200.126211]   \t[ 1400.093128     0.587878  1399.98197 ]\t[-10000.            6.            0.118574]\t[     0.666667     10.        10000.      ]\n",
      "14 \t37    \t[-399.364533    7.18      400.12404 ]   \t[ 1959.721508     0.93145   1959.566475]\t[-10000.           6.           0.09898]   \t[     0.666667     11.        10000.      ]\n",
      "15 \t29    \t[-599.377467    7.32      600.121345]   \t[ 2375.025698     0.988737  2374.83776 ]\t[-10000.           5.           0.11419]   \t[     0.666667     11.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Al',\n",
       " 'K',\n",
       " 'Ba',\n",
       " 'cos(2*pi*(RI-min(RI)+Mg-min(Mg)))/(max(RI)+max(Mg)-min(RI)-min(Mg))',\n",
       " 'cos(2*pi*(RI-min(RI)+Al-min(Al)))/(max(RI)+max(Al)-min(RI)-min(Al))',\n",
       " 'cos(2*pi*(Na-min(Na)+Si-min(Si)))/(max(Na)+max(Si)-min(Na)-min(Si))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+Ba-min(Ba)))/(max(Mg)+max(Ba)-min(Mg)-min(Ba))']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.93      0.81        27\n",
      "           2       0.75      0.82      0.78        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.76        71\n",
      "   macro avg       0.73      0.62      0.65        71\n",
      "weighted avg       0.70      0.76      0.72        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6402597402597403\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(logistic_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 378 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000001F2FFE2F1F0>)),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'classifier': [LogisticRegression()]}])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "logistic_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(logistic_chi,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.442933  4.68      0.107676]\t[ 0.063484  2.656614  0.032504]\t[ 0.328571  1.        0.041853]\t[ 0.580952  9.        0.182267]\n",
      "1  \t36    \t[-799.542848    6.8       800.108039]\t[ 2713.066801     2.32379   2712.900134]\t[-10000.            1.            0.041853]\t[     0.580952     12.        10000.      ]\n",
      "2  \t32    \t[-1399.550581     7.16      1400.104405]\t[ 3470.051644     2.618091  3469.82819 ]\t[-10000.            2.            0.032018]\t[     0.588095     15.        10000.      ]\n",
      "3  \t34    \t[-1199.514914     7.68      1200.10845 ]\t[ 3249.794492     1.630215  3249.575314]\t[-10000.            4.            0.059448]\t[     0.609048     11.        10000.      ]\n",
      "4  \t19    \t[-799.478152    7.86      800.110477]   \t[ 2713.085878     1.34179   2712.899415]\t[-10000.            5.            0.059448]\t[     0.609048     11.        10000.      ]\n",
      "5  \t34    \t[-2199.559733     8.34      2200.08721 ]\t[ 4142.696855     1.773246  4142.416719]\t[-10000.            5.            0.059448]\t[     0.609048     14.        10000.      ]\n",
      "6  \t31    \t[-399.447495    7.9       400.111613]   \t[ 1959.704574     1.153256  1959.569011]\t[-10000.            6.            0.059448]\t[     0.609048     11.        10000.      ]\n",
      "7  \t23    \t[-999.474333    7.94     1000.109467]   \t[ 3000.175222     1.08462   2999.963511]\t[-10000.            5.            0.083192]\t[     0.615714     10.        10000.      ]\n",
      "8  \t27    \t[-599.444933    7.68      600.111411]   \t[ 2375.008653     1.047664  2374.84027 ]\t[-10000.            6.            0.062104]\t[     0.61619     12.       10000.     ]   \n",
      "9  \t34    \t[-799.451438    7.8       800.115988]   \t[ 2713.093755     1.216553  2712.89779 ]\t[-10000.            6.            0.088525]\t[     0.623333     12.        10000.      ]\n",
      "10 \t34    \t[-1199.470152     7.9       1200.110447]\t[ 3249.811021     1.857418  3249.574577]\t[-10000.            5.            0.088525]\t[     0.644762     14.        10000.      ]\n",
      "11 \t33    \t[-799.441038    7.22      800.117994]   \t[ 2713.096822     1.5911    2712.897199]\t[-10000.            5.            0.109693]\t[     0.644762     11.        10000.      ]\n",
      "12 \t28    \t[-199.395152    6.86      200.121402]   \t[ 1400.086407     1.46983   1399.982657]\t[-10000.            5.            0.073023]\t[     0.644762     11.        10000.      ]\n",
      "13 \t26    \t[-199.393       6.64      200.125848]   \t[ 1400.086715     1.584424  1399.982022]\t[-10000.            5.            0.094136]\t[     0.644762     12.        10000.      ]\n",
      "14 \t27    \t[-399.399857    6.9       400.123905]   \t[ 1959.714298     1.417745  1959.566502]\t[-10000.            5.            0.083175]\t[     0.644762     11.        10000.      ]\n",
      "15 \t33    \t[-599.411905    6.72      600.117809]   \t[ 2375.016997     1.265543  2374.838654]\t[-10000.            5.            0.076909]\t[     0.644762     11.        10000.      ]\n",
      "16 \t34    \t[-599.405171    6.62      600.118931]   \t[ 2375.018698     1.278906  2374.83837 ]\t[-10000.            6.            0.105281]\t[     0.644762     11.        10000.      ]\n",
      "17 \t24    \t[ 0.627286  6.34      0.124659]         \t[ 0.033244  0.737835  0.008241]         \t[ 0.510952  6.        0.09991 ]            \t[ 0.644762  9.        0.151501]            \n",
      "18 \t30    \t[-199.379895    6.44      200.120144]   \t[ 1400.088587     1.116423  1399.982837]\t[-10000.            6.            0.085587]\t[     0.644762     12.        10000.      ]\n",
      "19 \t21    \t[ 0.640076  6.08      0.125862]         \t[ 0.016575  0.44      0.006535]         \t[ 0.567143  6.        0.10107 ]            \t[ 0.644762  9.        0.163611]            \n",
      "20 \t19    \t[ 0.640133  6.18      0.125592]         \t[ 0.013344  0.589576  0.008259]         \t[ 0.588571  6.        0.098018]            \t[ 0.644762  9.        0.173861]            \n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI',\n",
       " 'Al',\n",
       " 'K',\n",
       " 'cos(2*pi*(RI-min(RI)+K-min(K)))/(max(RI)+max(K)-min(RI)-min(K))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+K-min(K)))/(max(Mg)+max(K)-min(Mg)-min(K))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+Ba-min(Ba)))/(max(Mg)+max(Ba)-min(Mg)-min(Ba))']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.74      0.68        27\n",
      "           2       0.59      0.77      0.67        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.66        71\n",
      "   macro avg       0.70      0.56      0.61        71\n",
      "weighted avg       0.63      0.66      0.63        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5569264069264068\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(logistic_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [SVC(kernel='linear')]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.66 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000001F28005BD30>)),\n",
       "                                       ('classifier', SVC(kernel='linear'))]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [SVC(kernel='linear')]}])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "svm_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(svm_info,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.471114  5.22      0.116785]\t[ 0.068514  2.625186  0.03185 ]\t[ 0.340952  1.        0.041853]\t[ 0.651429  9.        0.165087]\n",
      "1  \t32    \t[-1199.547229     6.78      1200.110931]\t[ 3249.782559     2.351935  3249.574398]\t[-10000.            2.            0.079598]\t[     0.651429     11.        10000.      ]\n",
      "2  \t32    \t[-1799.558895     7.7       1800.103934]\t[ 3842.08121      2.308679  3841.825847]\t[-10000.           2.           0.07894]   \t[     0.651429     12.        10000.      ]\n",
      "3  \t40    \t[-1799.539505     7.98      1800.104986]\t[ 3842.090295     2.024747  3841.825354]\t[-10000.            2.            0.071437]\t[     0.658095     12.        10000.      ]\n",
      "4  \t35    \t[-1799.524514     7.94      1800.103719]\t[ 3842.097318     2.101523  3841.825948]\t[-10000.            3.            0.083012]\t[     0.658095     13.        10000.      ]\n",
      "5  \t26    \t[-1999.523619     8.08      2000.101718]\t[ 4000.238191     2.105612  3999.949141]\t[-10000.            3.            0.083012]\t[     0.66619     14.       10000.     ]   \n",
      "6  \t27    \t[-1399.459362     8.48      1400.108287]\t[ 3470.088448     1.486472  3469.826624]\t[-10000.            4.            0.099363]\t[     0.66619     12.       10000.     ]   \n",
      "7  \t26    \t[-1399.442857     8.58      1400.109366]\t[ 3470.095107     1.184736  3469.826188]\t[-10000.            6.            0.095219]\t[     0.66619     12.       10000.     ]   \n",
      "8  \t29    \t[-1199.422133     8.52      1200.112749]\t[ 3249.828753     0.964158  3249.573727]\t[-10000.            7.            0.095219]\t[     0.66619     12.       10000.     ]   \n",
      "9  \t24    \t[-799.3962      8.34      800.116628]   \t[ 2713.110044     0.79019   2712.897602]\t[-10000.            7.            0.072545]\t[     0.673333     12.        10000.      ]\n",
      "10 \t29    \t[-1399.428038     8.44      1400.110489]\t[ 3470.101086     1.116423  3469.825735]\t[-10000.            6.            0.110044]\t[     0.673333     13.        10000.      ]\n",
      "11 \t28    \t[-999.402943    8.54     1000.111943]   \t[ 3000.199019     0.899111  2999.962686]\t[-10000.           6.           0.10911]   \t[     0.673333     11.        10000.      ]\n",
      "12 \t23    \t[-799.391143    8.82      800.107809]   \t[ 2713.111536     0.93145   2712.900202]\t[-10000.            6.            0.093993]\t[     0.673333     13.        10000.      ]\n",
      "13 \t23    \t[-799.383362    9.2       800.102358]   \t[ 2713.11383      1.131371  2712.90181 ]\t[-10000.            8.            0.099897]\t[     0.673333     16.        10000.      ]\n",
      "14 \t30    \t[-1399.425067     9.34      1400.094487]\t[ 3470.102285     0.971802  3469.832192]\t[-10000.           8.           0.07461]   \t[     0.673333     13.        10000.      ]\n",
      "15 \t34    \t[-1999.462857     9.38      2000.088903]\t[ 4000.268571     0.891964  3999.955549]\t[-10000.            9.            0.110044]\t[     0.673333     13.        10000.      ]\n",
      "16 \t30    \t[-2799.519133     9.44      2800.079385]\t[ 4490.288737     0.852291  4489.939359]\t[-10000.            8.            0.096878]\t[     0.673333     12.        10000.      ]\n",
      "17 \t24    \t[-1999.46261      9.32      2000.087422]\t[ 4000.268695     0.810925  3999.956289]\t[-10000.            8.            0.092539]\t[     0.673333     12.        10000.      ]\n",
      "18 \t31    \t[-1799.447867     9.34      1800.090236]\t[ 3842.133229     0.79019   3841.832265]\t[-10000.            9.            0.110044]\t[     0.673333     12.        10000.      ]\n",
      "19 \t26    \t[-999.394      9.18    1000.09904]      \t[ 3000.202        0.589576  2999.966987]\t[-10000.            9.            0.110044]\t[     0.673333     12.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Al',\n",
       " 'K',\n",
       " 'Fe',\n",
       " 'cos(2*pi*(RI-min(RI)+Al-min(Al)))/(max(RI)+max(Al)-min(RI)-min(Al))',\n",
       " 'cos(2*pi*(RI-min(RI)+Si-min(Si)))/(max(RI)+max(Si)-min(RI)-min(Si))',\n",
       " 'cos(2*pi*(RI-min(RI)+Fe-min(Fe)))/(max(RI)+max(Fe)-min(RI)-min(Fe))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+Si-min(Si)))/(max(Mg)+max(Si)-min(Mg)-min(Si))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+Fe-min(Fe)))/(max(Mg)+max(Fe)-min(Mg)-min(Fe))',\n",
       " 'cos(2*pi*(K-min(K)+Ca-min(Ca)))/(max(K)+max(Ca)-min(K)-min(Ca))']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.67      0.64        27\n",
      "           2       0.50      0.73      0.59        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.61        71\n",
      "   macro avg       0.50      0.46      0.47        71\n",
      "weighted avg       0.56      0.61      0.57        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6080086580086579\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(svm_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "search_space = [{'classifier': [SVC(kernel='linear')]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 118 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', SVC(kernel='linear'))]),\n",
       "             param_grid=[{'classifier': [SVC(kernel='linear')]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "svm_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(svm_variance,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6785714285714286\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(svm_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [SVC()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 86.8 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000001F2FFE2F1F0>)),\n",
       "                                       ('classifier', SVC())]),\n",
       "             param_grid=[{'classifier': [SVC()]}])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "svm_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(svm_chi,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.4698    5.04      0.111182]\t[ 0.073841  2.770993  0.03046 ]\t[ 0.315238  1.        0.046474]\t[ 0.623333  9.        0.162545]\n",
      "1  \t23    \t[-999.524629    6.5      1000.099442]\t[ 3000.158458     2.609598  2999.966853]\t[-10000.            1.            0.061027]\t[     0.629048     13.        10000.      ]\n",
      "2  \t34    \t[-799.494067    6.86      800.093397]\t[ 2713.081185     2.181834  2712.904452]\t[-10000.            3.            0.061027]\t[     0.629048     12.        10000.      ]\n",
      "3  \t34    \t[-799.468667    6.3       800.090987]\t[ 2713.088675     2.042058  2712.905163]\t[-10000.           2.           0.06369]   \t[     0.63     11.    10000.  ]            \n",
      "4  \t25    \t[-399.43479     5.9       400.091018]\t[ 1959.707168     1.982423  1959.573215]\t[-10000.           2.           0.06369]   \t[     0.650952     12.        10000.      ]\n",
      "5  \t27    \t[-199.403286    5.84      200.094078]\t[ 1400.085245     1.419296  1399.986561]\t[-10000.           3.           0.06369]   \t[     0.650952     10.        10000.      ]\n",
      "6  \t31    \t[ 0.601514  5.94      0.097077]      \t[ 0.036049  1.287012  0.028016]         \t[ 0.523333  3.        0.06369 ]            \t[ 0.673333  9.        0.164261]            \n",
      "7  \t30    \t[ 0.611276  5.58      0.08867 ]      \t[ 0.034782  1.218031  0.023807]         \t[ 0.495238  3.        0.06369 ]            \t[ 0.673333  9.        0.164261]            \n",
      "8  \t22    \t[ 0.624924  5.52      0.095652]      \t[ 0.030568  1.315143  0.025089]         \t[ 0.551905  3.        0.06369 ]            \t[ 0.673333  9.        0.143114]            \n",
      "9  \t32    \t[-399.397305    6.06      400.099749]\t[ 1959.714819     1.592608  1959.571433]\t[-10000.            3.            0.054793]\t[     0.673333     11.        10000.      ]\n",
      "10 \t33    \t[ 0.638114  6.1       0.109736]      \t[ 0.034832  1.431782  0.022095]         \t[ 0.545238  3.        0.057073]            \t[ 0.68      9.        0.197596]            \n",
      "11 \t30    \t[-399.37179    6.04     400.11051]   \t[ 1959.720027     1.310878  1959.569237]\t[-10000.            3.            0.075654]\t[     0.687143     10.        10000.      ]\n",
      "12 \t33    \t[-199.357857    6.02      200.109921]\t[ 1400.091735     1.37826   1399.984297]\t[-10000.            3.            0.084144]\t[     0.687143     10.        10000.      ]\n",
      "13 \t28    \t[-199.349914    6.12      200.107973]\t[ 1400.09287      1.16      1399.984575]\t[-10000.            4.            0.071665]\t[     0.687143     10.        10000.      ]\n",
      "14 \t31    \t[-199.340571    6.52      200.109275]\t[ 1400.094204     1.299846  1399.984389]\t[-10000.            4.            0.092194]\t[     0.687143     11.        10000.      ]\n",
      "15 \t32    \t[-199.33681     6.78      200.111472]\t[ 1400.094742     1.025475  1399.984076]\t[-10000.            4.            0.103648]\t[     0.687143     10.        10000.      ]\n",
      "16 \t18    \t[-399.345952    7.3       400.110933]\t[ 1959.725301     0.943398  1959.56915 ]\t[-10000.            7.            0.107851]\t[     0.687143     12.        10000.      ]\n",
      "17 \t24    \t[ 0.683467  7.12      0.115011]      \t[ 0.013607  0.430813  0.009923]         \t[ 0.609048  7.        0.105667]            \t[ 0.687143  9.        0.18187 ]            \n",
      "18 \t29    \t[-399.350886    7.34      400.111291]\t[ 1959.724294     0.907965  1959.569077]\t[-10000.            7.            0.107522]\t[     0.687143     12.        10000.      ]\n",
      "19 \t30    \t[-599.358295    7.32      600.108718]\t[ 2375.030541     0.810925  2374.84095 ]\t[-10000.            7.            0.103648]\t[     0.687143     10.        10000.      ]\n",
      "20 \t30    \t[-799.371495    7.36      800.10543 ]\t[ 2713.117329     0.866256  2712.900904]\t[-10000.            7.            0.093339]\t[     0.687143     10.        10000.      ]\n",
      "21 \t32    \t[-799.382238    7.42      800.105339]\t[ 2713.114162     1.132961  2712.90093 ]\t[-10000.            5.            0.077868]\t[     0.687143     11.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI',\n",
       " 'Na',\n",
       " 'Al',\n",
       " 'K',\n",
       " 'Ba',\n",
       " 'cos(2*pi*(RI-min(RI)+Mg-min(Mg)))/(max(RI)+max(Mg)-min(RI)-min(Mg))',\n",
       " 'cos(2*pi*(Al-min(Al)+Ba-min(Ba)))/(max(Al)+max(Ba)-min(Al)-min(Ba))']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.96      0.78        27\n",
      "           2       0.68      0.68      0.68        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       1.00      0.80      0.89        10\n",
      "\n",
      "    accuracy                           0.70        71\n",
      "   macro avg       0.56      0.49      0.50        71\n",
      "weighted avg       0.63      0.70      0.65        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5519480519480519\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(svm_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', GaussianNB())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.63 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000001F28005BD30>)),\n",
       "                                       ('classifier', GaussianNB())]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [GaussianNB()]}])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nb_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(nb_info,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.376848  4.4       0.100338]\t[ 0.089912  2.135416  0.03149 ]\t[ 0.208571  1.        0.036873]\t[ 0.539524  9.        0.16686 ]\n",
      "1  \t25    \t[-799.588781    5.72      800.10305 ]\t[ 2713.053256     2.46609   2712.901606]\t[-10000.            1.            0.036873]\t[     0.547143     13.        10000.      ]\n",
      "2  \t32    \t[-799.568686    6.1       800.107211]\t[ 2713.059182     2.147091  2712.900379]\t[-10000.            1.            0.041853]\t[     0.575238     11.        10000.      ]\n",
      "3  \t29    \t[-599.531162    6.12      600.114745]\t[ 2374.986868     2.205811  2374.839428]\t[-10000.            3.            0.064356]\t[     0.575238     12.        10000.      ]\n",
      "4  \t22    \t[ 0.534086  5.86      0.121268]      \t[ 0.049371  1.886902  0.027225]         \t[ 0.292857  3.        0.063154]            \t[ 0.63      9.        0.182314]            \n",
      "5  \t22    \t[-199.447352    7.08      200.124936]\t[ 1400.07895      1.706927  1399.982152]\t[-10000.            3.            0.066079]\t[     0.63     12.    10000.  ]            \n",
      "6  \t31    \t[-1599.519524     7.92      1600.103061]\t[ 3666.270253     1.753169  3666.015576]\t[-10000.            4.            0.059362]\t[     0.63     11.    10000.  ]            \n",
      "7  \t22    \t[-999.466171    8.       1000.112634]   \t[ 3000.177943     1.67332   2999.962455]\t[-10000.            5.            0.086511]\t[     0.637143     13.        10000.      ]\n",
      "8  \t27    \t[-1399.472429     8.54      1400.099961]\t[ 3470.083176     1.359559  3469.829983]\t[-10000.            4.            0.078911]\t[     0.637143     11.        10000.      ]\n",
      "9  \t28    \t[-1199.447514     8.66      1200.098471]\t[ 3249.819381     1.176605  3249.578999]\t[-10000.            6.            0.102266]\t[     0.637143     11.        10000.      ]\n",
      "10 \t32    \t[-799.422924    8.1       800.104593]   \t[ 2713.102164     1.118034  2712.90115 ]\t[-10000.            6.            0.086557]\t[     0.637143     11.        10000.      ]\n",
      "11 \t24    \t[-799.41921     7.86      800.108833]   \t[ 2713.103259     1.216717  2712.8999  ]\t[-10000.            6.            0.102266]\t[     0.637143     12.        10000.      ]\n",
      "12 \t34    \t[-399.410238    7.44      400.116894]   \t[ 1959.71218      0.962497  1959.567933]\t[-10000.            7.            0.084205]\t[     0.637143     11.        10000.      ]\n",
      "13 \t31    \t[ 0.633486  7.2       0.123437]         \t[ 0.013001  0.6       0.006215]         \t[ 0.560476  7.        0.096633]            \t[ 0.642857  9.        0.139816]            \n",
      "14 \t34    \t[-599.403543    7.48      600.113327]   \t[ 2375.01911      0.943186  2374.839786]\t[-10000.            7.            0.096633]\t[     0.642857     10.        10000.      ]\n",
      "15 \t35    \t[-399.403562    7.56      400.111999]   \t[ 1959.713543     1.042305  1959.568933]\t[-10000.            7.            0.065881]\t[     0.642857     12.        10000.      ]\n",
      "16 \t25    \t[-599.404438    7.94      600.106069]   \t[ 2375.018884     1.102905  2374.84162 ]\t[-10000.           7.           0.09293]   \t[     0.642857     12.        10000.      ]\n",
      "17 \t22    \t[-999.425848    8.36     1000.094388]   \t[ 3000.191384     1.015086  2999.968537]\t[-10000.            7.            0.085295]\t[     0.642857     11.        10000.      ]\n",
      "18 \t26    \t[-399.386514    8.34      400.095568]   \t[ 1959.717022     0.737835  1959.572287]\t[-10000.            7.            0.087422]\t[     0.642857     11.        10000.      ]\n",
      "19 \t27    \t[-399.386295    8.14      400.094091]   \t[ 1959.717066     0.721388  1959.572588]\t[-10000.            7.            0.095913]\t[     0.642857     12.        10000.      ]\n",
      "20 \t25    \t[-399.384933    8.2       400.093308]   \t[ 1959.717344     0.916515  1959.572748]\t[-10000.            7.            0.080283]\t[     0.642857     13.        10000.      ]\n",
      "21 \t25    \t[-399.385495    8.22      400.09403 ]   \t[ 1959.71723      0.672012  1959.572601]\t[-10000.            8.            0.087422]\t[     0.642857     12.        10000.      ]\n",
      "22 \t34    \t[-799.413181    8.3       800.091741]   \t[ 2713.105037     1.044031  2712.90494 ]\t[-10000.            8.            0.079345]\t[     0.651429     14.        10000.      ]\n",
      "23 \t34    \t[-999.426562    8.24     1000.091183]   \t[ 3000.191146     0.708802  2999.969606]\t[-10000.            7.            0.079267]\t[     0.651429     10.        10000.      ]\n",
      "24 \t27    \t[-1399.454133     8.42      1400.086114]\t[ 3470.090558     1.021567  3469.83557 ]\t[-10000.           7.           0.09128]   \t[     0.651429     12.        10000.      ]\n",
      "25 \t34    \t[-1599.464676     8.44      1600.089019]\t[ 3666.29419      0.92      3666.021705]\t[-10000.            7.            0.080283]\t[     0.651429     11.        10000.      ]\n",
      "26 \t29    \t[-999.431524    8.44     1000.097271]   \t[ 3000.189492     1.116423  2999.967576]\t[-10000.            6.            0.080283]\t[     0.651429     13.        10000.      ]\n",
      "27 \t35    \t[-1399.4528       8.52      1400.090718]\t[ 3470.091095     0.943186  3469.833712]\t[-10000.            7.            0.080283]\t[     0.651429     11.        10000.      ]\n",
      "28 \t32    \t[-999.424933    8.36     1000.100198]   \t[ 3000.191689     0.889044  2999.966601]\t[-10000.            7.            0.080283]\t[     0.651429     11.        10000.      ]\n",
      "29 \t32    \t[-1799.47959     8.68     1800.09957]   \t[ 3842.118366     1.223765  3841.827892]\t[-10000.            7.            0.080283]\t[     0.651429     13.        10000.      ]\n",
      "30 \t31    \t[-799.406771    8.32      800.115062]   \t[ 2713.106927     0.968297  2712.898063]\t[-10000.            5.            0.100583]\t[     0.651429     12.        10000.      ]\n",
      "31 \t21    \t[-1199.435352     8.44      1200.111184]\t[ 3249.823872     1.08      3249.574304]\t[-10000.            7.            0.090282]\t[     0.651429     13.        10000.      ]\n",
      "32 \t26    \t[-599.3912      8.2       600.122124]   \t[ 2375.022228     0.52915   2374.837563]\t[-10000.            8.            0.100583]\t[     0.651429     10.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Na',\n",
       " 'Al',\n",
       " 'K',\n",
       " 'cos(2*pi*(RI-min(RI)+Mg-min(Mg)))/(max(RI)+max(Mg)-min(RI)-min(Mg))',\n",
       " 'cos(2*pi*(Al-min(Al)+Si-min(Si)))/(max(Al)+max(Si)-min(Al)-min(Si))',\n",
       " 'cos(2*pi*(Al-min(Al)+K-min(K)))/(max(Al)+max(K)-min(Al)-min(K))',\n",
       " 'cos(2*pi*(Al-min(Al)+Ba-min(Ba)))/(max(Al)+max(Ba)-min(Al)-min(Ba))',\n",
       " 'cos(2*pi*(K-min(K)+Ba-min(Ba)))/(max(K)+max(Ba)-min(K)-min(Ba))']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.93      0.77        27\n",
      "           2       0.62      0.68      0.65        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.66        71\n",
      "   macro avg       0.34      0.38      0.36        71\n",
      "weighted avg       0.55      0.66      0.60        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4813852813852814\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(nb_info, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', GaussianNB())])\n",
    "\n",
    "search_space = [{'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', GaussianNB())]),\n",
       "             param_grid=[{'classifier': [GaussianNB()]}], scoring='accuracy')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "nb_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(nb_variance,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.370514  4.78      0.09975 ]\t[ 0.096921  2.60223   0.02929 ]\t[ 0.180476  1.        0.041853]\t[ 0.53381   9.        0.188687]\n",
      "1  \t16    \t[ 0.462495  3.94      0.106702]\t[ 0.055444  2.27517   0.029668]\t[ 0.33619   1.        0.059417]\t[ 0.581429  9.        0.188687]\n",
      "2  \t29    \t[ 0.492962  3.22      0.098106]\t[ 0.07047   1.526958  0.023796]\t[ 0.195238  1.        0.052702]\t[ 0.608571  8.        0.146558]\n",
      "3  \t27    \t[ 0.534886  3.74      0.098939]\t[ 0.053881  1.368357  0.026963]\t[ 0.364286  1.        0.055216]\t[ 0.62381   8.        0.157097]\n",
      "4  \t35    \t[ 0.57379   4.44      0.102095]\t[ 0.052422  1.416474  0.024975]\t[ 0.405714  1.        0.057704]\t[ 0.651905  7.        0.153227]\n",
      "5  \t22    \t[ 0.592924  5.        0.097257]\t[ 0.060501  1.442221  0.023711]\t[ 0.300476  1.        0.052778]\t[ 0.651905  8.        0.138954]\n",
      "6  \t20    \t[-799.433762    6.        800.095882]\t[ 2713.098968     1.865476  2712.903719]\t[-10000.            3.            0.064994]\t[     0.657619     12.        10000.      ]\n",
      "7  \t24    \t[-199.385638    6.02      200.101508]\t[ 1400.087766     1.029369  1399.985499]\t[-10000.            4.            0.069504]\t[     0.657619     10.        10000.      ]\n",
      "8  \t25    \t[ 0.637971  6.2       0.10199 ]      \t[ 0.029439  0.69282   0.015263]         \t[ 0.518095  4.        0.069504]            \t[ 0.657619  8.        0.141674]            \n",
      "9  \t30    \t[ 0.643752  6.06      0.104471]      \t[ 0.021079  0.858138  0.013356]         \t[ 0.568095  5.        0.069504]            \t[ 0.657619  9.        0.146527]            \n",
      "10 \t30    \t[ 0.640819  6.02      0.106033]      \t[ 0.024354  1.029369  0.01282 ]         \t[ 0.574286  5.        0.087532]            \t[ 0.657619  8.        0.153662]            \n",
      "11 \t25    \t[ 0.645067  5.72      0.105431]      \t[ 0.022734  0.895321  0.014128]         \t[ 0.566667  5.        0.096002]            \t[ 0.657619  9.        0.172273]            \n",
      "12 \t29    \t[ 0.640057  5.5       0.10023 ]      \t[ 0.055278  1.024695  0.01248 ]         \t[ 0.3       5.        0.073802]            \t[ 0.657619  9.        0.152333]            \n",
      "13 \t32    \t[ 0.620495  5.48      0.100222]      \t[ 0.094073  0.943186  0.018051]         \t[ 0.258095  5.        0.060151]            \t[ 0.657619  9.        0.176371]            \n",
      "14 \t34    \t[ 0.631467  5.48      0.100836]      \t[ 0.061425  1.23677   0.015582]         \t[ 0.285238  3.        0.070484]            \t[ 0.657619  9.        0.169861]            \n",
      "15 \t35    \t[ 0.623695  5.62      0.101668]      \t[ 0.080463  1.146996  0.014191]         \t[ 0.265238  5.        0.071341]            \t[ 0.657619  9.        0.148205]            \n",
      "16 \t22    \t[ 0.6526    5.26      0.099852]      \t[ 0.015373  0.769675  0.012349]         \t[ 0.57381   5.        0.089317]            \t[ 0.657619  9.        0.161628]            \n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Na',\n",
       " 'Al',\n",
       " 'cos(2*pi*(Mg-min(Mg)+Al-min(Al)))/(max(Mg)+max(Al)-min(Mg)-min(Al))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+Fe-min(Fe)))/(max(Mg)+max(Fe)-min(Mg)-min(Fe))',\n",
       " 'cos(2*pi*(K-min(K)+Ba-min(Ba)))/(max(K)+max(Ba)-min(K)-min(Ba))']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.89      0.75        27\n",
      "           2       0.64      0.64      0.64        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.73      0.80      0.76        10\n",
      "\n",
      "    accuracy                           0.65        71\n",
      "   macro avg       0.34      0.39      0.36        71\n",
      "weighted avg       0.55      0.65      0.59        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4813852813852814\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(nb_variance, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 56.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000001F2FFE2F1F0>)),\n",
       "                                       ('classifier', GaussianNB())]),\n",
       "             param_grid=[{'classifier': [GaussianNB()]}])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nb_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(nb_chi,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.358686  4.4       0.09594 ]\t[ 0.102615  2.253886  0.030252]\t[ 0.173333  1.        0.032857]\t[ 0.573333  8.        0.16724 ]\n",
      "1  \t30    \t[-399.581457    5.26      400.109056]\t[ 1959.677231     2.406741  1959.569534]\t[-10000.            1.            0.047954]\t[     0.573333     11.        10000.      ]\n",
      "2  \t29    \t[-399.53879     6.26      400.111463]\t[ 1959.68594      2.152301  1959.569042]\t[-10000.            1.            0.062277]\t[     0.573333     10.        10000.      ]\n",
      "3  \t34    \t[-1199.540067     6.9       1200.093247]\t[ 3249.785204     1.931321  3249.580928]\t[-10000.            3.            0.073446]\t[     0.609048     12.        10000.      ]\n",
      "4  \t25    \t[-599.468505    6.9       600.097934]   \t[ 2375.002697     1.445683  2374.843675]\t[-10000.            4.            0.073446]\t[     0.623333     11.        10000.      ]\n",
      "5  \t28    \t[-199.423419    6.8       200.096198]   \t[ 1400.082369     1.019804  1399.986258]\t[-10000.            6.            0.073446]\t[     0.65     11.    10000.  ]            \n",
      "6  \t22    \t[-199.4218      7.08      200.104471]   \t[ 1400.082602     1.036147  1399.985076]\t[-10000.            5.            0.065238]\t[     0.651429     11.        10000.      ]\n",
      "7  \t25    \t[-999.457629    7.54     1000.104012]   \t[ 3000.180791     1.359559  2999.965329]\t[-10000.            4.            0.070784]\t[     0.658571     12.        10000.      ]\n",
      "8  \t31    \t[-399.400943    7.68      400.11335 ]   \t[ 1959.714077     1.008762  1959.568657]\t[-10000.            5.            0.073446]\t[     0.658571     11.        10000.      ]\n",
      "9  \t26    \t[-799.418533    7.72      800.110138]   \t[ 2713.103459     1.096175  2712.899515]\t[-10000.            6.            0.084442]\t[     0.658571     11.        10000.      ]\n",
      "10 \t30    \t[-199.391524    7.62      200.116563]   \t[ 1400.086928     1.037111  1399.983348]\t[-10000.            5.            0.083972]\t[     0.659048     10.        10000.      ]\n",
      "11 \t27    \t[-799.414048    7.88      800.116584]   \t[ 2713.104782     1.177115  2712.897614]\t[-10000.            6.            0.067907]\t[     0.665238     12.        10000.      ]\n",
      "12 \t33    \t[-1399.443429     8.28      1400.115518]\t[ 3470.094877     1.371714  3469.823706]\t[-10000.            6.            0.071359]\t[     0.687143     15.        10000.      ]\n",
      "13 \t33    \t[-1599.453648     8.4       1600.117199]\t[ 3666.299004     1.03923   3666.009406]\t[-10000.            6.            0.097405]\t[     0.687143     13.        10000.      ]\n",
      "14 \t32    \t[-599.381467    8.2       600.132407]   \t[ 2375.024687     0.894427  2374.834966]\t[-10000.            6.            0.096002]\t[     0.687619     11.        10000.      ]\n",
      "15 \t32    \t[-1599.436714     8.78      1600.127222]\t[ 3666.306394     0.985698  3666.005032]\t[-10000.           8.           0.11419]   \t[     0.687619     12.        10000.      ]\n",
      "16 \t22    \t[-1199.4008       8.94      1200.138894]\t[ 3249.836631     0.75921   3249.564072]\t[-10000.           8.           0.11419]   \t[     0.687619     12.        10000.      ]\n",
      "17 \t37    \t[-1399.419848     9.26      1400.13682 ]\t[ 3470.104391     1.1456    3469.815111]\t[-10000.            8.            0.109616]\t[     0.687619     14.        10000.      ]\n",
      "18 \t29    \t[-1799.436762     9.4       1800.133228]\t[ 3842.138431     1.03923   3841.812122]\t[-10000.            8.            0.148321]\t[     0.69381     13.       10000.     ]   \n",
      "19 \t28    \t[-1599.429229     9.3       1600.136744]\t[ 3666.309661     0.943398  3666.000876]\t[-10000.            8.            0.131371]\t[     0.69381     13.       10000.     ]   \n",
      "20 \t25    \t[-1799.436467     9.26      1800.13548 ]\t[ 3842.13857      0.934024  3841.811067]\t[-10000.            8.            0.154818]\t[     0.69381     13.       10000.     ]   \n",
      "21 \t27    \t[-1599.422562     9.22      1600.141304]\t[ 3666.312571     0.782049  3665.998886]\t[-10000.            8.            0.154818]\t[     0.69381     12.       10000.     ]   \n",
      "22 \t20    \t[-1399.40899      9.18      1400.148926]\t[ 3470.108771     0.712461  3469.810227]\t[-10000.            8.            0.154818]\t[     0.69381     12.       10000.     ]   \n",
      "23 \t35    \t[-1799.43461      9.4       1800.145408]\t[ 3842.13944      1.03923   3841.806416]\t[-10000.            8.            0.155882]\t[     0.69381     13.       10000.     ]   \n",
      "24 \t31    \t[-1399.405171     9.24      1400.153299]\t[ 3470.110312     0.68      3469.808462]\t[-10000.            9.            0.152292]\t[     0.69381     12.       10000.     ]   \n",
      "25 \t25    \t[-999.380676    9.18     1000.159864]   \t[ 3000.206441     0.766551  2999.946712]\t[-10000.            7.            0.113793]\t[     0.69381     12.       10000.     ]   \n",
      "26 \t27    \t[-1599.419038     9.34      1600.149337]\t[ 3666.314109     1.069766  3665.99538 ]\t[-10000.            8.            0.137951]\t[     0.707619     14.        10000.      ]\n",
      "27 \t30    \t[-1599.428086     9.14      1600.148545]\t[ 3666.31016      0.872009  3665.995726]\t[-10000.            7.            0.117213]\t[     0.707619     12.        10000.      ]\n",
      "28 \t29    \t[-1399.41939      9.14      1400.149716]\t[ 3470.104576     1.296302  3469.809908]\t[-10000.            7.            0.098309]\t[     0.707619     14.        10000.      ]\n",
      "29 \t25    \t[-399.329524    8.78      400.169438]   \t[ 1959.728655     0.782049  1959.557208]\t[-10000.            8.            0.171748]\t[     0.707619     13.        10000.      ]\n",
      "30 \t28    \t[-1599.41381      8.78      1600.145547]\t[ 3666.31639      0.878408  3665.997034]\t[-10000.            7.            0.127505]\t[     0.707619     11.        10000.      ]\n",
      "31 \t27    \t[-799.358333    8.46      800.158518]   \t[ 2713.121211     1.2839    2712.885249]\t[-10000.            6.            0.133081]\t[     0.707619     14.        10000.      ]\n",
      "32 \t33    \t[-199.317419    8.1       200.167841]   \t[ 1400.097512     0.608276  1399.976023]\t[-10000.            6.            0.108889]\t[     0.707619     11.        10000.      ]\n",
      "33 \t27    \t[-799.358629    8.14      800.155706]   \t[ 2713.121123     0.632772  2712.886078]\t[-10000.            7.            0.118751]\t[     0.707619     10.        10000.      ]\n",
      "34 \t23    \t[-1199.388114     8.4       1200.149471]\t[ 3249.841316     1.077033  3249.560166]\t[-10000.            7.            0.131863]\t[     0.707619     12.        10000.      ]\n",
      "35 \t34    \t[-999.366067    8.32     1000.15484 ]   \t[ 3000.211311     0.926067  2999.948387]\t[-10000.            8.            0.171748]\t[     0.707619     13.        10000.      ]\n",
      "36 \t31    \t[-599.338057    8.14      600.161467]   \t[ 2375.035654     0.721388  2374.827623]\t[-10000.            7.            0.130986]\t[     0.707619     12.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI',\n",
       " 'Al',\n",
       " 'K',\n",
       " 'cos(2*pi*(Na-min(Na)+Ba-min(Ba)))/(max(Na)+max(Ba)-min(Na)-min(Ba))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+K-min(K)))/(max(Mg)+max(K)-min(Mg)-min(K))',\n",
       " 'cos(2*pi*(Mg-min(Mg)+Ca-min(Ca)))/(max(Mg)+max(Ca)-min(Mg)-min(Ca))',\n",
       " 'cos(2*pi*(Al-min(Al)+Si-min(Si)))/(max(Al)+max(Si)-min(Al)-min(Si))',\n",
       " 'cos(2*pi*(Ba-min(Ba)+Fe-min(Fe)))/(max(Ba)+max(Fe)-min(Ba)-min(Fe))']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.59      0.60        27\n",
      "           2       0.56      0.82      0.67        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       1.00      0.67      0.80         3\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       1.00      0.70      0.82        10\n",
      "\n",
      "    accuracy                           0.62        71\n",
      "   macro avg       0.70      0.55      0.59        71\n",
      "weighted avg       0.62      0.62      0.60        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4813852813852814\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(nb_chi, X, y, cv=10).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
