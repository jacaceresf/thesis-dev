{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Execute imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn-genetic in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from sklearn-genetic) (0.23.2)\n",
      "Requirement already satisfied: deap>=1.0.2 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from sklearn-genetic) (1.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from sklearn-genetic) (1.19.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from sklearn-genetic) (0.70.12.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->sklearn-genetic) (2.1.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->sklearn-genetic) (1.5.2)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->sklearn-genetic) (0.17.0)\n",
      "Requirement already satisfied: dill>=0.3.4 in c:\\users\\walter ortiz\\anaconda3\\lib\\site-packages (from multiprocess->sklearn-genetic) (0.3.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\walter ortiz\\anaconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn-genetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from genetic_selection import GeneticSelectionCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glass = pd.read_csv('glass.csv', delimiter=',')\n",
    "X = pd.read_csv('glass_formula_c.csv', delimiter=',')\n",
    "y = data_glass['Type']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>RI*Na</th>\n",
       "      <th>...</th>\n",
       "      <th>Si*K</th>\n",
       "      <th>Si*Ca</th>\n",
       "      <th>Si*Ba</th>\n",
       "      <th>Si*Fe</th>\n",
       "      <th>K*Ca</th>\n",
       "      <th>K*Ba</th>\n",
       "      <th>K*Fe</th>\n",
       "      <th>Ca*Ba</th>\n",
       "      <th>Ca*Fe</th>\n",
       "      <th>Ba*Fe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.746576</td>\n",
       "      <td>...</td>\n",
       "      <td>4.3068</td>\n",
       "      <td>628.0750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.079603</td>\n",
       "      <td>...</td>\n",
       "      <td>34.9104</td>\n",
       "      <td>569.4759</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7584</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.513915</td>\n",
       "      <td>...</td>\n",
       "      <td>28.4661</td>\n",
       "      <td>567.8622</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0342</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.048289</td>\n",
       "      <td>...</td>\n",
       "      <td>41.3877</td>\n",
       "      <td>596.8542</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.6854</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.136163</td>\n",
       "      <td>...</td>\n",
       "      <td>40.1940</td>\n",
       "      <td>589.7556</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4385</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.439492</td>\n",
       "      <td>...</td>\n",
       "      <td>5.8088</td>\n",
       "      <td>666.5598</td>\n",
       "      <td>76.9666</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7344</td>\n",
       "      <td>0.0848</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.7308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.631402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>613.7040</td>\n",
       "      <td>116.1654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.3560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.836534</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>619.6648</td>\n",
       "      <td>120.4088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.8416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.807414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>624.2128</td>\n",
       "      <td>115.5677</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.3136</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.588475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>632.3632</td>\n",
       "      <td>122.5112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.3954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>214 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe      RI*Na  ...  \\\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0  20.746576  ...   \n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0  21.079603  ...   \n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0  20.513915  ...   \n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0  20.048289  ...   \n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0  20.136163  ...   \n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...  ...        ...  ...   \n",
       "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0  21.439492  ...   \n",
       "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0  22.631402  ...   \n",
       "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0  21.836534  ...   \n",
       "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0  21.807414  ...   \n",
       "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0  21.588475  ...   \n",
       "\n",
       "        Si*K     Si*Ca     Si*Ba  Si*Fe    K*Ca    K*Ba  K*Fe    Ca*Ba  Ca*Fe  \\\n",
       "0     4.3068  628.0750    0.0000    0.0  0.5250  0.0000   0.0   0.0000    0.0   \n",
       "1    34.9104  569.4759    0.0000    0.0  3.7584  0.0000   0.0   0.0000    0.0   \n",
       "2    28.4661  567.8622    0.0000    0.0  3.0342  0.0000   0.0   0.0000    0.0   \n",
       "3    41.3877  596.8542    0.0000    0.0  4.6854  0.0000   0.0   0.0000    0.0   \n",
       "4    40.1940  589.7556    0.0000    0.0  4.4385  0.0000   0.0   0.0000    0.0   \n",
       "..       ...       ...       ...    ...     ...     ...   ...      ...    ...   \n",
       "209   5.8088  666.5598   76.9666    0.0  0.7344  0.0848   0.0   9.7308    0.0   \n",
       "210   0.0000  613.7040  116.1654    0.0  0.0000  0.0000   0.0  13.3560    0.0   \n",
       "211   0.0000  619.6648  120.4088    0.0  0.0000  0.0000   0.0  13.8416    0.0   \n",
       "212   0.0000  624.2128  115.5677    0.0  0.0000  0.0000   0.0  13.3136    0.0   \n",
       "213   0.0000  632.3632  122.5112    0.0  0.0000  0.0000   0.0  14.3954    0.0   \n",
       "\n",
       "     Ba*Fe  \n",
       "0      0.0  \n",
       "1      0.0  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "..     ...  \n",
       "209    0.0  \n",
       "210    0.0  \n",
       "211    0.0  \n",
       "212    0.0  \n",
       "213    0.0  \n",
       "\n",
       "[214 rows x 45 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.25 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000001DA89F68D30>)),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [KNeighborsClassifier()]}])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "knn_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "knn_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size=0.2,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(knn_info,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.560248  4.54      0.093959]\t[ 0.092245  2.515631  0.02211 ]\t[ 0.33366   1.        0.047637]\t[ 0.696405  9.        0.143047]\n",
      "1  \t28    \t[-999.441601    6.86     1000.083892]\t[ 3000.186133     2.482015  2999.972036]\t[-10000.            1.            0.056183]\t[     0.696405     12.        10000.      ]\n",
      "2  \t29    \t[-1799.472765     7.92      1800.082925]\t[ 3842.121564     1.895679  3841.83569 ]\t[-10000.            2.            0.056998]\t[     0.696405     11.        10000.      ]\n",
      "3  \t37    \t[-1399.441327     7.56      1400.081638]\t[ 3470.095724     1.961224  3469.837376]\t[-10000.            2.            0.056998]\t[     0.719935     12.        10000.      ]\n",
      "4  \t30    \t[-799.380255    7.78      800.089171]   \t[ 2713.114746     1.616045  2712.905698]\t[-10000.            4.            0.063718]\t[     0.725817     12.        10000.      ]\n",
      "5  \t25    \t[-199.328837    7.3       200.092299]   \t[ 1400.095881     1.284523  1399.986814]\t[-10000.            4.            0.063718]\t[     0.725817     10.        10000.      ]\n",
      "6  \t35    \t[-799.356418    7.46      800.087756]   \t[ 2713.121775     1.486069  2712.906116]\t[-10000.            5.            0.056498]\t[     0.743791     12.        10000.      ]\n",
      "7  \t29    \t[-999.359725    8.2      1000.087816]   \t[ 3000.213425     1.4       2999.970728]\t[-10000.            5.            0.065978]\t[     0.743791     12.        10000.      ]\n",
      "8  \t28    \t[-1599.393359     8.46      1600.081913]\t[ 3666.325316     1.458904  3666.024806]\t[-10000.            5.            0.081136]\t[     0.743791     12.        10000.      ]\n",
      "9  \t33    \t[-1199.356275     8.4       1200.086892]\t[ 3249.853073     1.        3249.583275]\t[-10000.            6.            0.084114]\t[     0.743791     12.        10000.      ]\n",
      "10 \t34    \t[-599.305235    8.3       600.095884]   \t[ 2375.043947     0.67082   2374.844193]\t[-10000.            7.            0.074465]\t[     0.743791     11.        10000.      ]\n",
      "11 \t31    \t[-1199.349817     8.42      1200.091572]\t[ 3249.855458     1.040961  3249.581547]\t[-10000.            8.            0.080899]\t[     0.743791     12.        10000.      ]\n",
      "12 \t28    \t[-599.30483    8.16     600.09822]      \t[ 2375.044049     0.731027  2374.843602]\t[-10000.            7.            0.104199]\t[     0.743791     12.        10000.      ]\n",
      "13 \t35    \t[-799.319013    8.28      800.095439]   \t[ 2713.132805     0.775629  2712.90385 ]\t[-10000.            8.            0.085068]\t[     0.743791     11.        10000.      ]\n",
      "14 \t28    \t[-1199.347222     8.26      1200.091509]\t[ 3249.856416     0.795236  3249.58157 ]\t[-10000.            7.            0.094896]\t[     0.743791     11.        10000.      ]\n",
      "15 \t25    \t[-799.319614    8.24      800.09494 ]   \t[ 2713.132628     0.906863  2712.903997]\t[-10000.            6.            0.082265]\t[     0.743791     12.        10000.      ]\n",
      "16 \t26    \t[-599.302373    8.18      600.0981  ]   \t[ 2375.04467      0.712461  2374.843633]\t[-10000.            7.            0.095098]\t[     0.749346     12.        10000.      ]\n",
      "17 \t34    \t[-799.317614    8.3       800.095263]   \t[ 2713.133218     0.781025  2712.903902]\t[-10000.            8.            0.095098]\t[     0.749346     11.        10000.      ]\n",
      "18 \t30    \t[-799.317987    8.36      800.094794]   \t[ 2713.133108     0.911263  2712.90404 ]\t[-10000.            7.            0.086275]\t[     0.749346     12.        10000.      ]\n",
      "19 \t28    \t[-799.315928    8.52      800.092955]   \t[ 2713.133715     0.780769  2712.904582]\t[-10000.            8.            0.076502]\t[     0.749346     12.        10000.      ]\n",
      "20 \t29    \t[-799.313993    8.82      800.090887]   \t[ 2713.134286     0.993781  2712.905192]\t[-10000.            8.            0.082934]\t[     0.749346     12.        10000.      ]\n",
      "21 \t15    \t[-1399.356843     9.26      1400.082084]\t[ 3470.129811     0.715821  3469.837196]\t[-10000.            9.            0.095098]\t[     0.749346     12.        10000.      ]\n",
      "22 \t25    \t[-999.331229    9.16     1000.083079]   \t[ 3000.222924     0.856971  2999.972307]\t[-10000.            8.            0.063241]\t[     0.749346     13.        10000.      ]\n",
      "23 \t28    \t[-2399.430497     9.62      2400.072275]\t[ 4271.151334     1.29445   4270.790686]\t[-10000.            9.            0.095098]\t[     0.749346     14.        10000.      ]\n",
      "24 \t28    \t[-1799.386353     9.42      1800.078375]\t[ 3842.162049     1.115168  3841.837822]\t[-10000.            8.            0.095098]\t[     0.749346     14.        10000.      ]\n",
      "25 \t29    \t[-1199.344458     9.08      1200.082846]\t[ 3249.857437     0.688186  3249.584769]\t[-10000.            7.            0.063241]\t[     0.749346     12.        10000.      ]\n",
      "26 \t33    \t[-2199.419725     9.3       2200.074164]\t[ 4142.771211     0.781025  4142.423648]\t[-10000.            8.            0.078652]\t[     0.749346     12.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI', 'RI*Mg', 'Na*Al', 'Na*Ba', 'Al*Ca', 'Al*Ba', 'Si*Ca', 'K*Ca', 'Ba*Fe']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.79      0.69        14\n",
      "           2       0.62      0.67      0.65        15\n",
      "           3       0.00      0.00      0.00         3\n",
      "           5       0.50      0.67      0.57         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.65        43\n",
      "   macro avg       0.46      0.49      0.47        43\n",
      "weighted avg       0.59      0.65      0.62        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "search_space = [{'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 62.5 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             param_grid=[{'classifier': [KNeighborsClassifier()]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "knn_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "knn_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(knn_variance,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.510943  4.32      0.106975]\t[ 0.100835  2.679104  0.023691]\t[ 0.286667  1.        0.049725]\t[ 0.651429  9.        0.146308]\n",
      "1  \t32    \t[-1199.492019     6.3       1200.106968]\t[ 3249.802947     2.459675  3249.575861]\t[-10000.            1.            0.074298]\t[     0.651429     12.        10000.      ]\n",
      "2  \t34    \t[-1199.461838     7.18      1200.108555]\t[ 3249.814092     2.056113  3249.575275]\t[-10000.            2.            0.070797]\t[     0.677619     13.        10000.      ]\n",
      "3  \t31    \t[-799.415886    7.24      800.115857]   \t[ 2713.104239     1.668053  2712.897829]\t[-10000.            3.            0.088351]\t[     0.677619     13.        10000.      ]\n",
      "4  \t32    \t[-1199.441838     7.56      1200.110484]\t[ 3249.821477     1.790642  3249.574563]\t[-10000.            3.            0.071834]\t[     0.677619     13.        10000.      ]\n",
      "5  \t27    \t[-1199.439143     7.66      1200.111948]\t[ 3249.822472     1.422814  3249.574022]\t[-10000.            5.            0.096487]\t[     0.677619     12.        10000.      ]\n",
      "6  \t29    \t[-1599.461648     8.04      1600.106559]\t[ 3666.295512     1.672842  3666.01405 ]\t[-10000.            4.            0.065873]\t[     0.677619     13.        10000.      ]\n",
      "7  \t24    \t[-799.405962    7.7       800.120267]   \t[ 2713.107166     1.3       2712.896528]\t[-10000.            5.            0.083354]\t[     0.677619     11.        10000.      ]\n",
      "8  \t24    \t[-799.393562    7.72      800.123761]   \t[ 2713.110822     1.371714  2712.895498]\t[-10000.            4.            0.090937]\t[     0.678095     12.        10000.      ]\n",
      "9  \t42    \t[-2399.500848     8.4       2400.09904 ]\t[ 4271.1118       1.523155  4270.775645]\t[-10000.            4.            0.083354]\t[     0.692857     12.        10000.      ]\n",
      "10 \t37    \t[-599.371581    8.28      600.128319]   \t[ 2375.027185     0.938936  2374.835998]\t[-10000.            7.            0.083354]\t[     0.692857     13.        10000.      ]\n",
      "11 \t34    \t[-1599.433133     8.68      1600.113186]\t[ 3666.307957     1.008762  3666.011158]\t[-10000.            7.            0.094444]\t[     0.692857     12.        10000.      ]\n",
      "12 \t24    \t[-1199.400257     8.72      1200.11738 ]\t[ 3249.836832     0.84947   3249.572017]\t[-10000.            7.            0.120035]\t[     0.692857     11.        10000.      ]\n",
      "13 \t32    \t[-599.35479     8.54      600.123806]   \t[ 2375.031427     0.726911  2374.837138]\t[-10000.            7.            0.122617]\t[     0.692857     10.        10000.      ]\n",
      "14 \t29    \t[-1599.418571     9.28      1600.109332]\t[ 3666.314312     0.96      3666.01284 ]\t[-10000.            8.            0.130101]\t[     0.692857     13.        10000.      ]\n",
      "15 \t25    \t[-1399.404143     9.18      1400.111887]\t[ 3470.110727     0.517301  3469.825171]\t[-10000.            9.            0.130101]\t[     0.692857     12.        10000.      ]\n",
      "16 \t34    \t[-1599.419105     9.24      1600.109151]\t[ 3666.314079     0.949947  3666.012919]\t[-10000.           7.           0.12548]   \t[     0.692857     13.        10000.      ]\n",
      "17 \t29    \t[-1399.405667     9.28      1400.112038]\t[ 3470.110112     1.149609  3469.82511 ]\t[-10000.            8.            0.130101]\t[     0.692857     15.        10000.      ]\n",
      "18 \t30    \t[-799.365324    8.96      800.119842]   \t[ 2713.119149     0.527636  2712.896654]\t[-10000.            8.            0.124037]\t[     0.692857     11.        10000.      ]\n",
      "19 \t23    \t[-599.349952    8.84      600.122134]   \t[ 2375.032649     0.578273  2374.837561]\t[-10000.            8.            0.121432]\t[     0.692857     11.        10000.      ]\n",
      "20 \t30    \t[-799.362981    8.8       800.119651]   \t[ 2713.11984      0.824621  2712.89671 ]\t[-10000.           8.           0.12802]   \t[     0.692857     12.        10000.      ]\n",
      "21 \t27    \t[-799.363905    8.68      800.119091]   \t[ 2713.119568     0.76      2712.896875]\t[-10000.            8.            0.097385]\t[     0.693333     12.        10000.      ]\n",
      "22 \t33    \t[-1399.406267     8.56      1400.111089]\t[ 3470.10987      1.022937  3469.825493]\t[-10000.            8.            0.097385]\t[     0.693333     12.        10000.      ]\n",
      "23 \t32    \t[-3199.531552     8.92      3200.088349]\t[ 4665.082868     1.44      4664.700909]\t[-10000.            7.            0.097385]\t[     0.693333     13.        10000.      ]\n",
      "24 \t26    \t[-1999.449067     8.64      2000.103224]\t[ 4000.275467     1.109234  3999.948388]\t[-10000.            7.            0.097385]\t[     0.693333     12.        10000.      ]\n",
      "25 \t28    \t[-1399.410581     8.64      1400.104038]\t[ 3470.108129     1.015086  3469.828338]\t[-10000.           7.           0.08664]   \t[     0.693333     12.        10000.      ]\n",
      "26 \t28    \t[-999.383305    8.7      1000.104008]   \t[ 3000.205565     0.7       2999.965331]\t[-10000.            8.            0.091652]\t[     0.693333     11.        10000.      ]\n",
      "27 \t24    \t[-1199.396219     8.96      1200.0912  ]\t[ 3249.838323     0.631189  3249.581684]\t[-10000.            7.            0.090927]\t[     0.693333     11.        10000.      ]\n",
      "28 \t35    \t[-1599.420743     9.16      1600.082554]\t[ 3666.313365     0.731027  3666.024527]\t[-10000.            7.            0.097385]\t[     0.693333     12.        10000.      ]\n",
      "29 \t31    \t[-1599.418238     9.22      1600.081992]\t[ 3666.314458     0.729109  3666.024772]\t[-10000.            7.            0.083094]\t[     0.699524     12.        10000.      ]\n",
      "30 \t32    \t[-1599.417371     9.28      1600.080205]\t[ 3666.314836     1.149609  3666.025552]\t[-10000.            7.            0.074974]\t[     0.714286     14.        10000.      ]\n",
      "31 \t31    \t[-1599.417838     9.12      1600.080919]\t[ 3666.314632     1.124989  3666.02524 ]\t[-10000.            6.            0.074974]\t[     0.714286     12.        10000.      ]\n",
      "32 \t26    \t[-1399.404095     8.96      1400.079736]\t[ 3470.110746     1.341044  3469.838143]\t[-10000.            7.            0.074974]\t[     0.714286     15.        10000.      ]\n",
      "33 \t26    \t[-999.377724    8.78     1000.084008]   \t[ 3000.207426     1.063767  2999.971997]\t[-10000.            7.            0.074974]\t[     0.714286     12.        10000.      ]\n",
      "34 \t32    \t[-799.359762    8.42      800.082063]   \t[ 2713.120789     1.28203   2712.907794]\t[-10000.            6.            0.073093]\t[     0.714286     13.        10000.      ]\n",
      "35 \t24    \t[-999.370533    8.38     1000.086039]   \t[ 3000.209822     1.247237  2999.97132 ]\t[-10000.            6.            0.074974]\t[     0.727143     11.        10000.      ]\n",
      "36 \t34    \t[-1799.420048     8.66      1800.080504]\t[ 3842.146263     1.54415   3841.836825]\t[-10000.            6.            0.082787]\t[     0.727143     13.        10000.      ]\n",
      "37 \t31    \t[-1799.417181     9.04      1800.082809]\t[ 3842.147606     1.215895  3841.835745]\t[-10000.            6.            0.090237]\t[     0.727143     13.        10000.      ]\n",
      "38 \t35    \t[-2999.502048     9.22      3000.070075]\t[ 4582.901681     1.100727  4582.52982 ]\t[-10000.            6.            0.092117]\t[     0.727143     12.        10000.      ]\n",
      "39 \t32    \t[-3399.541333     9.04      3400.066707]\t[ 4737.416917     1.264278  4737.039835]\t[-10000.            6.            0.090237]\t[     0.727143     12.        10000.      ]\n",
      "40 \t31    \t[-2199.4452       8.72      2200.077304]\t[ 4142.757681     1.296765  4142.421981]\t[-10000.            6.            0.088961]\t[     0.727143     14.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Al', 'RI*Na', 'Na*K', 'Na*Ba', 'Mg*Al', 'Mg*Ca', 'Al*Ca', 'Ca*Fe']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.89      0.79        27\n",
      "           2       0.70      0.73      0.71        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.67      0.67      0.67         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.90      0.90      0.90        10\n",
      "\n",
      "    accuracy                           0.72        71\n",
      "   macro avg       0.49      0.53      0.51        71\n",
      "weighted avg       0.64      0.72      0.67        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [KNeighborsClassifier()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 80.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000001DA89D3B1F0>)),\n",
       "                                       ('classifier', KNeighborsClassifier())]),\n",
       "             param_grid=[{'classifier': [KNeighborsClassifier()]}])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "knn_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "knn_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(knn_chi,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.549295  4.7       0.109025]\t[ 0.099752  2.578759  0.027193]\t[ 0.293333  1.        0.038107]\t[ 0.692857  9.        0.18281 ]\n",
      "1  \t37    \t[-999.446352    6.28     1000.098973]\t[ 3000.18455      2.584879  2999.967009]\t[-10000.            1.            0.066052]\t[     0.721429     11.        10000.      ]\n",
      "2  \t33    \t[-999.423257    6.5      1000.098954]\t[ 3000.192248     2.202272  2999.967015]\t[-10000.            2.            0.071348]\t[     0.721429     11.        10000.      ]\n",
      "3  \t30    \t[-399.349581    6.54      400.103115]\t[ 1959.724561     1.675828  1959.570746]\t[-10000.            3.            0.060392]\t[     0.750476     11.        10000.      ]\n",
      "4  \t18    \t[ 0.703762  6.32      0.10762 ]      \t[ 0.030424  1.287478  0.019131]         \t[ 0.614762  3.        0.061583]            \t[ 0.750476  9.        0.146803]            \n",
      "5  \t23    \t[-399.309743    6.78      400.105848]\t[ 1959.732693     1.473635  1959.570188]\t[-10000.            4.            0.064164]\t[     0.762381     11.        10000.      ]\n",
      "6  \t34    \t[-199.282362    6.66      200.10757 ]\t[ 1400.10252      1.38      1399.984633]\t[-10000.           3.           0.05151]   \t[     0.76381     10.       10000.     ]   \n",
      "7  \t32    \t[-999.328581    7.3      1000.101972]\t[ 3000.223806     1.791647  2999.966009]\t[-10000.            5.            0.083945]\t[     0.785238     13.        10000.      ]\n",
      "8  \t27    \t[-999.3198     7.48    1000.10362]   \t[ 3000.226733     1.74631   2999.96546 ]\t[-10000.            3.            0.084662]\t[     0.785238     13.        10000.      ]\n",
      "9  \t32    \t[-1999.394152     8.14      2000.087209]\t[ 4000.302924     1.720581  3999.956395]\t[-10000.            4.            0.056416]\t[     0.790476     12.        10000.      ]\n",
      "10 \t33    \t[-1599.355895     7.76      1600.091044]\t[ 3666.341666     1.68      3666.020821]\t[-10000.            4.            0.054909]\t[     0.790476     11.        10000.      ]\n",
      "11 \t27    \t[-199.24399     7.82      200.105566]   \t[ 1400.108002     0.887468  1399.984919]\t[-10000.            5.            0.056416]\t[     0.790476     10.        10000.      ]\n",
      "12 \t27    \t[-1399.332562     8.5       1400.09522 ]\t[ 3470.139608     1.330413  3469.831896]\t[-10000.            6.            0.059554]\t[     0.791905     14.        10000.      ]\n",
      "13 \t35    \t[-1999.374752     8.82      2000.090618]\t[ 4000.312624     1.58354   3999.954691]\t[-10000.           6.           0.06653]   \t[     0.791905     14.        10000.      ]\n",
      "14 \t26    \t[-1799.361076     8.84      1800.091579]\t[ 3842.173892     1.155162  3841.831636]\t[-10000.            6.            0.071341]\t[     0.791905     12.        10000.      ]\n",
      "15 \t32    \t[-1599.345829     9.12      1600.094773]\t[ 3666.34606      1.177115  3666.019194]\t[-10000.            7.            0.101548]\t[     0.791905     13.        10000.      ]\n",
      "16 \t24    \t[-1399.3266       8.94      1400.095954]\t[ 3470.142014     0.732393  3469.8316  ]\t[-10000.            7.            0.056416]\t[     0.791905     11.        10000.      ]\n",
      "17 \t29    \t[-1599.342914     9.1       1600.091897]\t[ 3666.347332     0.921954  3666.020449]\t[-10000.            7.            0.081094]\t[     0.791905     13.        10000.      ]\n",
      "18 \t34    \t[-1599.339295     9.12      1600.091603]\t[ 3666.348911     0.95163   3666.020577]\t[-10000.            8.            0.083223]\t[     0.791905     12.        10000.      ]\n",
      "19 \t29    \t[-1999.368162     9.28      2000.088559]\t[ 4000.315919     0.872697  3999.955721]\t[-10000.            7.            0.108279]\t[     0.791905     12.        10000.      ]\n",
      "20 \t28    \t[-1199.303124     9.26      1200.096927]\t[ 3249.8727       0.795236  3249.579569]\t[-10000.            9.            0.110144]\t[     0.791905     13.        10000.      ]\n",
      "21 \t36    \t[-1399.318962     9.22      1400.094724]\t[ 3470.145095     0.575847  3469.832096]\t[-10000.            9.            0.110144]\t[     0.791905     11.        10000.      ]\n",
      "22 \t29    \t[-1399.326438     9.2       1400.0959  ]\t[ 3470.142079     0.72111   3469.831621]\t[-10000.            8.            0.109884]\t[     0.791905     12.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI', 'K', 'Ba', 'RI*Al', 'Na*K', 'Na*Ba', 'Mg*Ca', 'Si*K', 'Ca*Ba']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.89      0.76        27\n",
      "           2       0.80      0.73      0.76        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.40      0.67      0.50         3\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.70        71\n",
      "   macro avg       0.62      0.58      0.58        71\n",
      "weighted avg       0.67      0.70      0.68        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000001DA89F68D30>)),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [LogisticRegression()]}])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "logistic_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(logistic_info,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                         \n",
      "0  \t50    \t[ 0.5112    5.32      0.101452]\t[ 0.070193  2.774455  0.025952]\t[ 0.350952  1.        0.037265]\t[ 0.61619  9.       0.1547 ]\n",
      "1  \t29    \t[-1199.504105     7.22      1200.097651]\t[ 3249.798483     2.343416  3249.579302]\t[-10000.           1.           0.05363]\t[     0.61619     13.       10000.     ]\n",
      "2  \t20    \t[-1199.486276     7.94      1200.098371]\t[ 3249.805067     1.701881  3249.579036]\t[-10000.            4.            0.080874]\t[     0.62381     13.       10000.     ]\n",
      "3  \t34    \t[-999.477524    7.8      1000.103074]   \t[ 3000.174159     1.732051  2999.965642]\t[-10000.            1.            0.059858]\t[     0.624286     11.        10000.      ]\n",
      "4  \t37    \t[-1599.509562     7.92      1600.094296]\t[ 3666.274601     1.82033   3666.019402]\t[-10000.           4.           0.07557]   \t[     0.630476     12.        10000.      ]\n",
      "5  \t27    \t[-1399.486971     8.2       1400.093223]\t[ 3470.077308     1.708801  3469.832702]\t[-10000.            4.            0.078731]\t[     0.630476     13.        10000.      ]\n",
      "6  \t32    \t[-599.42679     8.46      600.104246]   \t[ 2375.013236     1.18676   2374.84208 ]\t[-10000.            4.            0.087294]\t[     0.630476     11.        10000.      ]\n",
      "7  \t24    \t[-1999.50579      8.86      2000.088238]\t[ 4000.247105     1.166362  3999.955881]\t[-10000.           5.           0.09532]   \t[     0.630476     11.        10000.      ]\n",
      "8  \t33    \t[-2399.52699      9.18      2400.083399]\t[ 4271.097109     0.993781  4270.784434]\t[-10000.            7.            0.096261]\t[     0.630476     13.        10000.      ]\n",
      "9  \t23    \t[-1399.460162     9.26      1400.09299 ]\t[ 3470.088125     0.934024  3469.832796]\t[-10000.            8.            0.099459]\t[     0.630476     14.        10000.      ]\n",
      "10 \t22    \t[-1199.446152     9.18      1200.094905]\t[ 3249.819884     0.653911  3249.580316]\t[-10000.            8.            0.107099]\t[     0.630476     12.        10000.      ]\n",
      "11 \t23    \t[-1799.48301      9.38      1800.087822]\t[ 3842.116764     0.869253  3841.833396]\t[-10000.            9.            0.107099]\t[     0.630476     12.        10000.      ]\n",
      "12 \t25    \t[-999.433543    9.22     1000.09627 ]   \t[ 3000.188819     0.807217  2999.96791 ]\t[-10000.           8.           0.08609]   \t[     0.630952     13.        10000.      ]\n",
      "13 \t30    \t[-2599.536229     9.42      2600.078787]\t[ 4386.61734      1.078703  4386.295739]\t[-10000.           7.           0.08609]   \t[     0.630952     14.        10000.      ]\n",
      "14 \t25    \t[-1599.472067     9.26      1600.088639]\t[ 3666.290965     0.86741   3666.021871]\t[-10000.           8.           0.08609]   \t[     0.630952     14.        10000.      ]\n",
      "15 \t24    \t[-1799.48521     9.24     1800.08593]   \t[ 3842.115733     0.861626  3841.834282]\t[-10000.           8.           0.08609]   \t[     0.630952     12.        10000.      ]\n",
      "16 \t29    \t[-1199.449276     9.16      1200.088512]\t[ 3249.81873      0.945727  3249.582677]\t[-10000.           8.           0.08609]   \t[     0.630952     14.        10000.      ]\n",
      "17 \t25    \t[-1199.444867     9.32      1200.080861]\t[ 3249.820358     0.904212  3249.585502]\t[-10000.           9.           0.08609]   \t[     0.630952     13.        10000.      ]\n",
      "18 \t34    \t[-999.433743    9.16     1000.080067]   \t[ 3000.188752     0.578273  2999.973311]\t[-10000.           8.           0.08609]   \t[     0.637619     11.        10000.      ]\n",
      "19 \t37    \t[-3199.572105     9.8       3200.059848]\t[ 4665.05505      1.574802  4664.720461]\t[-10000.           8.           0.08609]   \t[     0.637619     16.        10000.      ]\n",
      "20 \t27    \t[-1199.446781     9.12      1200.078068]\t[ 3249.819652     0.515364  3249.586533]\t[-10000.           8.           0.08609]   \t[     0.637619     11.        10000.      ]\n",
      "21 \t32    \t[-1399.459829     9.28      1400.07733 ]\t[ 3470.088259     0.980612  3469.839114]\t[-10000.           8.           0.08609]   \t[     0.637619     13.        10000.      ]\n",
      "22 \t26    \t[-799.4202      9.04      800.085816]   \t[ 2713.102967     0.344093  2712.906688]\t[-10000.           8.           0.08609]   \t[     0.637619     10.        10000.      ]\n",
      "23 \t29    \t[-1799.4814       9.26      1800.082896]\t[ 3842.117518     0.687314  3841.835704]\t[-10000.           8.           0.08609]   \t[     0.637619     12.        10000.      ]\n",
      "24 \t35    \t[-2599.529705     9.6       2600.080575]\t[ 4386.621207     1.296148  4386.294679]\t[-10000.           8.           0.08609]   \t[     0.637619     14.        10000.      ]\n",
      "25 \t32    \t[-2199.504219     9.34      2200.085562]\t[ 4142.726337     0.681469  4142.417595]\t[-10000.           9.           0.10182]   \t[     0.637619     11.        10000.      ]\n",
      "26 \t23    \t[-1599.465657     9.22      1600.091843]\t[ 3666.293762     0.756042  3666.020472]\t[-10000.            7.            0.096995]\t[     0.637619     11.        10000.      ]\n",
      "27 \t22    \t[-1599.464676     9.3       1600.09226 ]\t[ 3666.29419      0.806226  3666.02029 ]\t[-10000.           9.           0.10182]   \t[     0.637619     13.        10000.      ]\n",
      "28 \t36    \t[-1399.453895     9.32      1400.094673]\t[ 3470.090653     0.947418  3469.832117]\t[-10000.            8.            0.093576]\t[     0.651429     13.        10000.      ]\n",
      "29 \t23    \t[-2399.514714     9.54      2400.082445]\t[ 4271.104008     1.236285  4270.784971]\t[-10000.            8.            0.093576]\t[     0.651429     14.        10000.      ]\n",
      "30 \t34    \t[-599.400076    9.02      600.101933]   \t[ 2375.019986     0.423792  2374.842664]\t[-10000.            8.            0.093576]\t[     0.651429     11.        10000.      ]\n",
      "31 \t28    \t[-1999.489314     9.46      2000.085021]\t[ 4000.255343     1.41718   3999.957489]\t[-10000.            8.            0.093576]\t[     0.651429     14.        10000.      ]\n",
      "32 \t32    \t[-2199.500819     9.16      2200.081114]\t[ 4142.728143     1.007174  4142.419957]\t[-10000.            7.            0.093576]\t[     0.651429     13.        10000.      ]\n",
      "33 \t30    \t[-1599.461695     9.        1600.08564 ]\t[ 3666.295491     1.019804  3666.02318 ]\t[-10000.            7.            0.093576]\t[     0.651429     14.        10000.      ]\n",
      "34 \t20    \t[-1199.430629     9.08      1200.086086]\t[ 3249.825616     0.594643  3249.583572]\t[-10000.            8.            0.093576]\t[     0.651429     12.        10000.      ]\n",
      "35 \t31    \t[-2199.495067     9.4       2200.074849]\t[ 4142.731198     1.058301  4142.423284]\t[-10000.            7.            0.091757]\t[     0.651429     13.        10000.      ]\n",
      "36 \t29    \t[-1999.479133     9.32      2000.07519 ]\t[ 4000.260433     0.705408  3999.962405]\t[-10000.            9.            0.093576]\t[     0.651429     12.        10000.      ]\n",
      "37 \t33    \t[-1199.430819     9.24      1200.083831]\t[ 3249.825546     0.81388   3249.584405]\t[-10000.            9.            0.093576]\t[     0.651429     14.        10000.      ]\n",
      "38 \t33    \t[-799.402524    9.12      800.086431]   \t[ 2713.108179     0.552811  2712.906506]\t[-10000.            8.            0.085424]\t[     0.651429     12.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI', 'RI*Al', 'Na*Si', 'Na*Ca', 'Na*Ba', 'Na*Fe', 'Mg*Ca', 'K*Ca', 'K*Ba']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.74      0.62        27\n",
      "           2       0.60      0.55      0.57        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.50      0.33      0.40         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.80      0.80      0.80        10\n",
      "\n",
      "    accuracy                           0.58        71\n",
      "   macro avg       0.41      0.40      0.40        71\n",
      "weighted avg       0.53      0.58      0.54        71\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', LogisticRegression())])\n",
    "\n",
    "search_space = [{'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 259 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'classifier': [LogisticRegression()]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "logistic_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(logistic_variance,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.48361   4.78      0.103048]\t[ 0.064008  2.685442  0.032717]\t[ 0.336667  1.        0.037265]\t[ 0.568571  9.        0.159025]\n",
      "1  \t29    \t[-999.514352    6.84     1000.106535]\t[ 3000.161883     2.292248  2999.964488]\t[-10000.            2.            0.076412]\t[     0.622857     12.        10000.      ]\n",
      "2  \t23    \t[-999.505086    7.18     1000.109884]\t[ 3000.164972     2.065817  2999.963372]\t[-10000.            3.            0.064067]\t[     0.622857     12.        10000.      ]\n",
      "3  \t28    \t[-1199.508048     7.86      1200.109548]\t[ 3249.797028     1.800111  3249.574909]\t[-10000.            4.            0.079141]\t[     0.622857     12.        10000.      ]\n",
      "4  \t36    \t[-1999.552371     8.36      2000.099102]\t[ 4000.223815     2.017523  3999.950449]\t[-10000.            4.            0.072408]\t[     0.622857     14.        10000.      ]\n",
      "5  \t27    \t[-1599.516829     8.3       1600.10042 ]\t[ 3666.271429     1.445683  3666.016729]\t[-10000.            5.            0.072408]\t[     0.622857     12.        10000.      ]\n",
      "6  \t38    \t[-1199.483829     8.14      1200.108046]\t[ 3249.805971     1.442359  3249.575463]\t[-10000.            5.            0.090302]\t[     0.637143     12.        10000.      ]\n",
      "7  \t33    \t[-1799.506029     8.48      1800.09483 ]\t[ 3842.105979     1.627759  3841.830113]\t[-10000.            6.            0.096534]\t[     0.637143     13.        10000.      ]\n",
      "8  \t29    \t[-1399.480076     8.46      1400.101358]\t[ 3470.08009      1.486069  3469.82942 ]\t[-10000.            6.            0.096534]\t[     0.637143     15.        10000.      ]\n",
      "9  \t32    \t[-1999.509162     8.3       2000.089287]\t[ 4000.245419     1.3       3999.955356]\t[-10000.            5.            0.097158]\t[     0.64381     11.       10000.     ]   \n",
      "10 \t35    \t[-1799.489038     8.4       1800.089649]\t[ 3842.113939     1.428286  3841.83254 ]\t[-10000.            6.            0.097158]\t[     0.64381     13.       10000.     ]   \n",
      "11 \t35    \t[-2199.517829     8.42      2200.083065]\t[ 4142.71911      1.625915  4142.418921]\t[-10000.            6.            0.095889]\t[     0.64381     13.       10000.     ]   \n",
      "12 \t26    \t[-1199.448914     8.06      1200.092629]\t[ 3249.818864     1.391546  3249.581156]\t[-10000.            6.            0.097158]\t[     0.64381     13.       10000.     ]   \n",
      "13 \t21    \t[-799.410905    7.64      800.09683 ]   \t[ 2713.105708     1.29244   2712.90344 ]\t[-10000.            7.            0.100403]\t[     0.64381     12.       10000.     ]   \n",
      "14 \t29    \t[-999.427276    7.58     1000.095436]   \t[ 3000.190908     1.184736  2999.968188]\t[-10000.            7.            0.100403]\t[     0.64381     12.       10000.     ]   \n",
      "15 \t26    \t[ 0.637505  7.24      0.105763]         \t[ 0.022644  0.649923  0.005137]         \t[ 0.517143  7.        0.102266]            \t[ 0.64381   9.        0.126392]            \n",
      "16 \t33    \t[-599.400038    7.5       600.099016]   \t[ 2375.019995     1.153256  2374.843401]\t[-10000.            7.            0.100403]\t[     0.64381     12.       10000.     ]   \n",
      "17 \t30    \t[-199.376       7.16      200.103883]   \t[ 1400.089143     0.542586  1399.98516 ]\t[-10000.           7.           0.10428]   \t[     0.64381     10.       10000.     ]   \n",
      "18 \t34    \t[-599.39661     7.38      600.097699]   \t[ 2375.020861     0.997798  2374.843734]\t[-10000.            7.            0.087532]\t[     0.64381     12.       10000.     ]   \n",
      "19 \t32    \t[-599.403086    7.34      600.100399]   \t[ 2375.019225     0.862786  2374.843052]\t[-10000.            6.            0.084751]\t[     0.64381     10.       10000.     ]   \n",
      "20 \t36    \t[-799.411238    7.46      800.096737]   \t[ 2713.10561      1.004191  2712.903467]\t[-10000.            7.            0.100403]\t[     0.64381     11.       10000.     ]   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mg', 'RI*Al', 'Na*K', 'Na*Ba', 'Na*Fe', 'Al*K', 'K*Ca']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.85      0.72        27\n",
      "           2       0.65      0.59      0.62        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.50      0.67      0.57         3\n",
      "           6       1.00      0.50      0.67         2\n",
      "           7       0.89      0.80      0.84        10\n",
      "\n",
      "    accuracy                           0.66        71\n",
      "   macro avg       0.61      0.57      0.57        71\n",
      "weighted avg       0.61      0.66      0.63        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [LogisticRegression()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 200 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000001DA89D3B1F0>)),\n",
       "                                       ('classifier', LogisticRegression())]),\n",
       "             param_grid=[{'classifier': [LogisticRegression()]}])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "logistic_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "logistic_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(logistic_chi,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.482162  4.66      0.082262]\t[ 0.058337  2.518809  0.028035]\t[ 0.357143  1.        0.038686]\t[ 0.574286  9.        0.148703]\n",
      "1  \t36    \t[-799.522171    6.62      800.094201]\t[ 2713.072898     2.415699  2712.904215]\t[-10000.            1.            0.050269]\t[     0.574286     11.        10000.      ]\n",
      "2  \t27    \t[-1599.549171     7.58      1600.088324]\t[ 3666.257314     1.970685  3666.022008]\t[-10000.            4.            0.052314]\t[     0.588095     12.        10000.      ]\n",
      "3  \t32    \t[-999.506467    7.9      1000.094512]   \t[ 3000.164511     1.7       2999.968496]\t[-10000.            5.            0.052675]\t[     0.588095     13.        10000.      ]\n",
      "4  \t30    \t[-2399.570876     8.48      2400.075769]\t[ 4271.072448     1.513142  4270.788722]\t[-10000.            4.            0.071707]\t[     0.595714     12.        10000.      ]\n",
      "5  \t27    \t[-1199.500733     8.24      1200.084053]\t[ 3249.799728     1.32      3249.584323]\t[-10000.            5.            0.056241]\t[     0.595714     12.        10000.      ]\n",
      "6  \t30    \t[-2399.5638       8.66      2400.071642]\t[ 4271.076424     1.607607  4270.791041]\t[-10000.           5.           0.07481]   \t[     0.595714     12.        10000.      ]\n",
      "7  \t29    \t[-2199.553448     8.36      2200.075746]\t[ 4142.700193     1.81945   4142.422808]\t[-10000.            3.            0.064657]\t[     0.595714     13.        10000.      ]\n",
      "8  \t29    \t[-1999.542248     8.14      2000.073496]\t[ 4000.228876     1.428426  3999.963252]\t[-10000.           5.           0.07481]   \t[     0.595714     11.        10000.      ]\n",
      "9  \t23    \t[-1199.48939      8.2       1200.080528]\t[ 3249.803917     1.264911  3249.585625]\t[-10000.            5.            0.072054]\t[     0.595714     11.        10000.      ]\n",
      "10 \t30    \t[-1999.531876     8.46      2000.069645]\t[ 4000.234062     1.117318  3999.965178]\t[-10000.            6.            0.072054]\t[     0.595714     11.        10000.      ]\n",
      "11 \t32    \t[-1199.480162     8.28      1200.075611]\t[ 3249.807325     0.7494    3249.587441]\t[-10000.            6.            0.083502]\t[     0.595714     10.        10000.      ]\n",
      "12 \t25    \t[-799.45719     8.24      800.078892]   \t[ 2713.092059     0.838093  2712.908729]\t[-10000.            6.            0.083502]\t[     0.595714     11.        10000.      ]\n",
      "13 \t32    \t[-1399.4894       8.3       1400.072832]\t[ 3470.076328     1.044031  3469.840929]\t[-10000.           6.           0.07481]   \t[     0.595714     12.        10000.      ]\n",
      "14 \t28    \t[-399.432638    8.18      400.08312 ]   \t[ 1959.707607     0.589576  1959.574827]\t[-10000.            7.            0.083502]\t[     0.595714     11.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Al', 'RI*Na', 'RI*Ba', 'Na*Mg', 'Al*Si', 'Al*K', 'Si*K', 'Si*Fe']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.85      0.73        27\n",
      "           2       0.58      0.64      0.61        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.67      0.67      0.67         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.88      0.70      0.78        10\n",
      "\n",
      "    accuracy                           0.65        71\n",
      "   macro avg       0.46      0.48      0.46        71\n",
      "weighted avg       0.58      0.65      0.60        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', StandardScaler()),\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [SVC(kernel='linear')]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000001DA89F68D30>)),\n",
       "                                       ('classifier', SVC(kernel='linear'))]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [SVC(kernel='linear')]}])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "svm_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(svm_info,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.499     4.24      0.085044]\t[ 0.067672  2.445895  0.026844]\t[ 0.377619  1.        0.041853]\t[ 0.61      9.        0.137603]\n",
      "1  \t24    \t[-599.482305    6.06      600.093111]\t[ 2374.999211     2.781438  2374.844894]\t[-10000.            2.            0.051598]\t[     0.61     14.    10000.  ]\n",
      "2  \t23    \t[-399.443733    7.2       400.095269]\t[ 1959.705342     1.979899  1959.572348]\t[-10000.            2.            0.051598]\t[     0.61     11.    10000.  ]\n",
      "3  \t28    \t[-1199.479438     8.06      1200.093113]\t[ 3249.807592     1.848351  3249.580978]\t[-10000.            3.            0.051598]\t[     0.61     13.    10000.  ]\n",
      "4  \t40    \t[-1799.521629     8.3       1800.091172]\t[ 3842.09867      1.652271  3841.831826]\t[-10000.            5.            0.071771]\t[     0.623333     13.        10000.      ]\n",
      "5  \t25    \t[-999.461429    8.12     1000.103291]   \t[ 3000.179524     1.177115  2999.96557 ]\t[-10000.            5.            0.056713]\t[     0.623333     12.        10000.      ]\n",
      "6  \t30    \t[-1599.492495     8.32      1600.097494]\t[ 3666.282049     1.348184  3666.018006]\t[-10000.            6.            0.073494]\t[     0.624762     12.        10000.      ]\n",
      "7  \t26    \t[-1199.476867     8.34      1200.102377]\t[ 3249.808542     1.159483  3249.577556]\t[-10000.            6.            0.088013]\t[     0.624762     12.        10000.      ]\n",
      "8  \t28    \t[-1199.465324     8.28      1200.100678]\t[ 3249.812804     0.938936  3249.578184]\t[-10000.            6.            0.089118]\t[     0.624762     11.        10000.      ]\n",
      "9  \t27    \t[-199.406648    8.12      200.110971]   \t[ 1400.084765     0.765245  1399.984147]\t[-10000.            7.            0.076659]\t[     0.624762     11.        10000.      ]\n",
      "10 \t30    \t[-999.451686    8.26     1000.099117]   \t[ 3000.182771     1.694816  2999.966961]\t[-10000.            5.            0.056665]\t[     0.624762     15.        10000.      ]\n",
      "11 \t30    \t[-1199.462238     8.28      1200.097534]\t[ 3249.813944     1.265543  3249.579345]\t[-10000.            6.            0.070669]\t[     0.624762     13.        10000.      ]\n",
      "12 \t24    \t[-399.403238    8.14      400.107469]   \t[ 1959.713608     0.872009  1959.569857]\t[-10000.            7.            0.104745]\t[     0.624762     13.        10000.      ]\n",
      "13 \t28    \t[-1399.465895     8.42      1400.095648]\t[ 3470.085812     0.94      3469.831723]\t[-10000.            7.            0.080431]\t[     0.624762     11.        10000.      ]\n",
      "14 \t21    \t[-999.437714    8.26     1000.100888]   \t[ 3000.187429     0.795236  2999.966371]\t[-10000.            8.            0.112098]\t[     0.624762     11.        10000.      ]\n",
      "15 \t30    \t[-799.426657    8.32      800.103664]   \t[ 2713.101063     0.968297  2712.901424]\t[-10000.            8.            0.112098]\t[     0.624762     13.        10000.      ]\n",
      "16 \t23    \t[-999.441571    8.32     1000.10087 ]   \t[ 3000.186143     0.926067  2999.966377]\t[-10000.            7.            0.088939]\t[     0.624762     12.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ca', 'RI*Mg', 'RI*Al', 'RI*Si', 'RI*Ca', 'Mg*Ca', 'Al*K', 'Ca*Fe']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.76      0.93      0.83        27\n",
      "           2       0.76      0.73      0.74        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.67      0.67      0.67         3\n",
      "           6       0.33      0.50      0.40         2\n",
      "           7       0.82      0.90      0.86        10\n",
      "\n",
      "    accuracy                           0.75        71\n",
      "   macro avg       0.56      0.62      0.58        71\n",
      "weighted avg       0.68      0.75      0.71        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', SVC(kernel='linear'))])\n",
    "\n",
    "search_space = [{'classifier': [SVC(kernel='linear')]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', SVC(kernel='linear'))]),\n",
       "             param_grid=[{'classifier': [SVC(kernel='linear')]}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "svm_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(svm_variance,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [SVC()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 117 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000001A3B77905E0>)),\n",
       "                                       ('classifier', SVC())]),\n",
       "             param_grid=[{'classifier': [SVC()]}])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svm_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "svm_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(svm_chi,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.530524  5.84      0.084098]\t[ 0.050331  2.452427  0.021819]\t[ 0.391905  1.        0.053061]\t[ 0.609048  9.        0.13954 ]\n",
      "1  \t26    \t[-399.458781    7.14      400.08619 ]\t[ 1959.70227      1.865583  1959.574201]\t[-10000.            3.            0.053216]\t[     0.615714     13.        10000.      ]\n",
      "2  \t33    \t[-1599.51679      7.8       1600.077314]\t[ 3666.271446     1.754993  3666.026814]\t[-10000.            4.            0.061686]\t[     0.630476     13.        10000.      ]\n",
      "3  \t28    \t[-1799.515667     7.82      1800.070155]\t[ 3842.101463     2.21531   3841.841673]\t[-10000.            2.            0.063676]\t[     0.636667     13.        10000.      ]\n",
      "4  \t29    \t[-999.459029    7.64     1000.079362]   \t[ 3000.180324     1.774937  2999.973546]\t[-10000.            2.            0.059417]\t[     0.644286     12.        10000.      ]\n",
      "5  \t25    \t[-1399.487581     7.94      1400.078387]\t[ 3470.077062     1.912172  3469.838688]\t[-10000.            4.            0.054003]\t[     0.644286     13.        10000.      ]\n",
      "6  \t32    \t[-1399.476267     8.02      1400.078962]\t[ 3470.081627     1.489832  3469.838455]\t[-10000.            4.            0.067244]\t[     0.644286     11.        10000.      ]\n",
      "7  \t31    \t[-1399.468029     8.2       1400.077147]\t[ 3470.084951     1.536229  3469.839188]\t[-10000.            5.            0.054536]\t[     0.651429     12.        10000.      ]\n",
      "8  \t28    \t[-1199.4464       8.3       1200.077528]\t[ 3249.819792     1.330413  3249.586733]\t[-10000.            6.            0.058222]\t[     0.68619     13.       10000.     ]   \n",
      "9  \t20    \t[-999.422581    8.42     1000.075042]   \t[ 3000.192473     0.961041  2999.974986]\t[-10000.          6.          0.0507]      \t[     0.68619     11.       10000.     ]   \n",
      "10 \t24    \t[-1799.467067     8.56      1800.06784 ]\t[ 3842.124233     1.21918   3841.842758]\t[-10000.          6.          0.0507]      \t[     0.68619     12.       10000.     ]   \n",
      "11 \t36    \t[-2199.483905     8.7       2200.060564]\t[ 4142.737126     1.711724  4142.430871]\t[-10000.          6.          0.0507]      \t[     0.68619     15.       10000.     ]   \n",
      "12 \t33    \t[-1599.439419     8.16      1600.062587]\t[ 3666.305214     1.137717  3666.033241]\t[-10000.            6.            0.052372]\t[     0.7     10.   10000. ]               \n",
      "13 \t24    \t[-1399.419076     8.46      1400.060669]\t[ 3470.104702     1.68772   3469.845836]\t[-10000.            6.            0.048665]\t[     0.7     15.   10000. ]               \n",
      "14 \t25    \t[-1599.431657     8.32      1600.057942]\t[ 3666.308601     1.391977  3666.035268]\t[-10000.            4.            0.044201]\t[     0.7     12.   10000. ]               \n",
      "15 \t31    \t[-2399.480648     8.7       2400.050915]\t[ 4271.123152     1.153256  4270.802689]\t[-10000.            6.            0.055891]\t[     0.7     12.   10000. ]               \n",
      "16 \t31    \t[-1199.395486     8.68      1200.055629]\t[ 3249.838594     1.085173  3249.59482 ]\t[-10000.           7.           0.04926]   \t[     0.7     12.   10000. ]               \n",
      "17 \t25    \t[-1199.391819     8.82      1200.054498]\t[ 3249.839948     0.95268   3249.595237]\t[-10000.            6.            0.053824]\t[     0.7     11.   10000. ]               \n",
      "18 \t23    \t[-1199.385114     9.12      1200.052135]\t[ 3249.842423     0.620967  3249.59611 ]\t[-10000.            7.            0.058222]\t[     0.7     11.   10000. ]               \n",
      "19 \t28    \t[-1599.415381     9.28      1600.050205]\t[ 3666.315705     0.775629  3666.038645]\t[-10000.           8.           0.05836]   \t[     0.7     12.   10000. ]               \n",
      "20 \t23    \t[-1599.412695     9.22      1600.048948]\t[ 3666.316877     0.641561  3666.039193]\t[-10000.            8.            0.054629]\t[     0.7     12.   10000. ]               \n",
      "21 \t26    \t[-999.370705    9.26     1000.052794]   \t[ 3000.209765     0.890169  2999.982402]\t[-10000.           9.           0.05836]   \t[     0.7     13.   10000. ]               \n",
      "22 \t35    \t[-1199.384143     9.18      1200.0514  ]\t[ 3249.842782     0.653911  3249.596381]\t[-10000.           8.           0.05836]   \t[     0.7     12.   10000. ]               \n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI', 'Al', 'RI*Al', 'RI*Fe', 'Na*Al', 'Na*Si', 'Na*Ba', 'Mg*K', 'Si*Ca']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.70      0.61        27\n",
      "           2       0.65      0.68      0.67        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.50      0.33      0.40         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.78      0.70      0.74        10\n",
      "\n",
      "    accuracy                           0.59        71\n",
      "   macro avg       0.41      0.40      0.40        71\n",
      "weighted avg       0.54      0.59      0.56        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([\n",
    "                 ('selector', SelectKBest(mutual_info_classif, k='all')),\n",
    "                 ('classifier', GaussianNB())])\n",
    "\n",
    "search_space = [{'selector__k': ['all']},\n",
    "                {'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.17 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function mutual_info_classif at 0x000001A3B8970160>)),\n",
       "                                       ('classifier', GaussianNB())]),\n",
       "             param_grid=[{'selector__k': ['all']},\n",
       "                         {'classifier': [GaussianNB()]}])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nb_info = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_info.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(nb_info,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.316305  5.4       0.080826]\t[ 0.097546  2.842534  0.025292]\t[ 0.16619   1.        0.038686]\t[ 0.54      9.        0.161729]\n",
      "1  \t25    \t[-399.646076    4.8       400.08612 ]\t[ 1959.664041     2.912044  1959.574215]\t[-10000.            1.            0.044183]\t[     0.54     10.    10000.  ]\n",
      "2  \t22    \t[ 0.43939   3.74      0.107475]      \t[ 0.098246  2.733569  0.031776]         \t[ 0.208571  1.        0.042775]            \t[ 0.573333  9.        0.176864]\n",
      "3  \t33    \t[-399.522305    2.96      400.108283]\t[ 1959.689305     2.47354   1959.569691]\t[-10000.            0.            0.051598]\t[     0.573333     10.        10000.      ]\n",
      "4  \t35    \t[ 0.494486  2.7       0.105169]      \t[ 0.113413  2.291288  0.018407]         \t[ 0.111429  1.        0.051234]            \t[ 0.573333  9.        0.153186]            \n",
      "5  \t30    \t[ 0.505943  3.62      0.107214]      \t[ 0.109034  3.084737  0.013074]         \t[ 0.152381  1.        0.081783]            \t[ 0.580476  9.        0.127938]            \n",
      "6  \t31    \t[-599.487381    5.6       600.106067]\t[ 2374.997929     3.458323  2374.84162 ]\t[-10000.            1.            0.079197]\t[     0.61619     12.       10000.     ]   \n",
      "7  \t40    \t[-1199.512295     7.48      1200.105223]\t[ 3249.795459     2.385288  3249.576506]\t[-10000.            1.            0.068421]\t[     0.61619     12.       10000.     ]   \n",
      "8  \t31    \t[-799.490943    8.12      800.114632]   \t[ 2713.082107     1.904101  2712.89819 ]\t[-10000.            3.            0.068421]\t[     0.61619     12.       10000.     ]   \n",
      "9  \t27    \t[-1199.505648     7.78      1200.108692]\t[ 3249.797914     2.229709  3249.575225]\t[-10000.            3.            0.052155]\t[     0.61619     11.       10000.     ]   \n",
      "10 \t27    \t[-599.473162    6.58      600.110466]   \t[ 2375.001522     2.490703  2374.840509]\t[-10000.            3.            0.052651]\t[     0.61619     12.       10000.     ]   \n",
      "11 \t23    \t[-199.449219    5.1       200.108806]   \t[ 1400.078686     2.012461  1399.984456]\t[-10000.           3.           0.06653]   \t[     0.61619     10.       10000.     ]   \n",
      "12 \t22    \t[ 0.580829  3.84      0.106813]         \t[ 0.077436  1.27059   0.017445]         \t[ 0.21619   3.        0.055826]            \t[ 0.61619   7.        0.157129]            \n",
      "13 \t26    \t[ 0.586724  3.5       0.100408]         \t[ 0.07563   1.153256  0.01    ]         \t[ 0.250476  3.        0.057704]            \t[ 0.61619   8.        0.118632]            \n",
      "14 \t32    \t[ 0.545619  3.4       0.096316]         \t[ 0.143093  0.938083  0.012813]         \t[ 0.152381  2.        0.049855]            \t[ 0.61619   6.        0.102069]            \n",
      "15 \t25    \t[ 0.59299  3.34     0.10145]            \t[ 0.084417  0.950999  0.01022 ]         \t[ 0.124762  3.        0.057135]            \t[ 0.61619   7.        0.136047]            \n",
      "16 \t31    \t[ 0.574762  3.66      0.101969]         \t[ 0.099278  1.450655  0.012455]         \t[ 0.215714  3.        0.070598]            \t[ 0.61619   8.        0.166463]            \n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI*Na', 'Mg*Al', 'Al*Ca']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.81      0.73        27\n",
      "           2       0.62      0.59      0.60        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.75      1.00      0.86         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.70      0.70      0.70        10\n",
      "\n",
      "    accuracy                           0.63        71\n",
      "   macro avg       0.46      0.52      0.48        71\n",
      "weighted avg       0.58      0.63      0.60        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('selector', VarianceThreshold()),\n",
    "                 ('classifier', GaussianNB())])\n",
    "\n",
    "search_space = [{'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                                       ('classifier', GaussianNB())]),\n",
       "             param_grid=[{'classifier': [GaussianNB()]}], scoring='accuracy')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_variance = GridSearchCV(pipe, search_space, cv=None, verbose=0, scoring= 'accuracy')\n",
    "nb_variance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(nb_variance,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.3094    5.28      0.081361]\t[ 0.115144  2.800286  0.029484]\t[ 0.090952  1.        0.03851 ]\t[ 0.567143  9.        0.172139]\n",
      "1  \t26    \t[-399.650095    5.76      400.090022]\t[ 1959.663221     2.789695  1959.573419]\t[-10000.            1.            0.038285]\t[     0.567143     11.        10000.      ]\n",
      "2  \t29    \t[-599.566067    4.36      600.094973]\t[ 2374.978051     2.847876  2374.844423]\t[-10000.            0.            0.043913]\t[     0.57381     11.       10000.     ]   \n",
      "3  \t26    \t[ 0.505067  3.28      0.094833]      \t[ 0.096383  2.10751   0.021043]         \t[ 0.217143  1.        0.046474]            \t[ 0.57381   9.        0.172139]            \n",
      "4  \t25    \t[ 0.533105  3.02      0.094931]      \t[ 0.081698  1.667213  0.02236 ]         \t[ 0.187619  1.        0.049082]            \t[ 0.57381   8.        0.170941]            \n",
      "5  \t27    \t[ 0.519286  3.24      0.091273]      \t[ 0.109327  1.631686  0.017352]         \t[ 0.167143  1.        0.049861]            \t[ 0.589048  8.        0.148428]            \n",
      "6  \t27    \t[ 0.517971  3.24      0.099679]      \t[ 0.111969  1.257935  0.02415 ]         \t[ 0.097619  1.        0.063505]            \t[ 0.589048  6.        0.215562]            \n",
      "7  \t32    \t[ 0.546667  3.52      0.101269]      \t[ 0.069303  1.445545  0.022533]         \t[ 0.180476  1.        0.067291]            \t[ 0.594762  8.        0.189654]            \n",
      "8  \t23    \t[ 0.569724  3.28      0.098259]      \t[ 0.025918  1.059056  0.012501]         \t[ 0.447619  2.        0.083175]            \t[ 0.594762  7.        0.147115]            \n",
      "9  \t23    \t[ 0.550571  3.66      0.100077]      \t[ 0.100095  1.069766  0.017586]         \t[ 0.200952  2.        0.040308]            \t[ 0.594762  7.        0.139501]            \n",
      "10 \t30    \t[ 0.534895  3.92      0.099596]      \t[ 0.11656   1.19733   0.023112]         \t[ 0.23      3.        0.040308]            \t[ 0.594762  8.        0.157579]            \n",
      "11 \t28    \t[ 0.561962  3.68      0.104657]      \t[ 0.080614  0.988737  0.019333]         \t[ 0.222857  2.        0.042013]            \t[ 0.609048  8.        0.151956]            \n",
      "12 \t24    \t[ 0.581152  3.56      0.107166]      \t[ 0.049254  1.003195  0.013687]         \t[ 0.278095  3.        0.076047]            \t[ 0.609048  8.        0.152685]            \n",
      "13 \t27    \t[ 0.569495  3.58      0.108315]      \t[ 0.079887  0.873842  0.019082]         \t[ 0.210476  3.        0.056856]            \t[ 0.630952  7.        0.168682]            \n",
      "14 \t28    \t[-199.449962    3.98      200.095246]\t[ 1400.078581     1.581012  1399.986394]\t[-10000.            3.            0.042807]\t[     0.630952     10.        10000.      ]\n",
      "15 \t30    \t[ 0.572514  4.3       0.096212]      \t[ 0.105119  1.284523  0.012499]         \t[ 0.229048  3.        0.070226]            \t[ 0.630952  8.        0.118494]            \n",
      "16 \t26    \t[ 0.605581  4.5       0.093078]      \t[ 0.056293  0.964365  0.014439]         \t[ 0.30619   3.        0.069565]            \t[ 0.630952  8.        0.164448]            \n",
      "17 \t22    \t[-199.40779     4.48      200.092099]\t[ 1400.084603     1.330263  1399.986843]\t[-10000.            2.            0.055785]\t[     0.630952     11.        10000.      ]\n",
      "18 \t34    \t[ 0.5718   4.7      0.09323]         \t[ 0.130415  1.3       0.015057]         \t[ 0.14619   4.        0.047752]            \t[ 0.630952  9.        0.153762]            \n",
      "19 \t22    \t[ 0.6068    4.18      0.091609]      \t[ 0.076452  0.589576  0.00772 ]         \t[ 0.271429  4.        0.05836 ]            \t[ 0.630952  7.        0.116195]            \n",
      "20 \t32    \t[ 0.619124  4.02      0.091203]      \t[ 0.058953  0.244131  0.006551]         \t[ 0.237143  3.        0.052155]            \t[ 0.630952  5.        0.092539]            \n",
      "21 \t19    \t[ 0.611019  4.26      0.094553]      \t[ 0.069743  0.844038  0.009678]         \t[ 0.292381  4.        0.076137]            \t[ 0.630952  8.        0.142686]            \n",
      "22 \t29    \t[ 0.6146    4.22      0.093897]      \t[ 0.067257  0.878408  0.007077]         \t[ 0.270952  4.        0.088597]            \t[ 0.630952  8.        0.12872 ]            \n",
      "23 \t36    \t[-399.440171    4.54      400.087932]\t[ 1959.706072     1.329812  1959.573845]\t[-10000.            4.            0.038226]\t[     0.630952     10.        10000.      ]\n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI', 'Na*Al', 'Na*Si', 'Al*Ca']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.67      0.59        27\n",
      "           2       0.44      0.50      0.47        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.67      0.80      0.73        10\n",
      "\n",
      "    accuracy                           0.52        71\n",
      "   macro avg       0.27      0.33      0.30        71\n",
      "weighted avg       0.43      0.52      0.47        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi-Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "pipe = Pipeline([('scaler', MinMaxScaler()),\n",
    "                 ('selector', SelectKBest(chi2, k='all')),\n",
    "                 ('classifier', GaussianNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = [{'classifier': [GaussianNB()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 81.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                       ('selector',\n",
       "                                        SelectKBest(k='all',\n",
       "                                                    score_func=<function chi2 at 0x000001A3B77905E0>)),\n",
       "                                       ('classifier', GaussianNB())]),\n",
       "             param_grid=[{'classifier': [GaussianNB()]}])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nb_chi = GridSearchCV(pipe, search_space, cv=None, verbose=0)\n",
    "nb_chi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = GeneticSelectionCV(nb_chi,\n",
    "                              cv=10,\n",
    "                              verbose=2,\n",
    "                              scoring=\"accuracy\",\n",
    "                              max_features=9,\n",
    "                              n_population=50,\n",
    "                              crossover_proba=0.5,\n",
    "                              mutation_proba=0.2,\n",
    "                              n_generations=40,\n",
    "                              crossover_independent_proba=0.5,\n",
    "                              mutation_independent_proba=0.05,\n",
    "                              tournament_size=3,\n",
    "                              n_gen_no_change=10,\n",
    "                              caching=True,\n",
    "                              n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting features with genetic algorithm.\n",
      "gen\tnevals\tavg                            \tstd                            \tmin                            \tmax                            \n",
      "0  \t50    \t[ 0.295105  4.26      0.082827]\t[ 0.112639  2.512449  0.02245 ]\t[ 0.111429  1.        0.042698]\t[ 0.518571  9.        0.165197]\n",
      "1  \t29    \t[ 0.384438  3.86      0.083479]\t[ 0.098575  2.097713  0.021257]\t[ 0.230476  1.        0.045428]\t[ 0.518571  9.        0.163174]\n",
      "2  \t26    \t[ 0.44159   2.94      0.086544]\t[ 0.081399  1.391546  0.018048]\t[ 0.208095  1.        0.045428]\t[ 0.547619  8.        0.124668]\n",
      "3  \t28    \t[ 0.487257  2.68      0.084469]\t[ 0.0524    1.391977  0.018449]\t[ 0.24381   1.        0.045428]\t[ 0.56    7.      0.1206]      \n",
      "4  \t37    \t[ 0.47499   3.5       0.084447]\t[ 0.108139  1.7       0.024242]\t[ 0.153333  1.        0.037559]\t[ 0.581905  8.        0.169248]\n",
      "5  \t24    \t[ 0.504229  3.82      0.096306]\t[ 0.098407  1.774148  0.023397]\t[ 0.187143  1.        0.062771]\t[ 0.609048  8.        0.15214 ]\n",
      "6  \t36    \t[ 0.52921  4.06     0.09803]   \t[ 0.08808   1.515388  0.020663]\t[ 0.119524  2.        0.056362]\t[ 0.609048  9.        0.161768]\n",
      "7  \t32    \t[ 0.554238  3.98      0.103761]\t[ 0.070278  1.256821  0.016499]\t[ 0.236667  1.        0.059811]\t[ 0.609048  8.        0.136228]\n",
      "8  \t28    \t[ 0.548086  4.18      0.103515]\t[ 0.10287   1.337012  0.016111]\t[ 0.215238  2.        0.042775]\t[ 0.623333  9.        0.122079]\n",
      "9  \t38    \t[ 0.56279   4.28      0.105319]\t[ 0.087308  1.342237  0.013865]\t[ 0.215238  3.        0.050968]\t[ 0.623333  8.        0.128094]\n",
      "10 \t31    \t[ 0.572971  4.34      0.103933]\t[ 0.082041  1.176605  0.017433]\t[ 0.21      2.        0.045647]\t[ 0.623333  7.        0.15673 ]\n",
      "11 \t30    \t[-199.463533    4.78      200.092053]\t[ 1400.076644     1.473635  1399.98685 ]\t[-10000.            2.            0.049855]\t[     0.637143     10.        10000.      ]\n",
      "12 \t29    \t[ 0.603581  4.9       0.097047]      \t[ 0.047945  1.081665  0.015195]         \t[ 0.371905  3.        0.081211]            \t[ 0.637143  9.        0.174658]            \n",
      "13 \t25    \t[ 0.586171  4.94      0.096406]      \t[ 0.098452  1.08462   0.019549]         \t[ 0.230476  3.        0.037559]            \t[ 0.637143  9.        0.167094]            \n",
      "14 \t35    \t[ 0.588905  5.14      0.097394]      \t[ 0.102575  1.039423  0.014243]         \t[ 0.237143  4.        0.052155]            \t[ 0.637143  8.        0.139422]            \n",
      "15 \t28    \t[-199.401667    5.6       200.097822]\t[ 1400.085478     1.077033  1399.986025]\t[-10000.            4.            0.064504]\t[     0.637143     10.        10000.      ]\n",
      "16 \t28    \t[-399.431038    6.16      400.091492]\t[ 1959.707936     1.238709  1959.573119]\t[-10000.            4.            0.045734]\t[     0.637143     10.        10000.      ]\n",
      "17 \t21    \t[ 0.595829  6.24      0.096226]      \t[ 0.11167   0.81388   0.011563]         \t[ 0.16      5.        0.054594]            \t[ 0.637143  9.        0.150374]            \n",
      "18 \t18    \t[-399.426105    6.46      400.090452]\t[ 1959.708943     1.203495  1959.573331]\t[-10000.            5.            0.042775]\t[     0.637143     11.        10000.      ]\n",
      "19 \t22    \t[-399.433067    6.36      400.093188]\t[ 1959.707522     0.995188  1959.572772]\t[-10000.            5.            0.067278]\t[     0.637143     11.        10000.      ]\n",
      "20 \t36    \t[-399.431933    6.44      400.092265]\t[ 1959.707753     1.08      1959.572961]\t[-10000.            6.            0.042868]\t[     0.637143     11.        10000.      ]\n",
      "21 \t32    \t[ 0.585895  6.3       0.095043]      \t[ 0.127138  0.754983  0.012992]         \t[ 0.174286  5.        0.052155]            \t[ 0.637143  9.        0.124555]            \n"
     ]
    }
   ],
   "source": [
    "selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RI', 'Al', 'RI*Na', 'Na*Al', 'Na*Si', 'Al*Ca']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the selected features\n",
    "cols = X.columns.tolist()\n",
    "selected_feats = [cols[i] for i in np.where(selector.support_)[0]]\n",
    "selected_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train and test\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train[selected_feats], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.67      0.59        27\n",
      "           2       0.44      0.50      0.47        22\n",
      "           3       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00         3\n",
      "           6       0.00      0.00      0.00         2\n",
      "           7       0.67      0.80      0.73        10\n",
      "\n",
      "    accuracy                           0.52        71\n",
      "   macro avg       0.27      0.33      0.30        71\n",
      "weighted avg       0.43      0.52      0.47        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Walter Ortiz\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict(X_test[selected_feats])\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
